import OpenAI from "openai";

const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY || process.env.OPENAI_KEY || "default_key" 
});

export interface FeedbackItem {
  nodeId: string;
  suggestion: string;
  severity: "low" | "medium" | "high";
  rationale: string;
}

export interface FunnelAnalysisRequest {
  flowJson: any;
  knowledgeBase: Array<{
    title: string;
    content: string;
    source: string;
  }>;
  userGoals?: string;
  industry?: string;
}

export class OpenAIService {
  // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
  private readonly model = "gpt-4o";

  async generateFunnelFeedback(request: FunnelAnalysisRequest): Promise<FeedbackItem[]> {
    try {
      const prompt = this.buildFeedbackPrompt(request);

      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are a funnel optimization expert. Analyze the provided funnel and give specific, actionable feedback. Respond with valid JSON only."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        temperature: 0.3,
      });

      const result = JSON.parse(response.choices[0].message.content || "{}");
      return result.feedback || [];
    } catch (error) {
      console.error("Error generating funnel feedback:", error);
      throw new Error("Failed to generate AI feedback");
    }
  }

  async generateContentSummary(content: string, maxLength: number = 50): Promise<string> {
    try {
      const prompt = `ë‹¤ìŒ ë‚´ìš©ì„ ${maxLength}ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. ì œëª©ì²˜ëŸ¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë‚´ìš©: ${content}

ì‘ë‹µì€ ìš”ì•½ëœ ì œëª©ë§Œ ì œê³µí•˜ì„¸ìš”.`;

      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are an expert content summarizer. Create concise, meaningful titles from content."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.3,
        max_tokens: 100,
      });

      return response.choices[0].message.content?.trim() || "ìš”ì•½ëœ ë‚´ìš©";
    } catch (error) {
      console.error("Error generating content summary:", error);
      return "AI ë¶„ì„ ë‚´ìš©";
    }
  }

  async extractKeyTopics(content: string, maxTopics: number = 3): Promise<string[]> {
    try {
      const prompt = `ë‹¤ìŒ ë‚´ìš©ì—ì„œ í•µì‹¬ ì£¼ì œë‚˜ í‚¤ì›Œë“œë¥¼ ì •í™•íˆ ${maxTopics}ê°œë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ê°€ì¥ ì¤‘ìš”í•˜ê³  êµ¬ì²´ì ì¸ ë§ˆì¼€íŒ…/ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ìš©ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ë‚´ìš©: ${content.substring(0, 2000)} ${content.length > 2000 ? '...' : ''}

ì‘ë‹µì€ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ê³ , ì •í™•íˆ ${maxTopics}ê°œì˜ í‚¤ì›Œë“œë§Œ í¬í•¨í•˜ì„¸ìš”:
{"topics": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"]}`;

      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are an expert at extracting key topics and keywords from content. Return only valid JSON with exactly the requested number of topics."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        response_format: { type: "json_object" },
        temperature: 0.2,
      });

      const result = JSON.parse(response.choices[0].message.content || "{}");
      const topics = result.topics || [];
      return topics.slice(0, maxTopics); // ì •í™•íˆ maxTopics ê°œìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
    } catch (error) {
      console.error("Error extracting key topics:", error);
      return ["ë§ˆì¼€íŒ…", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì „ëµ"];
    }
  }

  async enhanceContent(content: string, contentType: string, context?: string): Promise<string> {
    try {
      const prompt = context || `ë‹¤ìŒ ${contentType} ë‚´ìš©ì„ ë§ˆì¼€íŒ… í¼ë„ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”:

${content}

ê¹¨ì§„ í…ìŠ¤íŠ¸ë‚˜ ë¶ˆì™„ì „í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ë§¥ë½ì„ íŒŒì•…í•´ì„œ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ìœ¼ë¡œ í•´ì„í•´ì£¼ì„¸ìš”.`;

      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are an expert business analyst and marketing funnel strategist. You can interpret fragmented or poorly extracted text and transform it into actionable business insights. Focus on practical applications and real-world value."
          },
          {
            role: "user",
            content: prompt
          }
        ],
        temperature: 0.4,
        max_tokens: 2000,
      });

      return response.choices[0].message.content || content;
    } catch (error) {
      console.error("Error enhancing content:", error);
      throw new Error("Failed to enhance content");
    }
  }

  async generateEmbedding(text: string): Promise<number[]> {
    try {
      const response = await openai.embeddings.create({
        model: "text-embedding-ada-002",
        input: text,
      });

      return response.data[0].embedding;
    } catch (error) {
      console.error("Error generating embedding:", error);
      throw new Error("Failed to generate embedding");
    }
  }

  async extractTextFromImage(base64Image: string): Promise<string> {
    try {
      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "user",
            content: [
              {
                type: "text",
                text: "Extract all text from this image. Preserve formatting and structure as much as possible."
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:image/jpeg;base64,${base64Image}`
                }
              }
            ],
          },
        ],
        max_tokens: 1000,
      });

      return response.choices[0].message.content || "";
    } catch (error) {
      console.error("Error extracting text from image:", error);
      throw new Error("Failed to extract text from image");
    }
  }

  async analyzePDFContent(base64Pdf: string, filename: string): Promise<string> {
    try {
      const prompt = `PDF íŒŒì¼ "${filename}"ë¥¼ ë¶„ì„í•´ì„œ í•µì‹¬ ë‚´ìš©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë¬¸ì„œ ì œëª©**: [ë¬¸ì„œì˜ ì£¼ì œë‚˜ ì œëª©]

ğŸ¯ **ì£¼ìš” ëª©ì **: [ë¬¸ì„œì˜ ëª©ì ì´ë‚˜ ëª©í‘œ]

ğŸ“‹ **í•µì‹¬ ë‚´ìš©**:
- [ì£¼ìš” í¬ì¸íŠ¸ 1]
- [ì£¼ìš” í¬ì¸íŠ¸ 2] 
- [ì£¼ìš” í¬ì¸íŠ¸ 3]

ğŸ’¡ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**:
- [ì¤‘ìš”í•œ í†µì°°ì´ë‚˜ ê²°ë¡  1]
- [ì¤‘ìš”í•œ í†µì°°ì´ë‚˜ ê²°ë¡  2]

ğŸ”§ **ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜**:
- [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ 1]
- [êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆ 2]

ì´ PDFëŠ” ë§ˆì¼€íŒ… í¼ë„ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ì— ê´€ë ¨ëœ ì „ë¬¸ ì§€ì‹ì´ë¯€ë¡œ, ê·¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”.`;

      const response = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are an expert business analyst specializing in marketing funnels and business growth strategies. Analyze documents thoroughly and extract actionable insights."
          },
          {
            role: "user", 
            content: prompt
          }
        ],
        max_tokens: 1500,
        temperature: 0.3,
      });

      return response.choices[0].message.content || `PDF íŒŒì¼ "${filename}"ì— ëŒ€í•œ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë§ˆì¼€íŒ… í¼ë„ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµì— ê´€ë ¨ëœ ì „ë¬¸ ì§€ì‹ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.`;
    } catch (error) {
      console.error("Error analyzing PDF content:", error);
      throw new Error("Failed to analyze PDF content");
    }
  }

  async extractAndEnhancePDFContentFromText(extractedText: string, filename: string): Promise<{ extractedText: string, aiEnhancement: string }> {
    try {
      // Convert PDF to base64
      // pdfBuffer is not defined in this scope - this function needs to be updated
      const base64Pdf = ""; // Placeholder - function needs proper PDF buffer parameter
      
      // First try to extract text using OpenAI vision API
      const visionResponse = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "ë‹¹ì‹ ì€ PDF ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. PDFì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ê³  êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”. ê¹¨ì§„ í…ìŠ¤íŠ¸ë‚˜ ë¶ˆì™„ì „í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ë¬¸ë§¥ì„ íŒŒì•…í•´ì„œ ì˜ë¯¸ìˆê²Œ ë³µì›í•´ì£¼ì„¸ìš”."
          },
          {
            role: "user",
            content: [
              {
                type: "text",
                text: `PDF íŒŒì¼ "${filename}"ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ë‹¤ìŒì„ í¬í•¨í•´ì„œ ì™„ë²½í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ì œëª©ê³¼ í—¤ë”©
2. ë³¸ë¬¸ ë‚´ìš© 
3. í‘œë‚˜ ì°¨íŠ¸ì˜ í…ìŠ¤íŠ¸
4. ì£¼ì„ì´ë‚˜ ìº¡ì…˜
5. ëª©ë¡ì´ë‚˜ ë²ˆí˜¸

ì›ë³¸ êµ¬ì¡°ì™€ ì„œì‹ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ë©´ì„œ ì½ê¸° ì‰½ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”. ê¹¨ì§„ í…ìŠ¤íŠ¸ëŠ” ì˜ë¯¸ë¥¼ íŒŒì•…í•´ì„œ ë³µì›í•´ì£¼ì„¸ìš”.`
              },
              {
                type: "image_url",
                image_url: {
                  url: `data:application/pdf;base64,${base64Pdf}`,
                  detail: "high"
                }
              }
            ]
          }
        ],
        max_tokens: 3000,
        temperature: 0.1,
      });

      const extractedText = visionResponse.choices[0].message.content || "";

      if (!extractedText || extractedText.trim().length < 50) {
        throw new Error("OpenAI vision APIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }

      // Now enhance the extracted content with AI analysis
      const analysisPrompt = `ë‹¤ìŒì€ PDF "${filename}"ì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ë¥¼ ë§ˆì¼€íŒ… í¼ë„ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”í•´ì£¼ì„¸ìš”:

${extractedText}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

ğŸ“„ **ë¬¸ì„œ ì œëª©**: [ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ëª…í™•í•œ ì œëª©]
ğŸ¯ **ì£¼ìš” ëª©ì **: [ë¬¸ì„œì˜ í•µì‹¬ ëª©ì ]
ğŸ“‹ **í•µì‹¬ ë‚´ìš©**: 
- [ì£¼ìš” í¬ì¸íŠ¸ 1 - êµ¬ì²´ì ìœ¼ë¡œ]
- [ì£¼ìš” í¬ì¸íŠ¸ 2 - êµ¬ì²´ì ìœ¼ë¡œ] 
- [ì£¼ìš” í¬ì¸íŠ¸ 3 - êµ¬ì²´ì ìœ¼ë¡œ]
ğŸ’¡ **í•µì‹¬ ì¸ì‚¬ì´íŠ¸**: 
- [ì‹¤ë¬´ í™œìš© ê°€ëŠ¥í•œ í†µì°° 1]
- [ì‹¤ë¬´ í™œìš© ê°€ëŠ¥í•œ í†µì°° 2]
ğŸ”§ **ì‹¤í–‰ ë°©ì•ˆ**: 
- [êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœ 1]
- [êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœ 2]

ë§ˆì¼€íŒ… í¼ë„ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì„±ì¥ ê´€ì ì—ì„œ ì‹¤ë¬´ì— ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¹˜ ìˆëŠ” ì •ë³´ë¡œ ì¬êµ¬ì„±í•´ì£¼ì„¸ìš”.`;

      const enhancementResponse = await openai.chat.completions.create({
        model: this.model,
        messages: [
          {
            role: "system",
            content: "You are an expert business analyst and marketing funnel strategist. Transform extracted content into actionable business insights with clear structure and practical value."
          },
          {
            role: "user",
            content: analysisPrompt
          }
        ],
        max_tokens: 2500,
        temperature: 0.3,
      });

      const aiEnhancement = enhancementResponse.choices[0].message.content || "";

      return {
        extractedText: extractedText.trim(),
        aiEnhancement: aiEnhancement.trim()
      };

    } catch (error) {
      console.error("Error in OpenAI PDF processing:", error);
      throw new Error(`OpenAIë¥¼ í†µí•œ PDF ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  private buildFeedbackPrompt(request: FunnelAnalysisRequest): string {
    const { flowJson, knowledgeBase, userGoals, industry } = request;

    const kbSummary = knowledgeBase
      .map(kb => `Source: ${kb.source}\nTitle: ${kb.title}\nContent: ${kb.content.substring(0, 500)}...`)
      .join('\n\n');

    return `Analyze this marketing funnel and provide specific feedback:

FUNNEL STRUCTURE:
${JSON.stringify(flowJson, null, 2)}

KNOWLEDGE BASE:
${kbSummary}

${userGoals ? `USER GOALS: ${userGoals}` : ''}
${industry ? `INDUSTRY: ${industry}` : ''}

Please analyze the funnel based on best practices and the provided knowledge base. For each issue or recommendation, provide:

1. The specific node ID that needs attention
2. A clear, actionable suggestion
3. Severity level (low/medium/high) 
4. Rationale explaining why this is important

Focus on:
- Conversion optimization
- User experience flow
- Content effectiveness  
- Technical implementation
- Industry best practices

Respond with JSON in this exact format:
{
  "feedback": [
    {
      "nodeId": "string",
      "suggestion": "string", 
      "severity": "low|medium|high",
      "rationale": "string"
    }
  ]
}`;
  }
}

export const openaiService = new OpenAIService();
