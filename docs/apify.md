input : 

{
    "downloadSubtitles": true,
    "hasCC": false,
    "hasLocation": false,
    "hasSubtitles": false,
    "is360": false,
    "is3D": false,
    "is4K": false,
    "isBought": false,
    "isHD": false,
    "isHDR": false,
    "isLive": false,
    "isVR180": false,
    "maxResultStreams": 0,
    "maxResults": 10,
    "maxResultsShorts": 0,
    "preferAutoGeneratedSubtitles": true,
    "saveSubsToKVS": false,
    "startUrls": [
        {
            "url": "https://youtu.be/Tt45NrVIBn8?si=Rh62ANKcBMsr04bE",
            "method": "GET"
        }
    ],
    "subtitlesFormat": "plaintext"
}

----------
output 

[
  {
    "title": "Build a Chatbot with Next.js, LangChain, OpenAI, and Supabase Vector",
    "translatedTitle": null,
    "type": "video",
    "id": "Tt45NrVIBn8",
    "url": "https://youtu.be/Tt45NrVIBn8?si=Rh62ANKcBMsr04bE",
    "thumbnailUrl": "https://i.ytimg.com/vi/Tt45NrVIBn8/maxresdefault.jpg",
    "viewCount": 23949,
    "date": "2023-06-28T14:00:16.000Z",
    "likes": 434,
    "location": null,
    "channelName": "Supabase",
    "channelUrl": "https://www.youtube.com/@Supabase",
    "channelId": "UCNTVzV1InxHV-YR0fSajqPQ",
    "channelUsername": "Supabase",
    "numberOfSubscribers": 63500,
    "duration": "00:20:47",
    "commentsCount": 20,
    "text": "In this demo[0] we showcase how to build an AI chatbot using Next.js, LangChain with OpenAI and Supabase Vector[1], Supabase Auth, and Supabase Realtime!\n\nThis demo is a fork of the Pinecone chatbot demo[2], the details about its architecture and workings can be found in their blogpost[3].\n\n[0] https://github.com/supabase-community...\n[1] https://js.langchain.com/docs/modules...\n[2] https://github.com/pinecone-io/chatbo...\n[3] https://www.pinecone.io/learn/javascr...\n\nIn this video we’re showing you exactly, step by step how to build a chatbot using Next.js and LangChain, powered by Supabase Vector. We’ll also show you how to integrate advanced AI capabilities in your app so you can interact dynamically with documents.\n\nWhat you'll learn:\n\n✅ How to set up a Chatbot: Learn how to set up a multi-user chatbot that interacts with documents, with LangChain JS and Next.js.\n\n✅ Supabase as a Full-Stack Solution: See how Supabase Vector can replace multiple services like Pinecone, Ably, and CockroachDB, simplifying your tech stack.\n\n✅ Indexing and Querying with LangChain: Understand the process of generating embeddings, indexing them using Supabase Vector, and querying these embeddings to fetch relevant information.\n\n✅ Real-Time Interaction: Implement Supabase real-time features to stream responses back to the user so interaction is fluid.\n\n✅ Securing with Row Level Security: Apply Supabase's row level security to ensure that queries are only accessible to authenticated users.\n\nBy the end of this video, you'll have a fully functional chatbot that not only understands user queries but also fetches and streams relevant answers using Supabase's robust infrastructure.\n\nThis is the EASIEST way to use Next.js, LangChain, and Supabase to create powerful AI-driven chatbots for your app. \n\n🎙️ Presented by Thor Schaeff (@thorwebdev https://go.thor.bio/x)\n\nChapters\n00:00 Intro\n00:08 Demo preview\n00:52 Demo architecture\n03:06 LangChain & Supabase Vector\n03:27 Clone the repo and run it locally\n04:35 Enable RLS for LangChain\n06:07 Start Supabase locally\n06:30 Crawl a website and store embeddings\n09:00 Inspecting the crawler code\n11:02 Testing email signup verification locally with Inbucket\n11:57 Chatbot demo\n12:55 Inspecting the chat code\n16:16 Using Supabase Realtime Broadcast to stream responses\n\n\n💻 Videos to watch next:\n▶ Monitor database Queries in Next.js:    • Monitor Database Queries in Next.js Apps w...  \n▶ Build your own ChatGPT with Next.js & OpenAI:    • Build your own ChatGPT with Next.js and Op...  \n▶ All Next.js Supabase videos:    • Next.js with Supabase  \n\n👇 Learn more about Supabase 👇\n\n🕸 Website: https://supabase.com/\n🏁 Get started: https://app.supabase.com/\n📄 Docs: https://supabase.com/docs\n\n🔔 Subscribe for more tutorials and feature updates from Supabase:    / @supabase  \n\n📱 Connect with Us:\n🐙 Github: https://www.github.com/supabase \n💬 Discord: https://discord.supabase.com/\n🐦 Twitter:   / supabase  \n▶ Instagram (follow for memes):   / supabasecom   \n\n\nABOUT SUPABASE:\nSupabase is the open source Firebase alternative. Supabase provides a full Postgres database for every project with pgvector, backups, realtime, and more. Add and manage email and password, passwordless, OAuth, and mobile logins to your project through a suite of identity providers and APIs.\n\nBuild in a weekend, scale to millions.\n\n#Supabase #AppDevelopment #RealtimeApps #DeveloperTools",
    "translatedText": null,
    "descriptionLinks": [
      {
        "url": "https://github.com/supabase-community/langchain-chatbot-demo",
        "text": "https://github.com/supabase-community..."
      },
      {
        "url": "https://js.langchain.com/docs/modules/indexes/vector_stores/integrations/supabase",
        "text": "https://js.langchain.com/docs/modules..."
      },
      {
        "url": "https://github.com/pinecone-io/chatbot-demo",
        "text": "https://github.com/pinecone-io/chatbo..."
      },
      {
        "url": "https://www.pinecone.io/learn/javascript-chatbot/",
        "text": "https://www.pinecone.io/learn/javascr..."
      },
      {
        "url": "https://go.thor.bio/x",
        "text": "https://go.thor.bio/x"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8",
        "text": "00:00"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=8s",
        "text": "00:08"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=52s",
        "text": "00:52"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=186s",
        "text": "03:06"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=207s",
        "text": "03:27"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=275s",
        "text": "04:35"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=367s",
        "text": "06:07"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=390s",
        "text": "06:30"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=540s",
        "text": "09:00"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=662s",
        "text": "11:02"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=717s",
        "text": "11:57"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=775s",
        "text": "12:55"
      },
      {
        "url": "https://www.youtube.com/watch?v=Tt45NrVIBn8&t=976s",
        "text": "16:16"
      },
      {
        "url": "https://www.youtube.com/watch?v=FmezY-vYlkg",
        "text": "   • Monitor Database Queries in Next.js Apps w...  "
      },
      {
        "url": "https://www.youtube.com/watch?v=xmfNUCjszh4",
        "text": "   • Build your own ChatGPT with Next.js and Op...  "
      },
      {
        "url": "https://www.youtube.com/playlist?list=PL5S4mPUpp4OtwG-qCxm8gA_hjaBq0OPdz",
        "text": "   • Next.js with Supabase  "
      },
      {
        "url": "https://supabase.com/",
        "text": "https://supabase.com/"
      },
      {
        "url": "https://app.supabase.com/",
        "text": "https://app.supabase.com/"
      },
      {
        "url": "https://supabase.com/docs",
        "text": "https://supabase.com/docs"
      },
      {
        "url": "https://www.youtube.com/channel/UCNTVzV1InxHV-YR0fSajqPQ",
        "text": "   / @supabase  "
      },
      {
        "url": "https://www.github.com/supabase",
        "text": "https://www.github.com/supabase"
      },
      {
        "url": "https://discord.supabase.com/",
        "text": "https://discord.supabase.com/"
      },
      {
        "url": "https://www.twitter.com/supabase/",
        "text": "  / supabase  "
      },
      {
        "url": "https://www.instagram.com/supabasecom/",
        "text": "  / supabasecom  "
      },
      {
        "url": "https://www.youtube.com/hashtag/supabase",
        "text": "#Supabase"
      },
      {
        "url": "https://www.youtube.com/hashtag/appdevelopment",
        "text": "#AppDevelopment"
      },
      {
        "url": "https://www.youtube.com/hashtag/realtimeapps",
        "text": "#RealtimeApps"
      },
      {
        "url": "https://www.youtube.com/hashtag/developertools",
        "text": "#DeveloperTools"
      }
    ],
    "subtitles": [
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "ar",
        "plaintext": "مرحبًا، اليوم نحن نتطلع إلى إنشاء روبوت دردشة باستخدام next.js وLangChain باستخدام Supabase\nVector، لذا يمكننا الآن الدردشة مع المستند الخاص بنا، لذا ربما دعونا نسأل هل يسمح Supabase\nبعلامة استفهام للعمل عن بُعد، لذلك نحن نطلق هذا الآن أم نحن\" نعثر على المطابقات ويمكننا أن نرى هنا،\nلذلك وجدنا المطابقات الخاصة بنا، وهما هاتان الوظيفتان المنشورتان في Supabase، والآن أصبح المستند\nطويل جدًا، لذا نقوم بتلخيص المعلومات من منشوري الوظائف ثم نقوم بتجميعها\nمعًا موجهنا لذلك يمكننا أن نرى هنا موجهنا اه ثم نعيد بث الإجابة\nاه نعم يدعم Supabase العمل عن بعد الآن هذا العرض التوضيحي هو شوكة من\nالعرض التوضيحي لـ Pinecone uh chatbot وهذا عمل رائع حقًا بواسطة اه روي هنا يمكنك قراءة منشور المدونة الذي سأقوم بربطه أدناه\nكنوع من مفهوم إنشاء روبوت دردشة متعدد المستخدمين مع سلسلة ربط JS في next.js وهناك\nمكونان له ولكن الأهم من ذلك هو ما أردته نوعًا ما إن المحاولة هنا هي\nنوع من استبدال الكثير من هذه الخدمات المختلفة بالإمكانيات المضمنة\nفي Supabase، لذا بدلاً من Pinecone، نستخدم Supabase Vector بدلاً من\nاستخدام Supabase في الوقت الفعلي بدلاً من Cockroachdb الذي نستخدمه. postgres التي تأتي مع\nمكدس Supabase ثم بدلاً من بصمة الإصبع نستخدم Supabase auth، لذلك\nنقوم بدمج كل هذه الخدمات في Supabase فقط ونفتح AI um باستخدام next.js هنا الآن فيما يتعلق\nبالهندسة المعمارية لـ الشات بوت لدينا نوع من المكونين لذلك لدينا مفهرس\nالذي يكتب نوعًا ما من التضمينات التي تولد عمليات التضمين من أنفسنا للحقيقة\nهنا حتى نتمكن من إلقاء نظرة على المفهرس حتى يكون لدينا مصدر الحقيقة الخاص بنا وهو بعض مواقع الويب التي نستخدمها لدينا\nنوع من الزاحف للحصول على تلك المعلومات من موقع الويب ثم استخدام LangChain وفتح الذكاء الاصطناعي، حيث\nنقوم بإنشاء عمليات التضمين الخاصة بنا ثم تخزينها في ناقل Supabase الخاص بنا،\nوبعد ذلك عندما نرغب في الدردشة مع نوع الحقيقة الخاص بنا، فإننا نأخذها بشكل أساسي استعلام المستخدم\nمرة أخرى، نقوم بإنشاء تضمين من هذا الاستعلام، ثم نقوم بالبحث نوعًا ما في جميع المستندات\nللعثور على نوع من مصدر الحقيقة ذي الصلة الذي قمنا بفهرسته من نوع عناوين\nURL ذات الصلة، ونلخص هذا المحتوى من عناوين URL تلك ثم أين نحن نولد نوعًا من الاستجابة\nونقوم ببث ذلك مرة أخرى إلى المستخدم باستخدام الوقت الفعلي الخاضع للإشراف، والشيء الرائع في LangChain هو\nأنه يحتوي على دعم مدمج لـ Supabase Vector لذا فإن الطريقة التي يمكننا بها القيام بذلك هي أنه يمكننا فقط أخذ\nهذا المخطط هنا وتطبيق ذلك على قاعدة البيانات الخاصة بنا باستخدام امتداد المتجه، وبالتالي إذا قمت بالاستنساخ\nهنا، فقم باستنساخ عرض توضيحي لسلسلة رابط الدردشة، عنوان URL موجود أيضًا أدناه في الوصف،\nيمكننا بعد ذلك فتح هذا في كود vs على سبيل المثال ويمكننا أن ننظر إلى ذلك لدينا بعض عمليات الترحيل\nهنا، لذا فهي عمليات ترحيل أولية نطبقها عندما نقوم بتشغيل Supabase start\nحتى نتمكن من تشغيل Supabase start هنا لبدء مكدسنا المحلي، لقد قمت بالفعل بتشغيله حتى أتمكن من\nتشغيل حالة الإشراف لمعرفة نوع من المحلي بيانات الاعتماد وإذا قمت بفتح هذا هنا\nحتى نتمكن من رؤية أننا قمنا بنسخ هذا للتو من وثائق سلسلة الارتباط، فهذا ما يمكّن\nSupabase Vector من إنشاء مستنداتنا، مما يجعل إطار عمل LangChain\nيعمل بشكل أساسي مع ناقل Supabase ومن ثم شيء واحد لقد أضفت هنا على وجه التحديد\nالقدرة على السماح بالاستعلام عن المستندات العامة للمستخدمين المصادق عليهم، لذلك يستخدم هذا\nسياسات الأمان على مستوى الصف هنا ولذا أردنا فقط السماح بالاستعلام عن\nالمستخدمين المصادق عليهم من جانب العميل هل يمكننا السماح بذلك على سبيل المثال، وإلا فإن الأمر هو نفسه\nهنا حيث تمت إضافة هذا نوعًا ما في أمان مستوى الدور هنا، ثم نقوم أيضًا\nبتخزين المحادثات بحيث يكون هذا في الأساس كما تعلمون نوع النص من ذلك الذي تم كتابته\nفي الدردشة ثم ما رد عليه الذكاء الاصطناعي لذلك نقوم بتخزين\nالمحادثات المربكة ودردشة الذكاء الاصطناعي وكذلك نريد أن نتذكر تاريخ الدردشة ونقوم أيضًا بإدخال\nسجل الدردشة هذا في مطالبة أيضًا بمعرفة نوع ما من تاريخ المحادثات السابقة\nومرة ​​أخرى نحن نطبق نوعًا من سياسة الأمان على مستوى الدور هنا على وجه التحديد بحيث\nلا يمكن إلا للمستخدم رؤية نوع المحادثات الخاصة به التي تعرفها باستخدام chatbot\nاه، لذلك نحن نقوم بتأمين نوع من المعلومات هنا، حسنًا رائع، لذا دعونا نلقي نظرة بالفعل،\nيمكننا تشغيل هذا حتى نتمكن من قول npm run def، لذا أولاً وقبل كل شيء، تعلم أن لدينا Supabase يعمل\nمحليًا، ثم لدينا أيضًا أه، روبوت الدردشة يعمل هنا محليًا وهو\nيأتي مزودًا بمصادقة Supabase، لذا فهذه هي واجهة مستخدم المصادقة للرد فعليًا ولكن بعد ذلك أولاً نريد\nالزحف إلى بعض المعلومات وأنت تعلم هنا على سبيل المثال أننا نقوم بالتوظيف إذا كنت لا تعرف\nيمكنك الاطلاع على وظائف Supabase على سبيل المثال، نحن نوظف مهندس حلول للعملاء\nوهذا هو الوصف الوظيفي الكامل هنا، حيث يوجد الكثير من المعلومات التي تعرفها\nمثل العمل عن بعد بنسبة 100 بالمائة في برنامج ESOP في الشركة وملكية الأسهم أم نعم، الكثير من\nالأشياء لذلك تعلم دعونا نجعل حياتنا أسهل ودعنا نزحف فعليًا إلى هذا حتى\nنتمكن من الزحف إلى وصف وظيفتنا هنا وما يمكننا رؤيته هو أننا الآن نزحف إلى أجزاءنا ونزحف\nأيضًا لذلك النوع من الزاحف of يفعل شيئًا متكررًا بعض الشيء حيث يزحف إلى\nالصفحات التي ترتبط نوعًا ما بها أيضًا وبعد ذلك يمكننا أن نرى حسنًا، لقد تم ذلك الآن،\nلذا ما يمكننا رؤيته فعليًا الآن إذا ذهبنا إلى Supabase Studio هنا، لذلك لدينا المضيف المحلي\nمرة أخرى إذا كنت لا تتذكر أنه يمكننا القيام بحالة Supabase بعد أن قمنا بتشغيل بداية خاضعة للإشراف، فيمكننا\nالحصول على التفاصيل المحلية الخاصة بنا هنا وحتى نتمكن من فتح هذا المشروع محليًا هنا ويمكننا\nالآن البحث في لدينا محادثاتنا، لذا ليس لدينا أي محادثات بعد ولكن هنا لدينا مستنداتنا،\nلذلك هذا هو ما قمنا بالزحف إليه اه هنا لدينا تضمينات المتجهات الخاصة بنا اه ويمكنك\nرؤية نوع من أسطر التعليمات البرمجية وليس أسطرًا من التعليمات البرمجية لذلك هناك بعض البيانات التعريفية أيضًا وهذه\nعبارة عن نوع من السطور بحيث يتم تقسيم المستندات إلى أقسام مختلفة، لذلك\nباستخدام البيانات التعريفية أيضًا يمكننا بعد ذلك إجراء بعض التصفية لذلك يكون هذا قويًا حقًا في\npostgres حيث لدينا Json نوع البيانات B حتى نتمكن من إسقاط نوع كامل من مستندات Json في\nأم، كما تعلم أنك تعرف مستنداتنا هنا باعتبارها بيانات وصفية رائعة، لذا قمنا الآن بالزحف إلى هذا ولدينا\nذلك في قاعدة البيانات الخاصة بنا، لذا الآن ما يمكننا فعله هو أن نمتلكه بالفعل نظرة على كيفية عمل هذا الزاحف بحيث\nيكون ذلك في Pages API الخاص بنا ثم نزحف هنا لذلك نستخدم سلسلة الطول ونستخدم\nتضمينات openai الخاصة بنا من LangChain ثم نستخدم متجر Supabase Vector لذلك يعد هذا رائعًا حقًا\nتم دمج نوع من السلسلة الطويلة مع متجر Supabase Vector وبعد ذلك فقط اه\nمن الاستعلام حصلنا على عناوين URL التي نريد فهرستها، نحن نوعًا ما نقوم بإنشاء نوع من\nمجموعة المستندات لذلك نحن نقوم بتقسيم نوع ما الأقسام للتأكد من أن لدينا نوعًا من الحق\nالذي تعرفه في الحجم لإنشاء التضمين حتى لا نفاد نوعًا ما من حجم الرمز المميز\nونوع تقسيم المستندات هنا ثم نقوم بإنشاء التضمين، لذا\nنقوم بإنشاء عمليات تضمين الذكاء الاصطناعي المفتوحة، حيث نقوم بإنشاء متجر Supabase Vector الخاص بنا، فقط نضع عميل مسؤول Supabase\nهنا، لذلك يستخدم عميل Supabase الإداري فقط um هنا، يمكننا أن نرى أنه يستخدم المفتاح الخاص الذي هو\nمفتاح دور الخدمة الخاص بنا هنا، وبعد ذلك يمكننا ذلك تنفيذ نوع من العمليات الإدارية التي تتمثل في\nإدراج هذه المستندات ولذا فإننا نقوم بعد ذلك بإنشاء نوع ما في مجموعة المستندات الخاصة بنا\nونضيف نوعًا من تخزين جميع المستندات ثم لدينا المستندات هنا في قاعدة البيانات الخاصة بنا\nويمكننا بعد ذلك إجراء عمليات البحث عليها، لذلك دعونا ننتقل إلى ذلك، لذا سنحتاج أولاً إلى تسجيل الدخول،\nلذا حاليًا، إذا نظرنا إلى مشروعنا هنا، لذلك فإننا نعمل مرة أخرى على المضيف المحلي، فنحن نقوم بتشغيل\nمكدس Supabase بالكامل محليًا ولا نفعل ذلك 'ليس لدي أي مستخدمين حتى الآن، لذا دعونا نسجل\nمختبر مستخدم جديدًا في test dot de وum هنا، لذا إذا قلنا قم بتسجيل الدخول، فنحن لا نعرف أن\nبيانات الاعتماد غير صالحة لأننا لم نفعل ذلك، فلنقم بالتسجيل ثم نحتاج إلى ذلك تحقق من بريدنا الإلكتروني بحثًا عن\nرابط المحادثة الذي نعمل الآن على مضيف محلي لذلك نحن لا نرسل رسائل بريد إلكتروني فعلية هنا\nولكن ما يمكننا فعله هو أن لدينا الخدمة التي يتم استدعاؤها في المجموعة وهي خدمة رائعة حقًا مفتوحة\nالمصدر أيضًا و يمكننا أن نرى هنا أننا قمنا بتأكيد بريدك الإلكتروني، لذلك تم\nإرسال هذه الرسالة للتو الآن ويمكننا النقر فوق عنوان بريدنا الإلكتروني وتأكيده، والآن يمكننا أن نرى أننا مقيدون\nتطبيقنا هنا يعمل على مضيف محلي، لذا يمكننا الآن الدردشة مع مستنداتنا، لذا ربما\nدعونا نسأل هل يسمح Supabase بعلامة استفهام للعمل عن بُعد، لذلك نطلق هذا الآن، ونعثر على\nالتطابقات ويمكننا أن نرى هنا لقد وجدنا المطابقات لدينا، وهما\nمنشوري الوظائف في Supabase، والآن أصبح المستند طويل جدًا، لذا نقوم بتلخيص المعلومات من\nمنشوري الوظائف، ثم نقوم بتجميع الموجه الخاص بنا حتى نتمكن من رؤيته هنا موجهنا\nثم نعيد بث الإجابة أه نعم يدعم Supabase العمل عن بعد\nأم أن الاتصال عن بعد بالكامل سيحدث عبر الفيديو عبر البريد الإلكتروني يادا يادا وهذا هو بالضبط ذلك،\nلذا فإن هذا يعمل اه تمامًا كما هو متوقع، فلنلقي نظرة على كيفية\nالعمل الفعلي تعمل وظيفة الدردشة، لذا مرة أخرى، جوهر الأمر هنا نوعًا ما هنا\nفي chat dot TS نعم مرة أخرى، نوع من LangChain، أشياء مفتوحة AI، لدينا قالب موجه هنا،\nوبعد ذلك حصلنا على الملخص الخاص بنا وهنا باستخدام مساعدي المصادقة نحن نقوم بإنشاء\nعميل خادم الصفحات وهو نوع من موقع الخادم الذي يمكننا استخدامه لإجراء نوع من\nالاستعلامات المصادق عليها على الخادم ولذا فإننا نحصل للتو على\nعميل Supabase auth uh لذلك يأتي عميل المصادقة الخاضع للإشراف لدينا من هنا، نقوم بإنشاء\nعميل خادم الصفحات والرد على الطلبات والاستجابة لبعض\nالمعلومات في الوقت الفعلي، لذلك نقوم بتعطيل حد المعدل هنا، يمكننا القيام بذلك باستخدام علامة ناقص لذلك نريد فقط\nالبث إذا كان لدينا أي حق، فنحن قادمون، ثم نحصل على جلستنا، وإذا تمت مصادقتنا،\nفلدينا هنا إذا كانت لدينا جلسة يمكننا بعد ذلك إطلاقها والتعامل مع محادثتنا\nوما يحدث هنا، لذلك نحن نستخدم الآن وضع عدم الاتصال أولاً وقبل كل شيء للحصول على\nقناة في الوقت الفعلي بمعرف المستخدم، وهذا ما نستخدمه للاتصال بعميل الخادم\n، ثم نقوم أيضًا بإدخال [الموسيقى] الخاصة بنا،\nلذلك بدأنا بشكل أساسي خارج محادثة للذكاء الاصطناعي الذي يمنحنا معرف التفاعل حتى\nنتمكن من استخدام المعرف الفريد هنا، ثم نحصل على\nسجل المحادثة، لذا فهذا مجرد نوع من النظر إلى قاعدة البيانات الخاصة بنا حتى نتمكن من النظر إلى\nما نستطيع انظر إلى الاستوديو الخاص بنا، لدينا الآن في المحادثات لدينا هذه المعلومات من\nمستخدمنا السؤال والرد هنا، لذا فقد أجريت محادثة واحدة سابقًا\nتم تخزينها هنا ثم نقوم بتجميع سلسلة نماذج اللغة هذه باستخدام نوع من قالب المطالبة الخاص بنا\n، هذا هو قالب الاستعلام هنا نوعًا ما نظرًا لصياغة موجه المستخدم التالي\nوسجل المحادثة للاستجابة ذات الصلة، لذا فإن مطالبة المستخدم هي نوع من\nسجل محادثة الاستعلام ونحن نوعًا ما نعطيها مجموعة من الإرشادات هنا،\nها نحن ذا وبعد ذلك ما نفعله هو أننا نقوم بإنشاء قناة البث الخاصة بنا حتى نتمكن\nمن الاشتراك في القناة وبمجرد اشتراكنا، يمكننا إرسال بث\n، وها نحن الآن نرسل حسنًا، لقد بدأنا نحن نعثر على التطابقات، لذلك نحن هنا نقوم\nبالحصول على التطابقات من التضمينات، لذا فهذا نوع من سلسلة طويلة\nأو سلسلة ربط بالإضافة إلى ذلك، يقوم العميل الخاضع للإشراف بفتح تضمينات Ai ومتجر المتجهات\n، نحن نقوم فقط بالبحث عن تشابه متجرنا هنا، يمكنك البحث عن كل هذه المعلومات\nفي تفاصيل سلسلة الطول ولكن هذه هي الطريقة التي نجري بها نوعًا من البحث عن التشابه مع\nLangChain للعثور على المستندات ذات الصلة لمحادثتنا حتى نحصل على المطابقات الخاصة بنا من المطابقات التي لدينا\nبعد ذلك عناوين URL الخاصة بنا وقد رأيت أننا قمنا بتسجيل الخروج من عناوين URL هذه، ثم أخيرًا حصلنا\nعلى البيانات التعريفية المطابقة للحصول على النص وعناوين URL، ثم نقوم بشكل أساسي\nببناء نموذج المطالبة الخاص بنا مع الملخصات، لذلك هذا ما تعرفه من\nالتفاصيل الملخصة من مستنداتنا، السؤال المطروح من المستخدم، سجل المحادثة بالإضافة إلى\nعناوين URL، ثم نقوم فقط بإجراء محادثة AI نعم مفتوحة هنا باستخدام نموذج GPT 3.5 Turbo\nونقوم فقط بتجميع ذلك معًا هنا وبعد ذلك ما قمنا به ما نقوم به هو بمجرد حصولنا على أي تحديثات،\nلذا فهذه في الأساس طريقة عمل البث هنا، لذلك نقول إن البث صحيح وفي\nأي وقت نحصل فيه على نوع من الرمز المميز الجديد، فإننا نرسله عبر قناة البث الخاصة بنا\nوحيث نحصل عليها بعد ذلك من جانب العميل ثم في النهاية عندما\nتنتهي سلسلة LL amp بأكملها نوعًا ما، فإننا نقوم فقط بتحديث محادثتنا باستخدام معرف التفاعل\nفي قاعدة البيانات حتى يكون لدينا أيضًا إجابات من الذكاء الاصطناعي في سجل محادثتنا\n، نعم، هذا إلى حد كبير يمكننا إلقاء نظرة على الفهرس هنا، لذا في الفهرس الذي نستخدمه، تعلم\nأن هذا تم تقديمه من جانب العميل، لذلك نستخدم عميل متصفح Supabase uh هنا من مساعدو مصادقة Supabase\nاه وبعد ذلك نقوم بتجميعها معًا، حيث يمكننا الحصول عليها هنا، نعم،\nنحن نوعًا ما نقوم بتجميع المصادقة معًا باستخدام مكون المصادقة السطحي هنا وبعد ذلك لدينا\nمستمع القناة الخاص بنا، لذلك هذا هو يتم بث قناة Supabase الخاصة بنا في الوقت الفعلي، لذا عندما\nنحصل على حدث دردشة، فإننا نتحقق بشكل أساسي من موافق، هل هذا رد، وهذه رسالة حالة،\nآه، رد وماذا لديك، ثم نقوم فقط بتحديث رسالة chatbot الخاصة بنا، وهذا\nلطيف حول كيفية الحصول على نوع البث باستخدام Supabase في الوقت الفعلي لمعرفة حجم عملائنا، نعم،\nهذا إلى حد كبير، هذه هي الطريقة التي يمكنك من خلالها الحصول على جميع\nموفري الخدمة المختلفين مجمعين بشكل أساسي ضمن سرعة فائقة بحيث تكون هذه الوظيفة متاحة إذا أنت\nمهتم بالبناء باستخدام um Supabase أه مع المزيد باستخدام next.js، المزيد من أنواع تطبيقات الذكاء الاصطناعي،\nلدينا بحث xjs openai doc وهذا يستخدم في الواقع umversal umversal AI SDK، لذا\nإذا كنت مهتمًا، فأنت تعرف ذلك النوع حول كيفية عمل ذلك، يمكنك إلقاء نظرة على هذا هنا ولدينا أيضًا\nشرح فيديو لهذا، لذا شكرًا جزيلاً على متابعتك ورؤيتك في الفيديو\nالأجنبي التالي"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "bn",
        "plaintext": "আরে আজ আমরা সুপাবেস\nভেক্টর ব্যবহার করে next.js এবং LangChain এর সাথে একটি চ্যাটবট তৈরির দিকে নজর দিচ্ছি তাই এখন আমরা আমাদের নথির সাথে চ্যাট করতে পারি তাই হয়ত আমরা জিজ্ঞাসা করি যে সুপাবেস কি দূরবর্তী কাজের\nপ্রশ্ন চিহ্নের অনুমতি দেয় তাই আমরা এখন এটি বন্ধ করে দিচ্ছি আবার মিলগুলি খুঁজে পাচ্ছি এবং আমরা এখানে দেখতে পাচ্ছি\nতাই আমরা আমাদের মিলগুলি খুঁজে পেয়েছি এই দুটি উম সুপাবেস চাকরির পোস্টিং এবং তারপরে এখন নথিটি\nখুব দীর্ঘ তাই আমরা দুটি চাকরির পোস্টিং থেকে তথ্য সংক্ষিপ্ত করছি এবং তারপরে আমরা\nএকসাথে রাখছি আমাদের উম প্রম্পট তাই উম আমরা এখানে আমাদের প্রম্পট দেখতে পারি এবং তারপর আমরা উত্তরটি স্ট্রিম করছি\nউহ হ্যাঁ সুপাবেস দূরবর্তী কাজকে সমর্থন করে এখন এই ডেমোটি পাইনকোন উহ চ্যাটবট ডেমোর একটি কাঁটা\nএবং এটি এখানে উহ রায়ের সত্যিই দুর্দান্ত কাজ\nআপনি ব্লগ পোস্টটি পড়তে পারেন আমি এটির নিচে লিঙ্ক\nকরব এখানে চেষ্টা করার জন্য সুপাবেসে\nতৈরি করা ক্ষমতাগুলির সাথে এই উহ পার্থক্য পরিষেবাগুলির অনেকগুলি প্রতিস্থাপন করার জন্য সাজানো\nহয়েছে তাই আমরা পাইনকোনের পরিবর্তে সুপাবেস ভেক্টর ব্যবহার করছি এর পরিবর্তে আমরা\nতেলাপোকার পরিবর্তে সুপাবেস রিয়েল টাইম ব্যবহার করছি পোস্টগ্রেস ডাটাবেস যা\nসুপাবেস স্ট্যাকের সাথে আসে এবং তারপরে ফিঙ্গারপ্রিন্টের পরিবর্তে আমরা সুপাবেস প্রমাণীকরণ ব্যবহার করছি তাই এই সমস্ত পরিষেবাগুলি\nআমরা এটিকে কেবল সুপাবেসে ফুটিয়ে তুলছি এবং\nস্থাপত্যের পরিপ্রেক্ষিতে এখানে next.js এর সাথে AI um খুলছি চ্যাটবট উম আমাদের কাছে দুটি উপাদান রয়েছে তাই আমাদের কাছে একটি ইনডেক্সার\nউম রয়েছে যা um এম্বেডিং লিখছে যা সত্যের নিজের থেকে এম্বেডিং তৈরি করে\nএখানে তাই আমরা ইনডেক্সারটি দেখতে পারি তাই আমাদের সত্যের উত্স রয়েছে যা আমরা কিছু ওয়েবসাইট\nওয়েবসাইট থেকে সেই তথ্য পাওয়ার জন্য একটি ক্রলার আছে এবং তারপরে ল্যাংচেইন এবং ওপেন এআই ব্যবহার করে\nআমরা আমাদের এম্বেডিং তৈরি করছি এবং তারপরে সেগুলিকে আমাদের সুপাবেস ভেক্টরে সংরক্ষণ করছি এবং\nতারপরে যখন আমরা আমাদের ধরণের সত্যের সাথে চ্যাট করতে চাই তখন মূলত আমরা গ্রহণ করি ব্যবহারকারীর ক্যোয়ারী\nআবার আমরা সেই ক্যোয়ারী থেকে একটি এমবেডিং তৈরি করি তারপর আমরা প্রাসঙ্গিক উম ধরণের সত্যের উত্স খুঁজে পেতে সমস্ত নথির মাধ্যমে অনুসন্ধান করি\nযা আমরা প্রাসঙ্গিক ইউআরএলগুলির ধরণের সূচী করি\nআমরা সেই URLগুলি থেকে সেই বিষয়বস্তুর সংক্ষিপ্তসার করি এবং তারপরে কোথায় আমরা তত্ত্বাবধানে থাকা রিয়েল টাইম ব্যবহার করে ব্যবহারকারীর কাছে এক ধরনের প্রতিক্রিয়া তৈরি করছি এবং\nস্ট্রিমিং করছি এখন ল্যাংচেইনের সবচেয়ে বড় বিষয় হল\nএটি সুপাবেস ভেক্টরের জন্য অন্তর্নির্মিত সমর্থন রয়েছে তাই আমরা যেভাবে এটি করতে পারি তা হল আমরা\nএই স্কিমাটি নিতে পারি এখানে এবং ভেক্টর এক্সটেনশন ব্যবহার করে আমাদের ডাটাবেসে এটি প্রয়োগ করুন এবং তাই আপনি যদি\nএখানে ক্লোন করেন তবে এই লিঙ্ক চেইন চ্যাটবট ডেমোটি ক্লোন করুন নীচের বর্ণনাটিতে\nআমরা এটিকে বনাম কোডে খুলতে পারি এবং আমরা তা দেখতে পারি। আমাদের\nএখানে কিছু মাইগ্রেশন আছে তাই এগুলি হল প্রাথমিক মাইগ্রেশন যা আমরা প্রয়োগ করি যখন আমরা একটি সুপাবেস স্টার্ট চালাই\nযাতে আমরা আমাদের স্থানীয় স্ট্যাক শুরু করতে এখানে সুপাবেস স্টার্ট চালাতে পারি আমার কাছে এটি ইতিমধ্যেই চলছে তাই আমি\nস্থানীয় ধরনের দেখতে তত্ত্বাবধানে স্থিতি চালাতে পারি শংসাপত্র এবং যদি আমি এটি এখানে খুলি\nযাতে আমরা দেখতে পারি যে আমরা লিঙ্ক চেইন ডকুমেন্টেশন থেকে এটি কপি করেছি তাই এটিই\nআমাদের সুপাবেস ভেক্টর আমাদের নথি তৈরি করতে সক্ষম করে তাই মূলত ল্যাংচেইন ফ্রেমওয়ার্ককে\nসুপাবেস ভেক্টরের সাথে কাজ করে এবং তারপর একটি জিনিস যা আমি এখানে বিশেষভাবে যোগ করেছি\nপ্রমাণীকৃত ব্যবহারকারীদের জন্য সর্বজনীন নথিতে অনুসন্ধানের অনুমতি দেওয়ার ক্ষমতা তাই এটি এখানে সারি স্তরের নিরাপত্তা নীতিগুলি ব্যবহার করছে\nএবং তাই আমরা কেবলমাত্র ক্লায়েন্ট পক্ষ থেকে প্রমাণীকৃত ব্যবহারকারীদের জন্য অনুসন্ধানের অনুমতি দিতে চেয়েছিলাম\nআমরা কি উদাহরণ স্বরূপ এটিকে অনুমতি দিতে পারি এবং অন্যথায় এটি\nএখানে একই রকম যা এখানে ভূমিকা স্তরের সুরক্ষায় যোগ করা হয়েছে এবং তারপরে আমরা\nকথোপকথনগুলি সংরক্ষণ করছি যাতে মূলত উম আপনি পাঠ্য সাজানোর বিষয়টি জানেন যেটি\nচ্যাটে টাইপ করা হয়েছিল এবং তারপরে এআই কী উত্তর দিয়েছে তাই আমরা বিভ্রান্তিকর এবং এআই চ্যাটবট\nকথোপকথনগুলি সংরক্ষণ করছি সেইসাথে আমরা চ্যাটের ইতিহাস মনে রাখতে চাই এবং আমরা\nসেই চ্যাটের ইতিহাসটিকেও ইনজেক্ট করছি পূর্ববর্তী কথোপকথনের ইতিহাস সম্পর্কেও উম ধরনের জানার জন্য অনুরোধ করুন\nএবং আবার আমরা এখানে একটি ভূমিকা স্তরের নিরাপত্তা নীতি প্রয়োগ করছি বিশেষ করে যে শুধুমাত্র\nব্যবহারকারীরা তাদের নিজস্ব উম ধরনের কথোপকথন দেখতে পাবেন যা আপনি চ্যাটবটের সাথে জানেন\nআহ তাই আমরা এখানে তথ্যের ধরনের লক ডাউন করছি ঠিক আছে চমৎকার তাই আসুন আমরা আসলে এক নজর দেখি\nউম আমরা এটি চালাতে পারি যাতে আমরা বলতে পারি এনপিএম রান ডিএফ তাই প্রথমে আপনি জানেন যে আমরা\nস্থানীয়ভাবে সুপাবেস চালাচ্ছি এবং তারপরেও আমাদের আছে উহ চ্যাট বট এখানে স্থানীয়ভাবে চলছে এবং এটি\nসুপাবেস প্রমাণের সাথে আসে তাই এটি আসলে প্রতিক্রিয়া করার জন্য প্রমাণীকরণ UI কিন্তু তারপরে প্রথমে আমরা\nকিছু তথ্য ক্রল করতে চাই এবং আপনি এখানে জানেন উদাহরণস্বরূপ আমরা নিয়োগ করছি যদি আপনি না জানেন\nআপনি সুপাবেস ক্যারিয়ারগুলি পরীক্ষা করে দেখতে পারেন উদাহরণস্বরূপ আমরা গ্রাহকদের জন্য নিয়োগ করছি সলিউশন আর্কিটেক্ট\nএবং এটি হল পুরো কাজের বিবরণ এখানে সেখানে অনেক তথ্য রয়েছে যা আপনি\nজানেন যে কোম্পানিতে 100 শতাংশ দূরবর্তী কাজ উম ESOP ইক্যুইটি মালিকানা উম হ্যাঁ টন\nস্টাফ তাই আপনি জানেন আসুন আমাদের জীবনকে আরও সহজ করে তুলি এবং আসুন আসলে এটি ক্রল করি যাতে API স্ল্যাশ ক্রল\nউম আমরা এখানে আমাদের কাজের বিবরণ ক্রল করতে পারি এবং আমরা যা দেখতে পারি তা হল এখন আমরা ক্রল করছি um আমাদের চপস এবং\nআমরা ক্রল করছি তাই ক্রলার ধরনের একটি পুনরাবৃত্ত জিনিস একটি বিট করে যেখানে এটি\nউম উহ পৃষ্ঠাগুলিকে ক্রল করে যেগুলি এটিতে সংযুক্ত um ধরনের এবং তারপর আমরা দেখতে পারি ঠিক আছে এটি এখন হয়ে গেছে\nতাই আমরা এখন দেখতে পারি যদি আমরা সেখানে যাই সুপাবেস স্টুডিও এখানে তাই আমাদের কাছে আবার লোকালহোস্ট আছে\nযদি আপনি মনে না করেন যে আমরা একটি তত্ত্বাবধানে শুরু করার পরে আমরা সুপাবেস স্ট্যাটাস করতে পারি আমরা\nএখানে আমাদের স্থানীয় বিবরণ পেতে পারি এবং তাই আমরা এখানে স্থানীয়ভাবে এই প্রকল্পটি খুলতে পারি এবং আমরা\nএখন দেখতে পারি আমাদের কথোপকথন আছে তাই আমাদের এখনও কোনো কথোপকথন নেই কিন্তু এখানে আমাদের\nনথি রয়েছে তাই এটি হল যা আমরা ক্রল করেছি উহ এখানে আমাদের ভেক্টর এম্বেডিং আছে এবং আপনি\nকোডের লাইনগুলি দেখতে পারেন উম লাইন নয় কোডের তাই কিছু মেটাডেটাও আছে এবং\nএগুলি লাইনগুলির মতো তাই নথিগুলিকে বিভিন্ন বিভাগে ভাগ করা হয় তাই\nউম মেটাডেটা ব্যবহার করে আমরা তারপর কিছু ফিল্টারিং করতে পারি যাতে\nপোস্টগ্রেসে সত্যিই শক্তিশালী যেখানে আমাদের Json আছে B ডেটা টাইপ তাই আমরা Json ডকুমেন্টের সম্পূর্ণ সাজানোর জন্য\nউম এ ড্রপ করতে পারি আপনি জানেন যে আপনি এখানে আমাদের নথিগুলিকে মেটাডেটা হিসাবে দুর্দান্ত হিসাবে জানেন তাই এখন আমরা এটি ক্রল করেছি\nআমাদের ডাটাবেসে রয়েছে তাই এখন আমরা যা করতে পারি তা হল আসলেই আছে সেই ক্রলারটি কীভাবে কাজ করেছে তা\nআমাদের পেজ এপিআই-এ রয়েছে এবং তারপরে এখানে ক্রল করুন তাই আমরা লেংথ চেইন ব্যবহার করছি আমরা\nল্যাংচেইন থেকে আমাদের ওপেনাই এম্বেডিং ব্যবহার করছি এবং তারপরে আমরা সুপাবেস ভেক্টর স্টোর ব্যবহার করছি তাই এটি সত্যিই ঝরঝরে\nসুপাবেস ভেক্টর স্টোরের সাথে এক ধরণের দৈর্ঘ্যের চেইন একত্রিত করা হয় এবং তারপরে সত্যই উহ যে\nক্যোয়ারী থেকে আমরা সেই URLগুলি পাচ্ছি যা আমরা um সূচী করতে চাই um আমরা এক ধরণের\nনথি সংগ্রহ তৈরি করছি তাই আমরা বিভক্ত করছি এম্বেডিং তৈরি করার জন্য\nআমাদের কাছে um ধরনের সঠিক মাপ আছে তা নিশ্চিত করার জন্য আমরা যাতে টোকেন সাইজ\nউম স্প্লিটিং ডকুমেন্টের বাইরে চলে না যাই এবং তারপরে আমরা আমাদের তৈরি করছি এমবেডিং তাই ওপেন এআই\nএমবেডিং আমরা আমাদের সুপাবেস ভেক্টর স্টোর তৈরি করছি শুধু এখানে একটি সুপাবেস অ্যাডমিন ক্লায়েন্ট রাখছি\nতাই সুপাবেস অ্যাডমিন ক্লায়েন্ট এখানে উম ব্যবহার করে আমরা দেখতে পাচ্ছি যে এটি প্রাইভেট কী ব্যবহার করে যা\nআমাদের এখানে আমাদের পরিষেবা ভূমিকা কী এবং তারপর আমরা পারি প্রশাসক ক্রিয়াকলাপগুলি সম্পাদন করুন যা\nএই নথিগুলিকে সন্নিবেশ করাচ্ছে এবং তাই আমরা তখন উম হ্যাঁ আমাদের নথি সংগ্রহে এক ধরণের তৈরি করছি এবং\nসমস্ত নথি সংরক্ষণ করার ধরণের যোগ করছি এবং তারপরে আমাদের এখানে আমাদের ডাটাবেসে নথি রয়েছে\nএবং তারপরে আমরা অনুসন্ধান করতে পারি তাদের উপর তাই আসুন এটিতে যাই তাই প্রথমে আমাদের লগ\nইন করতে হবে তাই বর্তমানে যদি আমরা আমাদের প্রকল্পটি এখানে দেখি তাহলে আমরা আবার লোকালহোস্টে চলছি আমরা\nস্থানীয়ভাবে পুরো সুপাবেস স্ট্যাকটি চালাচ্ছি এবং আমরা ডন 'এখনও কোনো ব্যবহারকারী নেই তাই আসুন\nএখানে টেস্ট ডট ডি এবং um-এ একটি নতুন ব্যবহারকারী পরীক্ষক সাইন আপ করি তাই যদি আমরা বলি সাইন ইন um আমরা জানি না আপনি অবৈধ\nপ্রমাণপত্রাদি জানেন কারণ আমরা নেই তাই আসুন সাইন আপ করি এবং তারপরে আমাদের করতে হবে কথোপকথনের লিঙ্কের জন্য আমাদের ইমেল চেক করুন\nএখন আমরা লোকালহোস্টে চলছি তাই আমরা এখানে প্রকৃত ইমেল পাঠাচ্ছি না\nকিন্তু আমরা যা করতে পারি তা হল আমাদের বালতিতে বলা পরিষেবাটি রয়েছে যা সত্যিই একটি দুর্দান্ত ওপেন\nসোর্স পরিষেবা এবং পাশাপাশি আমরা এখানে দেখতে পাচ্ছি যে আমাদের কাছে আপনার ইমেলটি নিশ্চিত করা হয়েছে তাই এটি\nএইমাত্র পাঠানো হয়েছে এবং আমরা আমাদের ইমেল ঠিকানাটি ক্লিক করে নিশ্চিত করতে পারি এবং এখন আমরা দেখতে পাচ্ছি যে আমরা লক হয়ে গেছি\nউম আমাদের অ্যাপ্লিকেশনটি এখানে আমি লোকালহোস্টে চালাচ্ছি তাই এখন আমরা আমাদের নথিগুলির সাথে চ্যাট করতে পারি তাই হয়ত\nজিজ্ঞাসা করা যাক সুপাবেস কি দূরবর্তী কাজের প্রশ্ন চিহ্নের অনুমতি দেয় তাই আমরা এখন এটি বন্ধ করে দিচ্ছি উম আমরা\nম্যাচগুলি খুঁজে পাচ্ছি এবং আমরা এখানে দেখতে পাচ্ছি তাই আমরা আমাদের মিল খুঁজে পেয়েছি এই দুটি উম সুপাবেস চাকরির\nপোস্টিং এবং তারপরে এখন নথিটি খুব দীর্ঘ তাই আমরা\nদুটি চাকরির পোস্টিং থেকে তথ্যের সংক্ষিপ্তসার করছি এবং তারপরে আমরা আমাদের উম প্রম্পট একসাথে রাখছি যাতে আমরা এখানে দেখতে পারি আমাদের প্রম্পট\nএবং তারপরে আমরা উত্তরটি স্ট্রিম করছি উহ হ্যাঁ সুপাবেস দূরবর্তী কাজকে সমর্থন করে\nউম সম্পূর্ণভাবে দূরবর্তী যোগাযোগ ইমেল ভিডিওর মাধ্যমে ঘটবে ইয়াদা ইয়াদা এবং এটি ঠিক তাই\nউম তাই এটি সম্পূর্ণভাবে প্রত্যাশিত হিসাবে কাজ করছে চলুন দেখে নেওয়া যাক কিভাবে\nউম আসল চ্যাট\nকার্যকারিতা আবার কাজ\nকরছে আমরা একটি পেজ সার্ভার ক্লায়েন্ট তৈরি করছি\nযা আমাদের ক্লায়েন্টের মতো একটি সার্ভার সাইট যা আমরা\nসার্ভারে প্রমাণীকৃত প্রশ্নগুলি সম্পাদন করতে ব্যবহার করতে পারি এবং তাই আমরা শুধু আমাদের Supabase auth uh\nক্লায়েন্ট পাচ্ছি যাতে আমাদের তত্ত্বাবধানে auth ক্লায়েন্ট আসছে এখান থেকে নিচে থেকে তাই আমরা উম উহ পৃষ্ঠা তৈরি করছি\nসার্ভার ক্লায়েন্ট উহ অনুরোধ এবং প্রতিক্রিয়া কিছু রিয়েল-টাইম\nতথ্য রাখছি তাই আমরা এখানে হারের সীমা নিষ্ক্রিয় করছি আমরা তা বিয়োগ এক দিয়ে করতে পারি তাই আমরা শুধু\nস্ট্রিম করতে চাই কোন ধরনের অধিকার আমরা আসছি তারপর আমরা আমাদের অধিবেশন পাচ্ছি এবং যদি আমরা\nপ্রমাণীকৃত হয়ে থাকি তাহলে আমাদের এখানে আছে যদি আমাদের একটি অধিবেশন থাকে তাহলে আমরা গুলি চালাতে পারি এবং আমাদের চ্যাট\nওম পরিচালনা করতে পারি এবং এখানে যা ঘটছে তাই আমরা করছি এখন ব্যবহারকারী আইডি সহ একটি রিয়েল-টাইম চ্যানেল পেতে প্রথমে আমাদের অফলাইন ব্যবহার করছি\nযাতে আমরা সার্ভার ক্লায়েন্ট কমিউনিকেশনের জন্য এটিই ব্যবহার করছি\nতারপর আমরা আমাদের [মিউজিক] উম কমিউনিকেশনও সন্নিবেশ করছি\nতাই মূলত আমরা শুরু করছি AI এর জন্য একটি কথোপকথন বন্ধ যা আমাদের একটি ইন্টারঅ্যাকশন আইডি দেয় যাতে\nআমরা এখানে uid ব্যবহার করতে পারি এবং আমরা তারপর কথোপকথন\nউম লক হিস্ট্রি পাচ্ছি যাতে এটি আমাদের ডাটাবেসের দিকে তাকিয়ে থাকে যাতে আমরা দেখতে\nপারি আমাদের স্টুডিওর দিকে তাকান তাই এখানে আমরা এখন কথোপকথনে\nআমাদের ব্যবহারকারীর কাছ থেকে এই তথ্যটি প্রশ্ন এবং প্রতিক্রিয়া এখানে পেয়েছি\nতাই আমি ইতিমধ্যেই একটি কথোপকথন করেছি যা এখানে সংরক্ষিত ছিল তারপর আমরা একসাথে এই ভাষা মডেল চেইনটি ব্যবহার করছি আমাদের\nপ্রম্পট টেমপ্লেট এটি এখানে অনুসন্ধানের টেমপ্লেট যা নিম্নোক্ত ব্যবহারকারীর প্রম্পট\nএবং কথোপকথনের লগ প্রদত্ত প্রাসঙ্গিক প্রতিক্রিয়া তৈরি করে তাই ব্যবহারকারীর প্রম্পটটি ক্যোয়ারী কথোপকথনের ইতিহাসের এক প্রকার\nএবং আমরা এটিকে এখানে একগুচ্ছ নির্দেশনা দিচ্ছি\nএবং তারপরে আমরা যা করছি তা হল আমরা আমাদের ব্রডকাস্ট চ্যানেল তৈরি করছি যাতে আমরা\nচ্যানেল সাবস্ক্রাইব করতে পারি এবং মূলত একবার আমরা সাবস্ক্রাইব করার পরে আমরা একটি সম্প্রচার পাঠাতে পারি\nএবং তাই এখানে আমরা এখনই পাঠাচ্ছি ঠিক আছে আমরা শুরু করছি 'মিলগুলি খুঁজে পাচ্ছি তাই এখানে আমরা\nএমবেডিং থেকে আমাদের ম্যাচগুলি করছি তাই এটি একটি দৈর্ঘ্যের চেইন\nউম লিঙ্ক চেইন এবং সেইসাথে তত্ত্বাবধান করা ক্লায়েন্ট ওপেন এআই এমবেডিং এবং ভেক্টর স্টোর\nউম আমরা কেবল আমাদের স্টোরের মিল অনুসন্ধান করছি এখানে তাই সেই সমস্ত তথ্য যা আপনি\nদৈর্ঘ্যের চেইনের বিশদ বিবরণের মাধ্যমে খনন করতে পারেন তবে এইভাবে আমরা আমাদের চ্যাটের প্রাসঙ্গিক নথিগুলি খুঁজে পেতে LangChain-এর সাথে আমাদের মিল অনুসন্ধান করছি\nযাতে আমরা তখন আমাদের ম্যাচগুলি থেকে আমাদের মিলগুলি পেতে পারি\nআমাদের ইউআরএল এবং আমরা দেখেছি আমরা কনসোল সেই ইউআরএলগুলি লগ আউট করেছি এবং তারপরে শেষ পর্যন্ত আমরা\nমেটাডেটা মেটাডেটা টেক্সট এবং ইউআরএল পেতে যাচ্ছি এবং তারপরে আমরা মূলত\nসারাংশ সহ আমাদের প্রম্পট টেমপ্লেট তৈরি করছি যাতে আপনি জানেন আমাদের নথিগুলি থেকে সংক্ষিপ্ত বিবরণের মধ্যে\nব্যবহারকারীর কাছ থেকে কথোপকথনের ইতিহাসের সাথে সাথে\nURL-এর প্রশ্ন এবং তারপরে আমরা এখানে জিপিটি 3.5 টার্বো মডেল\num ব্যবহার করে আমাদের উম হ্যাঁ ওপেন এআই চ্যাট করছি এবং এটি এখানে একসাথে রাখছি এবং তারপরে আমরা কী করব আমরা যখন কোন আপডেট পেয়ে থাকি তখনই um হয়\nতাই মূলত এখানে স্ট্রিমিং কিভাবে কাজ করে তাই আমরা বলছি স্ট্রিমিং সত্য এবং\nযে কোন সময় আমরা একটি নতুন টোকেন পাচ্ছি আমরা তারপর আমাদের সম্প্রচার চ্যানেলের মাধ্যমে এটি পাঠাচ্ছি\nএবং যেখানে আমরা এটিকে ক্লায়েন্টের দিকে নিয়ে যাই এবং তারপরে যখন um পুরো LL amp চেইনটি শেষ\nহয়ে যায় তখন আমরা ডাটাবেসের ইন্টারঅ্যাকশন আইডি দিয়ে আমাদের কথোপকথন আপডেট করি\nযাতে আমাদের কাছেও থাকে আমাদের কথোপকথনের লগে AI থেকে উত্তরগুলি\nউম হ্যাঁ আমরা এখানে সূচকটি দেখতে পারি তাই আমরা যে সূচীটি ব্যবহার করছি তা আপনি জানেন\nযে এটি ক্লায়েন্ট-সাইড রেন্ডার করা হয়েছে তাই আমরা এখানে সুপাবেস উহ ব্রাউজার ক্লায়েন্ট ব্যবহার করছি সুপাবেস\nপ্রমাণীকরণ সহায়ক উহ এবং তারপরে মোটামুটি আমরা একসাথে রাখছি উম আমাদের এখানে এটি কোথায় আছে হ্যাঁ\nআমরা এখানে সুপারফেস প্রমাণীকরণ উপাদান ব্যবহার করে উম পুটিং auth একসাথে রাখছি এবং তারপরে আমাদের\nচ্যানেল শ্রোতা রয়েছে তাই এটি হল আমাদের সুপাবেস উহ রিয়েল-টাইম চ্যানেল সম্প্রচারিত তাই যখন\nআমরা একটি চ্যাট ইভেন্ট পাই তখন আমরা মূলত ঠিক আছে চেক করি এটি কি একটি প্রতিক্রিয়া এটি একটি স্ট্যাটাস বার্তা\nউহ প্রতিক্রিয়া এবং আপনার কাছে কী আছে এবং তারপরে আমরা কেবল আমাদের চ্যাটবট বার্তা আপডেট করি এবং তাই এটি\nসদয় আমরা কীভাবে সুপাবেস রিয়েল টাইম ব্যবহার করে আমাদের ক্লায়েন্টের আকার উম করার জন্য স্ট্রিমিং ধরনের পেতে পারি হ্যাঁ\nউম এটি মোটামুটি এটি উম এইভাবে আপনি এই ধরণের সমস্ত বিভিন্ন পরিষেবা\nসরবরাহকারীকে মূলত উহ সুপার পেসের মধ্যে বান্ডিল পেতে পারেন যাতে কার্যকারিতা পাওয়া যায় যদি আপনি\nউম সুপাবেস উহ এর সাথে নেক্সট.জেএস এর সাথে আরও অনেক ধরণের এআই অ্যাপ্লিকেশন তৈরি করতে আগ্রহী\nসেখানে আমাদের কাছে একটি এক্সজেএস ওপেনই ডক সার্চ রয়েছে এবং এটি আসলে um versal um versal AI SDK ব্যবহার করে তাই\nআপনি যদি আগ্রহী হন তবে আপনি জানতে চান এটি কীভাবে কাজ করে আপনি এখানে এটি দেখতে পারেন এবং আমাদের\nকাছে এটির জন্য একটি ভিডিও ব্যাখ্যা রয়েছে তাই টিউন করার জন্য অনেক ধন্যবাদ এবং পরের ভিডিও\nবিদেশীতে দেখা হবে"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "zh",
        "plaintext": "嘿，今天我们正在考虑使用 Supabase\nVector 使用 next.js 和 LangChain 构建一个聊天机器人，所以现在我们可以与我们的文档聊天，所以也许让我们问一下 Supabase 是否允许远程工作\n问号，所以我们现在将其关闭，嗯，我们'正在寻找匹配项，我们可以在这里看到，\n所以我们找到了匹配项，这是两个 um Supabase 职位发布，然后现在文档\n太长，所以我们正在总结 um 两个职位发布的信息，然后我们将其放在\n一起我们的嗯提示所以嗯我们可以在这里看到我们的提示呃然后我们流回答案\n呃是的Supabase现在支持远程工作这个演示是Pinecone呃聊天机器人\n演示的一个分支，这真的是呃Roy在这里的很棒的工作你可以阅读博客文章，我将在下面链接它，\n嗯，这是在 next.js 中使用链接链 JS 构建多用户聊天机器人的概念，\n嗯，它有几个组件，但最重要的是，我想要什么这里尝试用\nSupabase 内置的功能来替换很多这些呃差异服务，\n所以我们使用 Supabase Vector 代替 Pinecone，而不是巧妙地\n使用 Supabase 实时代替 cockroachdb，我们使用的是与 Supabase 堆栈一起提供的 postgres 数据库\n，然后我们使用 Supabase 身份验证而不是指纹，因此\n我们将所有这些服务归结为 Supabase 并使用 next.js 开放 AI 嗯，现在就\n架构而言聊天机器人我们有两个组件，所以我们有一个索引器，\n它可以写入嵌入，从我们自己的真理中生成嵌入，\n这样我们就可以查看索引器，这样我们就有了真理的来源，这是我们的一些网站有\n一个爬虫从网站上获取信息，然后使用 LangChain 和开放人工智能\n生成我们的嵌入，然后将它们存储在我们的 Supabase 向量中，\n然后当我们想要与我们的真相本身聊天时，基本上我们会采取 再次 用户查询\n，我们根据该查询创建一个嵌入，然后搜索所有文档，\n找到我们索引的相关 URL 类型的相关事实来源，\n我们总结该 URL 中的内容，然后在哪里我们正在生成某种响应，并\n使用监督实时将其流式传输回用户，现在 LangChain 的伟大之处\n在于它内置了对 Supabase Vector 的支持，所以我们可以做到这一点的方法是我们可以采用\n这个模式在这里并使用矢量扩展将其应用到我们的数据库，因此，如果您克隆\n到这里，克隆到这个链接链聊天机器人演示，URL 也在下面的描述中，\n然后我们可以在 VS Code 中打开它，例如，我们可以看一下我们\n在这里有一些迁移，所以这些是我们在运行 Supabase start 时应用的初始迁移，\n这样我们就可以在此处运行 Supabase start 来启动我们的本地堆栈我已经运行了它，所以我\n可以运行受监督状态来查看本地堆栈的类型如果我在这里打开它\n，我们可以看到我们刚刚从链接链文档中复制了它，这就是\n我们的 Supabase Vector 创建文档的原因，所以基本上使 LangChain 框架\n与 Supabase Vector 一起工作，然后是一件事我在这里特别添加的\n是允许对经过身份验证的用户查询公共文档的能力，因此\n这里使用呃行级安全策略，所以我们只想允许嗯\n从客户端查询经过身份验证的用户例如，我们可以允许这样吗？否则，\n这里的情况与这里的情况相同，这是在此处的角色级别安全性中添加的，然后我们也\n存储对话，这样基本上嗯，您知道文本排序输入到聊天中的内容\n，然后是人工智能回复的内容，因此我们存储混淆者和人工智能聊天机器人的\n对话，并且我们想要记住聊天的历史记录，我们还将\n该聊天历史记录注入到提示还了解之前对话的历史记录\n，我们再次在这里应用某种角色级别的安全策略，特别是只有\n用户才能看到他们自己的对话，你知道与聊天机器人的对话\n呃，所以我们在这里锁定了一些信息，好吧，太好了，让我们实际看一下，\n我们可以运行它，这样我们就可以说 npm run def 所以首先你知道我们有 Supabase\n在本地运行，然后我们也有我们的呃，这里的聊天机器人在本地运行，它\n带有 Supabase 身份验证，所以这实际上是用于 React 的身份验证 UI，但首先我们要\n抓取一些信息，您知道这里，例如，如果您不知道，我们正在招聘\n你可以查看 Supabase 的职业，例如我们正在为客户招聘解决方案架构师\n，这是整个职位描述，里面有很多你\n知道的信息，比如 100% 远程工作，公司的 ESOP 股权，嗯，是的，很多\n东西所以你知道让我们让我们的生活更轻松呃让我们实际爬行这个所以API斜线爬行\n嗯我们可以在这里爬行我们的工作描述我们可以看到现在我们正在爬行我们的印章\n我们也在爬行所以爬虫类型of 做了一些递归的事情，它抓取了\n嗯嗯页面，这些页面也有链接嗯，然后我们可以看到，现在已经完成了嗯，\n所以如果我们转到Supabase Studio 在这里，所以我们再次拥有本地主机，\n如果您不记得，我们可以在运行监督启动后执行 Supabase 状态，我们\n可以在此处获取本地详细信息，因此我们可以在本地打开此项目，\n现在我们可以查看我们已经进行了对话，所以我们还没有任何对话，但是这里有我们的\n文档，所以这就是我们爬行的内容，这里我们有向量嵌入，你\n可以看到一些代码行，而不是行代码，所以还有一些元数据，\n这些都是行，所以文档被分解成不同的部分，所以\n嗯，使用元数据，然后我们可以执行一些过滤，这\n在我们有 Json 的 postgres 中非常强大 B 数据类型，这样我们就可以将完整类型的 Json 文档放入\n嗯，你知道你知道我们这里的文档，就像元数据一样，所以现在我们已经爬取了它，我们将\n其存储在我们的数据库中，所以现在我们能做的就是让我们实际拥有看看爬虫是如何工作的，\n这是在我们的 Pages API 中，然后爬到这里，所以我们使用长度链，我们使用\nLangChain 的 openai 嵌入，然后我们使用 Supabase Vector 存储，所以这对于\n一种长度链与 Supabase Vector 存储集成，然后实际上只是\n从查询中获取我们想要索引的 URL，我们正在创建某种\n文档集合，因此我们正在拆分确保我们有 um 类型的正确\n的大小 um 来创建嵌入，这样我们就不会用完\n此处的令牌大小 um 拆分排序的文档，然后我们正在创建我们的嵌入如此开放的人工智能\n嵌入，我们正在创建我们的 Supabase Vector 存储，只需在此处放入 Supabase 管理客户端，\n以便 Supabase 管理客户端仅使用 um ，我们可以看到它使用私钥，这是\n我们的服务角色密钥，然后我们可以执行某种管理操作，即\n插入这些文档，然后我们在文档集合中创建某种形式，\n添加存储所有文档的形式，然后我们将这些文档存储在数据库中\n，然后我们可以执行搜索所以让我们回顾一下，首先我们需要登录\n所以目前如果我们在这里查看我们的项目，那么我们再次在本地主机上运行，​​我们正在\n本地运行整个呃Supabase堆栈，我们不还没有任何用户，所以让我们\n在测试点 de 和 um 注册一个新的用户测试人员，所以如果我们说登录，我们不知道无效的\n凭据，因为我们还没有，所以让我们注册，然后我们需要检查我们的电子邮件中的\n对话链接，现在我们在本地主机上运行，​​所以我们不会在这里发送实际的呃电子邮件，\n但我们能做的是我们在存储桶中调用了该服务，这\n也是一个非常非常酷的开源服务，我们可以在这里看到我们确认了您的电子邮件，所以这封邮件是刚刚\n发送的，我们可以单击并确认我们的电子邮件地址，现在我们可以看到我们已被锁定\n嗯，我们的应用程序在这里，我在本地主机上运行，​​所以现在我们可以与我们的文档聊天，所以也许\n让我们问一下 Supabase 是否允许远程工作问号，所以我们现在将其关闭，嗯，我们正在找到\n匹配项，我们可以在这里看到，所以我们找到了我们的匹配项，这些是这两个 um Supabase 职位\n发布呃，然后现在文档太长了，所以我们正在总结 um\n两个职位发布的信息，然后我们将我们的 um 提示放在一起，所以 um 我们可以在这里看到我们的提示\n，然后我们将返回答案呃是的 Supabase 支持远程工作\n嗯完全远程通信将通过电子邮件视频yada yada 进行，这正是\n嗯所以这完全按预期工作嗯让我们看看\n实际情况如何聊天功能又开始工作了，嗯，它的核心是\n在聊天点 TS 中，是的，嗯，类似 LangChain 嗯，开放人工智能，我们这里有一个提示模板，\n嗯，然后我们有我们的摘要器，在这里使用身份验证助手我们正在创建一个 Pages\n服务器客户端，它是我们的客户端的服务器站点，我们可以使用 它在服务器上\n执行某种 经过身份验证的查询，因此我们刚刚获得 Supabase 身份验证\n客户端，因此我们的受监督身份验证客户端即将到来从这里开始，我们正在创建\n嗯嗯页面嗯服务器客户端嗯放入请求和响应一些实时\n信息所以我们在这里禁用速率限制我们可以用负号来做到这一点所以我们只想\n流式传输任何权利，我们来了，然后我们就得到了我们的会话，如果我们通过了\n身份验证，那么我们就在这里，如果我们有一个会话，我们就可以启动并处理我们的聊天，\n嗯，发生了什么，所以我们是现在首先使用我们的离线功能来获取\n带有用户 ID 的实时频道，这就是我们用于服务器客户端通信的内容\n，然后我们还插入我们的 [音乐] 嗯通信\n嗯，所以基本上我们开始了关闭人工智能的对话，它为我们提供了一个交互 ID，因此\n我们可以在此处使用 uid，然后我们将获取对话的\n锁定历史记录，这样就可以查看我们的数据库，以便我们可以查看\n我们可以看看我们的工作室，所以我们现在在对话中，我们从\n用户那里获得了问题和响应的信息，所以我之前已经有过一次对话，\n嗯，存储在这里，然后我们使用某种方式将这个语言模型链放在一起我们的\n提示模板这是这里的查询模板，给出了以下用户提示\n和对话日志制定了相关响应，因此用户提示是查询对话历史记录\n，我们在这里给了它一堆指令，\n嗯，我们去然后我们正在做的是创建我们的广播频道，这样我们\n就可以进行频道订阅，基本上一旦我们订阅了，我们就可以发送广播\n，所以我们现在就发送，好的，我们开始了正在寻找匹配项，所以我们在这里\n从嵌入中获取匹配项，所以这是一种长度链\n，也是链接链，因此受监督的客户端开放 Ai 嵌入和向量存储\n，我们只是在进行存储相似性搜索 在这里，您可以 通过长度链详细信息\n挖掘所有信息 ，但这就是我们使用\nLangChain 进行相似性搜索的方式，以找到我们聊天的相关文档，以便我们从\n现有的 匹配中获取匹配 我们的网址，您看到我们控制台注销了这些网址，最后我们\n只是获取匹配元数据，获取文本和网址，然后我们基本上将\n提示模板与摘要一起构建，这样您就知道了 我们文档中总结的详细 信息、\n用户提出的问题、对话历史记录以及\nURL，然后我们只是使用 GPT 3.5 Turbo 模型在这里进行嗯是的开放式 AI 聊天\n，然后将它们放在一起，然后我们会做什么一旦我们有任何更新，我们所做的\n就是，基本上这就是流式传输的工作方式，所以我们说流式传输是真实的，\n每当我们获得某种新令牌时，我们都会通过我们的广播频道发送它\n然后我们在客户端获取它，最后当整个 LL 放大器链\n完成时，我们就用\n数据库中的交互 ID 更新我们的对话，这样我们也有我们对话日志中 AI 的答案，\n嗯，是的，差不多就是这样，我们可以查看这里的索引，因此在我们使用的索引中，您知道\n这是客户端呈现的，所以我们在这里使用 Supabase 呃浏览器客户端Supabase\n身份验证助手 嗯，然后我们只是将其放在一起，嗯，我们在哪里有它，是的，\n我们在这里使用 superface 身份验证组件，将身份验证放在一起，然后我们\n就拥有了 Channel 侦听器，所以这就是我们的 Supabase 呃实时频道广播，所以当\n我们收到聊天事件时，我们基本上只是检查这是一个响应吗？这是一个状态消息\n呃响应，你有什么呃然后我们只是更新我们的聊天机器人消息呃，这样就\n很好了我们如何使用 Supabase 实时获得流媒体类型，以了解我们的\n客户\n规模您\n有兴趣使用 um Supabase 呃，使用 next.js 构建更多类型的 AI 应用程序，\n我们有一个 xjs openai 文档搜索，这实际上使用 um versal um versal AI SDK，所以\n如果您有兴趣，您知道吗这是如何工作的，呃，你可以在这里看这个，我们还有\n一个视频解释，所以非常感谢你的收听，我们在下一个视频中\n再见"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "en",
        "plaintext": "hey there today we're looking at building a \nchatbot with next.js and LangChain using Supabase\nVector so now we can chat with our document so \nmaybe let's ask does Supabase allow remote work\nquestion mark so we're firing this off now um \nwe're finding the matches and we can see here\nso we found our matches these are these two um \nSupabase job postings and then now the document is\ntoo long so we're summarizing um the information \nfrom the two job postings and we're then putting\ntogether our um prompt so um we can see here \nour prompt uh and then we're streaming back the\nanswer uh yes Supabase supports remote work now \nthis demo is a fork of the Pinecone uh chatbot\ndemo and the this is really awesome work by uh Roy \nhere you can read the blog post I'll link it below\num kind of the concept of building a multi-user \nchatbot with link chain JS in in next.js and\num there's a couple components to it but um most \nimportantly what I kind of wanted to try here is\nsort of replace a lot of these uh difference \nservices with the capabilities that are built\ninto Supabase so instead of Pinecone we're \nusing Supabase Vector instead of ably we're\nusing Supabase real time instead of cockroachdb \nwe're using the postgres database that comes with\nthe Supabase stack and then instead of fingerprint \nwe're using Supabase auth so all of these Services\nwe're boiling it down into just Supabase and \nopen AI um with with next.js here now in terms\nof the architecture for the chatbot um we have \nkind of two components so we have an indexer\num which sort of writes um embeddings kind \nof generates embeddings from ourself of Truth\nhere so we can look at the indexer so we have our \nsource of Truth which is some some website we have\na crawler kind of getting that information from \nthe website and then using LangChain and open AI\nwe're generating our embeddings and then \nstoring them in our Supabase vector and\nthen when we kind of want to chat with our sort \nof Truth itself basically we take the user query\nagain we create an embedding from that query we \nthen search kind of through all the documents\nto find kind of the relevant um sort of source \nof truth that we indexed kind of the relevant\nURLs we summarize that content from that URLs and \nthen where we're generating kind of a response and\nstreaming that back to the user using supervised \nreal time now the great thing with LangChain is\num it has built-in support for Supabase Vector \nso the way we can do this is we can just take\nthis schema here and apply that to our database \nusing the vector extension and so if you clone\ndown here clone down this link chain chatbot \ndemo the URL is also Below in the description\nwe can then open this up in vs code for example \nand we can look at so we have some migrations\nin here so these are initial migrations \nthat we apply when we run a Supabase start\nso we can run Supabase start here to start up \nour local stack I already have it running so I\ncan run supervised status to see kind of the \nlocal credentials and if I open this up here\nso we can see we have just copied this from the \nlink chain documentation so this is what enables\nour Supabase Vector creates our documents so \nbasically makes the the LangChain framework\nwork with with Supabase vector and then \none thing that I've added specifically here\nis the ability to allow the querying on the public \ndocuments for authenticated users so this is using\nuh row level security policies here and so we only \nwanted to allow um the querying for authenticated\nusers kind of from the client side we can we can \nallow that for example and so otherwise it is the\nsame here as as this which is kind of added in the \nthe role level security here and then also we're\nstoring the conversations so that is basically um \nyou know the the text sort of that that was typed\nin into the chat and then what the AI replied \nso we're storing the confuser and AI chatbot\nconversations as well as we want to remember the \nthe history of the chat and we're also injecting\nthat chat history into the prompt to also know um \nkind of the history of of previous conversations\nand again we're applying kind of a role level \nsecurity policy here specifically that only\num the user can see their own um kind of \nconversations um you know with with the chatbot\nuh so we're locking down kind of the information \nhere okay great so let's actually have a look\num we can run this so we can say npm run def so \nfirst of all you know we have Supabase running\nlocally and then also we have um our uh \nchat bot here running locally and it is\num comes with Supabase auth so this is the auth UI \nfor react actually but then first of all we want\nto crawl some information and you know here \nfor example we're hiring if you didn't know\nyou can check out Supabase careers for example \nwe're hiring for customers Solutions architect\nand this is the whole job description here \nthere's a lot of information in there you\nknow like 100 percent remote work um ESOP in \nthe company Equity ownership um yeah tons of\nstuff so you know let's make our lives easier uh \nand let's actually crawl this so API slash crawl\num we can crawl our job description here and what \nwe can see is now we're crawling um our chops and\nwe're also crawling so the crawler kind of does \na bit of a recursive thing where it crawls the\num the uh pages that are kind of linked um in it \nas well and then we can see okay this is done now\num so what we can um see actually now if we go to \nthe Supabase Studio here so we have the localhost\nagain if you don't remember we can do Supabase \nstatus after we've run a supervised start we\ncan get our local details here and so we can \nopen up this project locally here and we can\nnow look at we have our conversations so we don't \nhave any conversations yet but here we have our\ndocuments so this is um what we've crawled uh \nhere we have our Vector embeddings uh and you\ncan see kind of the lines of code um not lines \nof code so there's some metadata as well and\nthese are sort of the lines so the documents are \nkind of broken down into different sections so\num using the metadata as well we can then perform \nsome filtering so that's really powerful in\npostgres where we have the Json B data type so we \ncan kind of drop full sort of Json documents into\num you know you know our documents here as as \nmetadata great so now we've crawled this we have\nit in our database so now what we can do is let's \nactually have a look at how that crawler worked so\nthis is in our Pages API and then crawl here so \nwe're using length chain we're using our openai\nembeddings from LangChain and then we're using the \nSupabase Vector store so this is really neat for\na kind of length chain is integrated with the \nSupabase Vector store and then really just uh\nfrom the query we're getting the URLs that we um \nwant to index um we're kind of creating sort of\ndocument collection so we're splitting kind of the \nsections to make sure we have um kind of the the\nright you know size um to create the embedding so \nwe don't run out kind of out of the the token size\num splitting sort of the documents here and \nthen we're creating our embedding so open AI\nembeddings we're creating our Supabase Vector \nstore just putting in a Supabase admin client\nhere so Supabase admin client just uses um here \nwe can see that uses the private key which is\nour here our service role key uh and then we \ncan perform kind of admin operations which is\ninserting these documents and so we're then um \nyeah creating kind of in our document collection\num adding in kind of storing all the documents and \nthen we have the documents here in our database\nand we can then perform searches on them so let's \ngo over to that so first of all we'll need to log\nin So currently if we look in our project here um \nso we're running again on localhost we're running\nthe entire uh Supabase stack locally and we \ndon't have any users yet so let's sign up a\nnew user tester at test dot d e and um here so \nif we say sign in um we're not you know invalid\ncredentials because we haven't so let's sign \nup and then we need to check our email for the\nconversation link now we're running on localhost \nso we're not sending out actual uh emails here\nbut what we can do is we have the service called \nin bucket which is a really really cool Open\nSource service as well and we can see here we have \nour confirm your email so this one was uh just\nsent just now and we can click and confirm our \nemail address and now we can see we're locked into\num our application here I'm running on localhost \nso now we can chat with our documents so maybe\nlet's ask does Supabase allow remote work question \nmark so we're firing this off now um we're finding\nthe matches and we can see here so we found \nour matches these are these two um Supabase job\npostings uh and then now the document is too long \nso we're summarizing um the information from the\ntwo job postings and we're then putting together \nour um prompt so um we can see here our prompt\nand then we're streaming back the answer \nuh yes Supabase supports remote work\num fully remote communication will happen over \nemail video yada yada and that's exactly that\num so this is working uh entirely \nas expected let's have a look at how\num the actual chat functionality is working \nso again um the heart of it is kind of here\nin chat dot TS Yes again uh kind of LangChain \nuh stuff open AI we have a prompt template here\num and then we're got our summarizer and here \nusing the auth helpers we're creating a Pages\nserver client which is kind of a server site \nour client that we can use to perform sort of\nauthenticated queries on on the server and \nso we're just getting our Supabase auth uh\nclient so our supervised auth client is \ncoming from down here so we're creating\num uh Pages uh server client uh putting in \nthe requests and the response some real-time\ninformation so we're disabling the rate limit \nhere we can do that with the minus one so we just\nwant to stream kind of any right we're coming \nthen we're getting our session and if we're\nauthenticated then we have here our if we have a \nsession we can then fire off and handle our chat\num and what's Happening Here is so we're \nnow using our offline first of all to get a\nreal-time Channel with the user ID so that's what \nwe're using for the server client communication\nuh then we're also inserting \nour [Music] um communication\num so basically we're starting off a conversation \nfor the AI which gives us an interaction ID so\nwe can kind of use the the uid here um \nand we're then getting the conversation\num lock history so that's just kind of \nlooking at our database so um we can look\nwe can look at our studio so here we now have \nin conversations we have this information from\nour user the question and the response here \nso I had already one conversation earlier\num that stored in here then we're putting together \num this language model chain using kind of our\nprompt template this is the inquiry template \nhere kind of given the following user prompt\nand conversation log formulated relevant \nresponse so user prompt is kind of the\nthe query conversation history and we're kind \nof giving it a bunch of instructions here\num there we go and then what we're doing is \nwe're creating our broadcast channel so we\ncan do Channel subscribe and basically once \nwe're subscribed then we can send a broadcast\nand so here we're just now sending okay we're \nstarting off we're finding matches so here we're\ndoing our get matches from embeddings \nso this is um kind of a length chain\num link chain as well so supervised client \nopen Ai embeddings and the the vector store\num we're just doing our store similarity search \nhere so all that information you can kind of dig\nthrough the the length chain details but this is \nhow we're doing kind of our similarity search with\nLangChain to find the relevant documents for our \nchat so we get our matches from the matches we\nthen have our URLs and we you saw we console \nlogged out those URLs and then lastly we're\njust kind of getting the match metadata getting \nthe text and the urls and then we're basically\nBuilding Together our prompt template with \nthe summaries so that's you know kind of the\nsummarized details from our documents the question \nfrom the user the conversation history as well as\nthe URLs and then we're just doing our um yeah \nopen AI chat here using GPT 3.5 turbo model\num and just putting that together here and then \nwhat we're doing is um once we have um any updates\nso basically that's kind of how the streaming \nworks here so we're saying streaming true and\nanytime we're getting kind of a new token we're \nthen sending this through our broadcast channel\nand where we then get it on the client side and \nthen at the end when the um whole LL amp chain is\nkind of finished we're then just um updating \nour conversation uh with the interaction ID\nin the database so that we also have the the \nanswers from the AI in our conversation log\num yeah that's pretty much it we can look at the \nindex here so in the index we're using you know\nthis is client-side rendered um so we're using the \nSupabase uh browser client here from the Supabase\nauth helpers uh and then pretty much we're just \nputting together um where do we have it here yeah\nwe're kind of putting up um putting auth together \nusing superface auth component here and then we\njust have our Channel listener so this is our \nSupabase uh real-time Channel broadcast so when\nwe get a chat event we then basically just check \nokay is this a response this is a status message\nuh response and what have you uh and then we \njust update our chatbot message uh and so that's\nkind of how we get the streaming kind of using \nSupabase real time to um our client size yeah\num that's pretty much it um this is how you \ncan kind of get all of these different service\nproviders bundled basically within uh super pace \nso that functionality is available if you are\ninterested in building with um Supabase uh with \nmore with next.js more kind of AI applications\nthere is we have an xjs openai doc search and this \nactually uses the um versal um versal AI SDK so\nif you're interested in you know kind of how does \nthat work uh you can look at this here and we also\nhave a video explanation for this one so thanks so \nmuch for tuning in and see you in the next video\nforeign"
      },
      {
        "srtUrl": null,
        "type": "auto_generated",
        "language": "en",
        "plaintext": "hey there today we're looking at\nbuilding a chatbot with next.js and Lang\nchain using Super Bass Vector so now we\ncan chat with our document so maybe\nlet's ask does Super Bass allow remote\nwork question mark so we're firing this\noff now\num we're finding the matches\nand we can see here so we found our\nmatches these are these two\num Super Bass job postings and then now\nthe document is too long so we're\nsummarizing\num the information from the two job\npostings and we're then putting together\nour\num prompt so\num we can see here our prompt\nuh and then we're streaming back the\nanswer uh yes Super Bass supports remote\nwork now this demo is a fork of the\nPinecone uh chatbot demo and the this is\nreally awesome work by uh Roy here\nyou can read the blog post I'll link it\nbelow\num kind of the concept of building a\nmulti-user chatbot with link chain JS in\nin next.js and\num there's a couple components to it but\num most importantly what I kind of\nwanted to try here is sort of replace a\nlot of these uh difference services with\nthe capabilities that are built into\nSuper Bass so instead of Pinecone we're\nusing Super Bass Vector instead of ably\nwe're using Super Bass real time instead\nof cockroachdb we're using the postgres\ndatabase that comes with the Super Bass\nstack and then instead of fingerprint\nwe're using Super Bass auth so all of\nthese Services we're boiling it down\ninto just super bass and open AI\num with with next.js here now in terms\nof the architecture for the chatbot\num we have kind of two components so we\nhave an indexer\num which sort of writes\num embeddings kind of generates\nembeddings from ourself of Truth here so\nwe can look at the indexer so we have\nour source of Truth which is some some\nwebsite we have a crawler kind of\ngetting that information from the\nwebsite and then using Lang chain and\nopen AI\nwe're generating our embeddings and then\nstoring them in our Super Bass vector\nand then when we kind of want to chat\nwith our sort of Truth itself basically\nwe take the user query\nagain we create an embedding from that\nquery we then search kind of through all\nthe documents to find kind of the\nrelevant\num sort of source of truth that we\nindexed kind of the relevant URLs we\nsummarize that content from that URLs\nand then where we're generating kind of\na response and streaming that back to\nthe user using supervised real time\nnow the great thing with Lang chain is\num it has built-in support for Super\nBass Vector so the way we can do this is\nwe can just take this schema here\nand apply that to our database using the\nvector extension and so if you clone\ndown here clone down this link chain\nchatbot demo the URL is also Below in\nthe description\nwe can then open this up in vs code for\nexample and we can look at so we have\nsome migrations in here so these are\ninitial migrations that we apply when we\nrun a Super Bass start\nso we can run super bass start here to\nstart up our local stack I already have\nit running so I can run supervised\nstatus to see kind of the local\ncredentials\nand if I open this up here so we can see\nwe have just copied this from the link\nchain documentation so this is what\nenables our Super Bass Vector creates\nour documents so basically makes the the\nLang chain framework work with with\nSuper Bass vector and then one thing\nthat I've added specifically here\nis the ability to allow the querying on\nthe public documents for authenticated\nusers so this is using uh row level\nsecurity policies here and so we only\nwanted to allow\num the querying for authenticated users\nkind of from the client side we can we\ncan allow that for example\nand so otherwise it is the same here as\nas this which is kind of added in the\nthe role level security here and then\nalso we're storing the conversations\nso that is basically\num you know the the text sort of that\nthat was typed in into the chat and then\nwhat the AI replied so we're storing the\nconfuser and AI chatbot conversations as\nwell as we want to remember the the\nhistory of the chat and we're also\ninjecting that chat history into the\nprompt to also know\num kind of the history of of previous\nconversations and again we're applying\nkind of a role level security policy\nhere specifically that only\num the user can see their own\num\nkind of conversations\num you know with with the chatbot uh so\nwe're locking down kind of the\ninformation here\nokay great so let's actually have a look\num we can run this so we can say npm run\ndef so first of all you know we have\nsuper bass running locally\nand then also we have\num our uh chat bot here running locally\nand it is um comes with Super Bass auth\nso this is the auth UI for react\nactually but then first of all we want\nto crawl some information and you know\nhere for example we're hiring if you\ndidn't know you can check out Super Bass\ncareers for example we're hiring for\ncustomers Solutions architect\nand this is the whole job description\nhere there's a lot of information in\nthere you know like 100 percent remote\nwork\num ESOP in the company Equity ownership\num yeah tons of stuff so you know let's\nmake our lives easier\nuh and let's actually crawl this so API\nslash crawl\num we can crawl our job description here\nand what we can see is now we're\ncrawling\num our chops\nand we're also crawling so the crawler\nkind of does a bit of a recursive thing\nwhere it crawls the\num\nthe uh pages that are kind of linked\num in it as well and then we can see\nokay this is done now\num so what we can\num see actually now if we go to the\nSuper Bass Studio here so we have the\nlocalhost again if you don't remember we\ncan do Super Bass status after we've run\na supervised start we can get our local\ndetails here and so we can open up this\nproject locally\nhere and we can now look at we have our\nconversations so we don't have any\nconversations yet but here we have our\ndocuments so this is um what we've\ncrawled uh here we have our Vector\nembeddings uh and you can see kind of\nthe lines of code\num not lines of code so there's some\nmetadata as well and these are sort of\nthe lines so the documents are kind of\nbroken down into different sections so\num using the metadata as well we can\nthen perform some filtering so that's\nreally powerful in postgres where we\nhave the Json B data type so we can kind\nof drop full sort of Json documents into\num you know you know our documents here\nas as metadata\ngreat so now we've crawled this we have\nit in our database so now what we can do\nis let's actually have a look at how\nthat crawler worked so this is in our\nPages API and then crawl\nhere so we're using length chain we're\nusing our openai embeddings from Lang\nchain and then we're using the Super\nBass Vector store so this is really neat\nfor a kind of length chain is integrated\nwith the Super Bass Vector store\nand then really just uh from the query\nwe're getting the URLs that we um want\nto index\num we're kind of creating sort of\ndocument collection so we're splitting\nkind of the sections to make sure we\nhave\num kind of the the right you know size\num to create the embedding so we don't\nrun out kind of out of the the token\nsize\num splitting sort of the documents here\nand then we're creating our embedding so\nopen AI embeddings we're creating our\nSuper Bass Vector store just putting in\na Super Bass admin client here so super\nbass admin client just uses\num here we can see that uses the private\nkey which is our here our service role\nkey\nuh and then we can\nperform kind of admin operations which\nis inserting these documents\nand so we're then\num yeah creating kind of in our document\ncollection\num adding in kind of storing all the\ndocuments and then we have the documents\nhere in our database and we can then\nperform searches on them so let's go\nover to that so first of all we'll need\nto log in So currently if we look in our\nproject here\num so we're running again on localhost\nwe're running the entire uh Super Bass\nstack locally and we don't have any\nusers yet so let's sign up a new user\ntester at test dot d e\nand\num here so if we say sign in\num we're not you know invalid\ncredentials because we haven't so let's\nsign up\nand then we need to check our email for\nthe conversation link now we're running\non localhost so we're not sending out\nactual uh emails here\nbut what we can do is we have the\nservice called in bucket which is a\nreally really cool Open Source service\nas well and we can see here we have our\nconfirm your email so this one was uh\njust sent just now and we can click and\nconfirm our email address and now we can\nsee we're locked into\num\nour application here I'm running on\nlocalhost so now we can chat with our\ndocuments so maybe let's ask does Super\nBass allow remote work question mark\nso we're firing this off now\num we're finding the matches\nand we can see here so we found our\nmatches these are these two\num Super Bass job postings uh and then\nnow the document is too long so we're\nsummarizing\num the information from the two job\npostings and we're then putting together\nour\num prompt so\num we can see here our prompt\nand then we're streaming back the answer\nuh yes Super Bass supports remote work\num fully remote communication will\nhappen over email video yada yada and\nthat's exactly that\num so this is working uh entirely as\nexpected let's have a look at how um the\nactual chat functionality is working so\nagain\num the heart of it is kind of here in\nchat dot TS Yes again uh kind of Lang\nchain uh stuff open AI we have a prompt\ntemplate here\num and then we're got our summarizer and\nhere using the auth helpers we're\ncreating a Pages server client which is\nkind of a server site\nour client that we can use to perform\nsort of authenticated queries on on the\nserver and so we're just getting our\nSuper Bass auth uh client so our\nsupervised auth client is coming from\ndown here so we're creating\num\nuh Pages uh server client\nuh putting in the requests and the\nresponse some real-time information so\nwe're disabling the rate limit here we\ncan do that with the minus one so we\njust want to stream kind of any right\nwe're coming then we're getting our\nsession\nand if we're authenticated then we have\nhere our if we have a session we can\nthen fire off and handle our chat\num and what's Happening Here is so we're\nnow using our offline first of all to\nget a real-time Channel with the user ID\nso that's what we're using for the\nserver client communication\nuh then we're also inserting our\n[Music]\num\ncommunication\num so basically we're starting off a\nconversation for the AI which gives us\nan interaction ID so we can kind of use\nthe the uid here\num and we're then getting the\nconversation\num lock history so that's just kind of\nlooking at our database so\num we can\nlook\nwe can look at our studio\nso here we now have in conversations we\nhave\nthis information from our user the\nquestion and the response\nhere so I had already one conversation\nearlier\num that stored in here\nthen we're putting together\num\nthis language model chain using kind of\nour prompt template this is the inquiry\ntemplate here kind of given the\nfollowing user prompt and conversation\nlog\nformulated relevant response so user\nprompt is kind of the\nthe query\nconversation\nhistory and we're kind of giving it a\nbunch of instructions here\num\nthere we go\nand then what we're doing is we're\ncreating our broadcast channel so we can\ndo Channel subscribe\nand basically once we're subscribed then\nwe can send a broadcast\nand so here we're just now sending okay\nwe're starting off we're finding matches\nso here we're doing our get matches from\nembeddings\nso this is um kind of a length chain\num\nlink chain as well so supervised client\nopen Ai embeddings and the the vector\nstore\num we're just doing our store similarity\nsearch here\nso all that information you can kind of\ndig through the the length chain details\nbut this is how we're doing kind of our\nsimilarity search with Lang chain to\nfind the relevant documents\nfor our chat so we get our matches from\nthe matches we then have our URLs\nand we you saw we console logged out\nthose URLs and then lastly we're just\nkind of getting the match metadata\ngetting the text and the urls\nand then we're basically Building\nTogether our prompt template with the\nsummaries so that's you know kind of the\nsummarized details from our documents\nthe question from the user the\nconversation history as well as the URLs\nand then we're just doing our\num\nyeah open AI chat here using GPT 3.5\nturbo model\num and just putting that together here\nand then what we're doing is\num once we have\num any updates so basically that's kind\nof how the streaming works here so we're\nsaying streaming true and anytime we're\ngetting kind of a new token we're then\nsending this through our broadcast\nchannel\nand where we then get it on the client\nside and then at the end when the\num whole LL amp chain is kind of\nfinished we're then just\num updating our conversation uh with the\ninteraction ID in the database so that\nwe also have the the answers from the AI\nin our conversation log\num yeah that's pretty much it we can\nlook at the index here so in the index\nwe're using you know this is client-side\nrendered\num so we're using the Super Bass uh\nbrowser client here from\nthe Super Bass auth helpers\nuh and then pretty much we're just\nputting together\num where do we have it here yeah we're\nkind of putting up um putting auth\ntogether using superface auth component\nhere and then we just have our Channel\nlistener so this is our Super Bass uh\nreal-time Channel\nbroadcast so when we get a chat event we\nthen basically just check okay is this a\nresponse this is a status message uh\nresponse and what have you uh and then\nwe just update our chatbot message uh\nand so that's kind of how we get the\nstreaming kind of using Super Bass real\ntime to\num our client size yeah\num that's pretty much it\num this is how you can kind of get all\nof these different service providers\nbundled basically within uh super pace\nso that functionality is available if\nyou are interested in building with\num Super Bass uh with more with next.js\nmore kind of AI applications there is we\nhave an xjs openai doc search and this\nactually uses the um versal\num versal AI SDK\nso if you're interested in you know kind\nof how does that work uh you can look at\nthis here and we also have a video\nexplanation for this one so thanks so\nmuch for tuning in and see you in the\nnext video\nforeign"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "fr",
        "plaintext": "hé, aujourd'hui, nous envisageons de créer un chatbot avec next.js et LangChain en utilisant Supabase\nVector, nous pouvons donc maintenant discuter avec notre document, alors peut-être demandons-nous si Supabase autorise le travail à distance,\ndonc nous lançons cela maintenant, euh, nous' Je cherche les correspondances et nous pouvons voir ici\ndonc nous avons trouvé nos correspondances, ce sont ces deux offres d'emploi Supabase et maintenant le document est\ntrop long donc nous résumons euh les informations des deux offres d'emploi et nous rassemblons\nensuite notre invite donc euh nous pouvons voir ici notre invite euh et ensuite nous renvoyons la\nréponse euh oui Supabase prend en charge le travail à distance maintenant cette démo est un fork de la\ndémo du chatbot Pinecone euh et c'est un travail vraiment génial de euh Roy ici vous pouvez lire l'article de blog, je vais le lier ci-dessous,\neuh, une sorte de concept de construction d'un chatbot multi-utilisateurs avec une chaîne de liens JS dans next.js et\neuh, il y a quelques composants, mais euh, plus important encore, ce que je voulais en quelque sorte essayer ici, c'est\nen quelque sorte remplacer beaucoup de ces services de différence par les capacités intégrées\nà Supabase, donc au lieu de Pinecone, nous utilisons Supabase Vector au lieu de habilement, nous\nutilisons Supabase en temps réel au lieu de cockroachdb, nous utilisons le base de données postgres fournie avec\nla pile Supabase, puis au lieu de l'empreinte digitale, nous utilisons l'authentification Supabase, donc tous ces services,\nnous les réduisons en Supabase et ouvrons AI um avec avec next.js ici maintenant en termes\nd'architecture pour le chatbot euh nous avons en quelque sorte deux composants donc nous avons un indexeur\neuh qui écrit en quelque sorte euh des intégrations qui génère en quelque sorte des intégrations de nous-mêmes de la vérité\nici afin que nous puissions regarder l'indexeur afin que nous ayons notre source de vérité qui est un site Web que nous avoir\nune sorte de robot qui récupère ces informations à partir du site Web, puis en utilisant LangChain et l'IA ouverte,\nnous générons nos intégrations, puis les stockons dans notre vecteur Supabase,\npuis lorsque nous voulons en quelque sorte discuter avec notre type de vérité elle-même, nous prenons essentiellement la requête de l'utilisateur,\nnous créons à nouveau une intégration à partir de cette requête, nous recherchons ensuite en quelque sorte dans tous les documents\npour trouver une sorte de source de vérité pertinente que nous avons indexée, une sorte d'\nURL pertinente, nous résumons ce contenu à partir de ces URL, puis où nous générons une sorte de réponse et\nla renvoyons à l'utilisateur en temps réel supervisé. Maintenant, ce qui est génial avec LangChain, c'est\nqu'il a un support intégré pour Supabase Vector, donc la façon dont nous pouvons le faire est de simplement prendre\nce schéma. ici et appliquez-le à notre base de données en utilisant l'extension vectorielle et donc si vous clonez\nici, clonez cette démo de chatbot de chaîne de liens, l'URL est également ci-dessous dans la description,\nnous pouvons ensuite l'ouvrir dans vs code par exemple et nous pouvons le regarder nous avons quelques migrations\nici, ce sont donc des migrations initiales que nous appliquons lorsque nous exécutons un démarrage de Supabase\nafin que nous puissions exécuter Supabase start ici pour démarrer notre pile locale. Je l'ai déjà en cours d'exécution afin que je\npuisse exécuter le statut supervisé pour voir le type de local. informations d'identification et si j'ouvre ceci ici\npour que nous puissions voir que nous venons de copier cela à partir de la documentation de la chaîne de liens, c'est ce qui permet à\nnotre vecteur Supabase de créer nos documents, ce qui fait que le framework LangChain\nfonctionne avec le vecteur Supabase, puis une chose qui J'ai ajouté spécifiquement ici\nla possibilité d'autoriser l'interrogation des documents publics pour les utilisateurs authentifiés, donc cela utilise\nici des politiques de sécurité au niveau des lignes et nous voulions donc uniquement autoriser l'interrogation des\nutilisateurs authentifiés du côté client. pouvons-nous autoriser cela par exemple et sinon, c'est la\nmême chose ici que ceci qui est en quelque sorte ajouté dans la sécurité au niveau du rôle ici et ensuite nous stockons également\nles conversations, donc c'est fondamentalement, euh, vous connaissez le tri du texte de ce qui a été saisi\ndans le chat, puis de ce que l'IA a répondu. Nous stockons donc les\nconversations du confondeur et du chatbot de l'IA. Nous voulons également nous souvenir de l'historique du chat et nous injectons également\ncet historique du chat dans le invite également à connaître l'historique des conversations précédentes\net encore une fois, nous appliquons ici une sorte de politique de sécurité au niveau du rôle, spécifiquement selon laquelle seul\nl'utilisateur peut voir son propre type de conversations avec le chatbot\neuh donc nous verrouillons le genre d'informations ici, ok, super, alors jetons un coup d'oeil,\neuh, nous pouvons exécuter ceci afin que nous puissions dire npm run def donc tout d'abord vous savez que Supabase fonctionne\nlocalement et ensuite nous avons aussi euh notre euh, le chat bot ici fonctionne localement et il est\nlivré avec l'authentification Supabase, donc c'est l'interface utilisateur d'authentification pour réagir en fait, mais tout d'abord, nous voulons\nexplorer certaines informations et vous savez ici, par exemple, nous embauchons si vous ne le saviez pas.\nvous pouvez consulter les carrières Supabase, par exemple, nous recrutons pour les clients Architecte de solutions\net voici la description complète du poste ici, il y a beaucoup d'informations là-dedans, vous\nsavez, comme le travail à 100 % à distance, euh ESOP dans l'entreprise, la participation au capital, euh ouais des tonnes de\ntrucs donc vous savez, simplifions-nous la vie, euh et explorons cela pour que l'API slash explore\neuh, nous pouvons explorer notre description de poste ici et ce que nous pouvons voir, c'est que maintenant nous explorons euh nos côtelettes et\nnous explorons également donc le genre de robot d'exploration of fait une chose un peu récursive où il explore les\neuh les pages qui sont en quelque sorte liées euh dedans aussi et puis nous pouvons voir ok c'est fait maintenant\neuh donc ce que nous pouvons voir en fait maintenant si nous allons au Supabase Studio ici afin que nous ayons à nouveau l'hôte local\nsi vous ne vous en souvenez pas, nous pouvons faire le statut Supabase après avoir effectué un démarrage supervisé, nous\npouvons obtenir nos détails locaux ici et ainsi nous pouvons ouvrir ce projet localement ici et nous pouvons\nmaintenant regarder à nous avons nos conversations donc nous n'avons pas encore de conversations mais ici nous avons nos\ndocuments donc c'est euh ce que nous avons exploré euh ici nous avons nos intégrations vectorielles euh et vous\npouvez voir une sorte de lignes de code euh pas des lignes de code donc il y a aussi des métadonnées et\nce sont en quelque sorte des lignes donc les documents sont en quelque sorte divisés en différentes sections donc\neuh en utilisant également les métadonnées, nous pouvons ensuite effectuer un filtrage, donc c'est vraiment puissant dans\npostgres où nous avons le Json Type de données B afin que nous puissions en quelque sorte déposer une sorte complète de documents Json dans\neuh, vous savez que vous connaissez nos documents ici en tant que métadonnées, alors maintenant nous avons exploré cela, nous\nl'avons dans notre base de données, donc maintenant ce que nous pouvons faire, c'est d'avoir réellement regardez comment ce robot d'exploration a fonctionné,\nc'est donc dans notre API Pages, puis explorez ici afin que nous utilisions la chaîne de longueur, nous utilisons nos\nintégrations openai de LangChain, puis nous utilisons le magasin Supabase Vector, donc c'est vraiment intéressant pour\nune sorte de chaîne de longueur est intégrée au magasin Supabase Vector, puis, à\npartir de la requête, nous obtenons les URL que nous voulons indexer, nous créons en quelque sorte une sorte de\ncollection de documents, donc nous divisons en quelque sorte les sections pour nous assurer que nous avons en quelque sorte la bonne\ntaille, vous savez, pour créer l'intégration afin que nous ne soyons pas à court de taille de jeton, euh,\nen divisant les documents ici, puis nous créons notre en intégrant des intégrations d'IA si ouvertes,\nnous créons notre magasin Supabase Vector en mettant simplement un client administrateur Supabase\nici afin que le client administrateur Supabase utilise simplement euh ici, nous pouvons voir qu'il utilise la clé privée qui est\nnotre ici notre clé de rôle de service euh et ensuite nous pouvons effectuer une sorte d'opérations d'administration qui\ninsère ces documents et donc nous sommes alors, euh ouais, en train de créer une sorte de dans notre collection de documents,\neuh en ajoutant en quelque sorte le stockage de tous les documents, puis nous avons les documents ici dans notre base de données\net nous pouvons ensuite effectuer des recherches sur eux donc passons à cela donc tout d'abord nous devrons nous connecter\nDonc actuellement, si nous regardons dans notre projet ici euh donc nous courons à nouveau sur localhost, nous exécutons\ntoute la pile Supabase localement et nous ne le faisons pas Je n'ai pas encore d'utilisateurs, alors inscrivons un\nnouveau testeur utilisateur sur test point de et euh ici donc si nous disons de vous connecter, nous ne sommes pas, vous connaissez\ndes informations d'identification invalides parce que nous ne l'avons pas fait, alors inscrivons-nous et nous devons ensuite vérifiez notre courrier électronique pour le\nlien de conversation que nous utilisons maintenant sur localhost, nous n'envoyons donc pas de véritables courriers électroniques ici,\nmais ce que nous pouvons faire, c'est que nous avons le service appelé dans le bucket qui est\négalement un service Open Source vraiment très cool et nous pouvons voir ici que nous avons notre confirmation de votre e-mail, donc celui-ci vient d'\nêtre envoyé tout à l'heure et nous pouvons cliquer et confirmer notre adresse e-mail et maintenant nous pouvons voir que nous sommes verrouillés\neuh, notre application ici, je l'utilise sur localhost, donc maintenant nous pouvons discuter avec nos documents, alors peut-être\ndemandons-nous si Supabase autorise le travail à distance, donc nous lançons cela maintenant, euh, nous trouvons\nles correspondances et nous pouvons voir ici donc nous avons trouvé nos correspondances, ce sont ces deux\noffres d'emploi Supabase euh et maintenant le document est trop long donc nous résumons euh les informations des\ndeux offres d'emploi et nous rédigeons ensuite notre invite pour que nous puissions voir ici notre invite\net ensuite nous renvoyons la réponse euh oui Supabase prend en charge le travail à distance\neuh la communication entièrement à distance se fera par e-mail vidéo yada yada et c'est exactement ça\neuh donc cela fonctionne euh tout à fait comme prévu, regardons comment\neuh le réel la fonctionnalité de chat fonctionne donc encore une fois, le cœur est en quelque sorte ici\ndans le chat dot TS Oui encore, euh, genre de LangChain, euh, des trucs d'IA ouverte, nous avons un modèle d'invite ici,\neuh, puis nous avons notre résumé et ici en utilisant les aides d'authentification nous créons un\nclient serveur Pages qui est une sorte de site serveur que notre client peut utiliser pour effectuer des sortes de\nrequêtes authentifiées sur le serveur et nous obtenons donc simplement notre\nclient d'authentification Supabase, donc notre client d'authentification supervisé arrive à partir d'ici donc nous créons\neuh euh Pages euh serveur client euh en mettant les requêtes et la réponse\ndes informations en temps réel donc nous désactivons la limite de débit ici, nous pouvons le faire avec le moins un donc nous\nvoulons juste diffuser en quelque sorte, nous arrivons, nous obtenons notre session et si nous sommes\nauthentifiés, nous avons ici notre si nous avons une session, nous pouvons alors lancer et gérer notre conversation\neuh et ce qui se passe Voici donc nous sommes maintenant, nous utilisons d'abord notre mode hors ligne pour obtenir un\ncanal en temps réel avec l'ID utilisateur, c'est donc ce que nous utilisons pour la communication client serveur\neuh, puis nous insérons également notre communication [Musique]\neuh, donc en gros, nous commençons une conversation pour l'IA qui nous donne un identifiant d'interaction afin que\nnous puissions en quelque sorte utiliser l'uid ici euh et nous obtenons ensuite l'\nhistorique de verrouillage de la conversation, donc c'est juste en quelque sorte en regardant notre base de données pour que nous puissions regarder,\nnous pouvons regardez notre studio donc ici nous avons maintenant dans les conversations, nous avons ces informations de\nnotre utilisateur, la question et la réponse ici donc j'ai déjà eu une conversation plus tôt\neuh qui est stockée ici, puis nous mettons en place cette chaîne de modèles de langage en utilisant une sorte de notre\nmodèle d'invite, c'est le modèle de demande ici, étant donné l'invite utilisateur suivante\net le journal de conversation formulé une réponse pertinente, donc l'invite utilisateur est en quelque sorte l'\nhistorique de la conversation de la requête et nous lui donnons en quelque sorte un tas d'instructions ici,\neuh, c'est parti et puis ce que nous faisons, c'est créer notre chaîne de diffusion afin que nous\npuissions nous abonner à la chaîne et, en gros, une fois que nous sommes abonnés, nous pouvons envoyer une diffusion\net donc ici, nous envoyons juste maintenant, ok, nous commençons Nous trouvons des correspondances, donc ici, nous faisons\nnos correspondances à partir des intégrations, donc c'est euh une sorte de chaîne de longueur,\neuh chaîne de liens, donc le client supervisé ouvre les intégrations Ai et le magasin vectoriel\neuh, nous faisons juste notre recherche de similarité de magasin. ici, donc toutes ces informations, vous pouvez en quelque sorte fouiller\ndans les détails de la chaîne de longueur, mais c'est ainsi que nous effectuons notre recherche de similarité avec\nLangChain pour trouver les documents pertinents pour notre discussion afin que nous obtenions nos correspondances à partir des correspondances que nous\navons ensuite nos URL et vous avez vu que nous avons déconnecté ces URL sur la console et enfin, nous obtenons\nsimplement les métadonnées de correspondance en obtenant le texte et les URL, puis nous\nconstruisons ensemble notre modèle d'invite avec les résumés pour que vous sachiez le genre des\ndétails résumés de nos documents, la question de l'utilisateur, l'historique des conversations ainsi que\nles URL, puis nous faisons simplement notre euh ouais, ouvrez le chat AI ici en utilisant le modèle turbo GPT 3.5\neuh et mettons cela ensemble ici et ensuite ce que nous ce que nous faisons, c'est euh une fois que nous avons eu des mises à jour,\ndonc fondamentalement, c'est un peu comme ça que le streaming fonctionne ici, donc nous disons que le streaming est vrai et\nchaque fois que nous recevons une sorte de nouveau jeton, nous l'envoyons ensuite via notre canal de diffusion.\net là où nous l'obtenons ensuite du côté client, puis à la fin, lorsque toute la chaîne d'amplis LL est\nen quelque sorte terminée, nous mettons alors simplement à jour notre conversation euh avec l'ID d'interaction\ndans la base de données afin que nous ayons également le réponses de l'IA dans notre journal de conversation\neuh ouais c'est à peu près tout, nous pouvons regarder l'index ici donc dans l'index que nous utilisons, vous savez\nque c'est rendu côté client euh donc nous utilisons le client de navigateur Supabase euh ici à partir de les\nassistants d'authentification Supabase euh et puis à peu près nous sommes juste en train de mettre en place, euh, où l'avons-nous ici ouais,\nnous sommes en quelque sorte en train de mettre en place, euh, de mettre en place l'authentification en utilisant le composant d'authentification de surface ici, puis nous\navons juste notre écouteur de chaîne, donc c'est notre Supabase euh diffusion de chaîne en temps réel, donc quand\nnous recevons un événement de chat, nous vérifions simplement, d'accord, est-ce une réponse, c'est un message d'état,\neuh, une réponse et qu'avez-vous euh, puis nous mettons simplement à jour notre message de chatbot, euh et donc c'est\ngentil de la façon dont nous obtenons le type de streaming en utilisant Supabase en temps réel pour la taille de notre client ouais, euh\n, c'est à peu près tout, c'est ainsi que vous pouvez en quelque sorte regrouper tous ces différents\nfournisseurs de services essentiellement à un rythme super rapide afin que la fonctionnalité soit disponible si vous êtes\nintéressé à construire avec um Supabase euh avec plus avec next.js plus de types d'applications d'IA\nil y a nous avons une recherche de doc xjs openai et cela utilise en fait le SDK um versal um versal AI donc\nsi vous êtes intéressé par vous savez genre de comment ça marche, vous pouvez regarder ça ici et nous\navons aussi une explication vidéo pour celle-ci, alors merci beaucoup de vous être connecté et à bientôt dans la prochaine vidéo\nétrangère"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "de",
        "plaintext": "Hallo, heute überlegen wir, mit Supabase\nVector einen Chatbot mit next.js und LangChain zu erstellen, damit wir jetzt mit unserem Dokument chatten können. Vielleicht fragen wir uns, ob Supabase Remote-Arbeit zulässt.\nFragezeichen, also feuern wir das jetzt ab, ähm, wir Wir finden die Übereinstimmungen und können hier sehen,\nalso haben wir unsere Übereinstimmungen gefunden. Das sind diese beiden ähm-Supabase-Stellenausschreibungen und dann ist das Dokument jetzt\nzu lang, also fassen wir die Informationen aus den beiden Stellenausschreibungen zusammen und stellen sie dann\nzusammen unsere ähm-Eingabeaufforderung, also ähm, wir können hier unsere Eingabeaufforderung sehen, ähm, und dann streamen wir die\nAntwort zurück. Äh ja, Supabase unterstützt Remote-Arbeit. Diese Demo ist jetzt eine Abzweigung der Pinecone-Chatbot-\nDemo, und das ist wirklich eine großartige Arbeit von äh Roy hier Sie können den Blog-Beitrag lesen, den ich unten verlinken werde.\nÄhm, so etwas wie das Konzept, einen Mehrbenutzer-Chatbot mit Link-Chain-JS in next.js zu erstellen, und\nähm, es gibt ein paar Komponenten, aber ähm, das Wichtigste ist, was ich irgendwie wollte Der Versuch besteht\ndarin, viele dieser äh-Unterschiedsdienste durch die in Supabase integrierten Funktionen zu ersetzen\n. Anstelle von Pinecone verwenden wir also Supabase\nVector Postgres-Datenbank, die mit dem Supabase-Stack geliefert wird\n, und dann verwenden wir anstelle von Fingerprint die Supabase-Authentifizierung, also\nreduzieren wir alle diese Dienste auf Supabase und öffnen AI ähm mit next.js hier jetzt in Bezug\nauf die Architektur für Der Chatbot, ähm, wir haben sozusagen zwei Komponenten, also haben wir einen Indexer,\nder sozusagen um Einbettungen schreibt, sozusagen Einbettungen von uns selbst der Wahrheit\nhier generiert, sodass wir uns den Indexer ansehen können, damit wir unsere Quelle der Wahrheit haben, die eine Website ist, die wir haben Wir haben\neinen Crawler, der diese Informationen von der Website abruft und dann mithilfe von LangChain und offener KI\nunsere Einbettungen generiert und sie dann in unserem Supabase-Vektor speichert.\nWenn wir dann mit unserer Art von Wahrheit selbst chatten wollen, nehmen wir im Grunde genommen Bei der Benutzerabfrage\nerstellen wir erneut eine Einbettung aus dieser Abfrage. Anschließend durchsuchen wir alle Dokumente,\num die relevante Quelle der Wahrheit zu finden, die wir indiziert haben, die relevanten\nURLs. Wir fassen den Inhalt dieser URLs zusammen und dann wo Wir generieren eine Art Antwort und\nstreamen diese in überwachter Echtzeit an den Benutzer zurück. Das Tolle an LangChain ist,\ndass es eine integrierte Unterstützung für Supabase Vector bietet. Wir können dies also tun, indem wir einfach\ndieses Schema verwenden Hier und wenden Sie das mit der Vektorerweiterung auf unsere Datenbank an. Wenn Sie also\nhierher klonen, klonen Sie diese Link-Chain-Chatbot-Demo, die URL ist auch unten in der Beschreibung.\nWir können dies dann zum Beispiel im vs-Code öffnen und es uns ansehen Wir haben\nhier einige Migrationen, das sind also anfängliche Migrationen, die wir anwenden, wenn wir einen Supabase-Start ausführen,\ndamit wir Supabase-Start hier ausführen können, um unseren lokalen Stack zu starten. Ich habe ihn bereits laufen lassen, sodass ich den\nüberwachten Status ausführen kann, um die Art des lokalen zu sehen Anmeldeinformationen und wenn ich das hier öffne,\ndamit wir sehen können, dass wir es gerade aus der Link-Chain-Dokumentation kopiert haben, ermöglicht dies\nunserem Supabase Vector die Erstellung unserer Dokumente, sodass im Grunde das LangChain-Framework\nmit dem Supabase Vector funktioniert, und dann noch etwas Ich habe hier speziell\ndie Möglichkeit hinzugefügt, die Abfrage öffentlicher Dokumente für authentifizierte Benutzer zuzulassen, sodass\nhier Sicherheitsrichtlinien auf Zeilenebene verwendet werden und wir die Abfrage authentifizierter\nBenutzer nur auf der Clientseite zulassen wollten Können wir das zum Beispiel zulassen? Ansonsten ist es\nhier das Gleiche wie hier, was in der Rollenebenensicherheit hier irgendwie hinzugefügt wird, und dann\nspeichern wir auch die Konversationen, also im Grunde, ähm, Sie kennen die Textsortierung davon, was\nin den Chat eingegeben wurde, und dann, was die KI geantwortet hat, also speichern wir die Konversations- und KI-Chatbot-\nGespräche sowie den Verlauf des Chats und fügen\ndiesen Chat-Verlauf auch in den Chat ein Sie werden aufgefordert, auch den Verlauf früherer Konversationen zu erfahren\n, und auch hier wenden wir eine Art Sicherheitsrichtlinie auf Rollenebene an, insbesondere dass nur\nder Benutzer seine eigenen Konversationen sehen kann, die Sie mit dem Chatbot kennen\nÄhm, also sperren wir die Art der Informationen hier ein, okay, großartig, also schauen wir uns mal\num, wir können das ausführen, damit wir npm run def sagen können. Sie wissen also zunächst einmal, dass Supabase\nlokal ausgeführt wird, und dann haben wir auch ähm unser Äh, der Chat-Bot hier läuft lokal und\nkommt mit Supabase-Authentifizierung, also ist dies eigentlich die Authentifizierungs-Benutzeroberfläche für React, aber zunächst einmal wollen wir\nein paar Informationen crawlen und Sie wissen, dass wir hier zum Beispiel einstellen, falls Sie es nicht wussten\nSie können sich die Stellenangebote von Supabase ansehen, zum Beispiel stellen wir für Kunden Lösungsarchitekten ein,\nund das ist die gesamte Stellenbeschreibung hier. Da sind viele Informationen drin, die Sie\nwissen, wie 100-prozentige Remote-Arbeit, ESOP im Unternehmen, Kapitalbeteiligung, ähm, jede Menge\nZeug Also, wissen Sie, lasst uns unser Leben einfacher machen, und lasst uns das wirklich crawlen, also API-Slash-Crawling,\nähm, wir können hier unsere Stellenbeschreibung crawlen, und was wir sehen können, ist, dass wir jetzt ähm nach unseren Kräften crawlen, und\nwir crawlen auch so auf die Crawler-Art von macht so etwas wie eine rekursive Sache, bei der es\nauch die äh Seiten durchsucht, die darin irgendwie verlinkt sind, und dann können wir sehen, okay, das ist jetzt erledigt,\nähm, was wir also jetzt tatsächlich sehen können, wenn wir zu gehen Supabase Studio hier, damit wir wieder den Localhost haben.\nFalls Sie sich nicht erinnern, können wir den Supabase-Status festlegen, nachdem wir einen überwachten Start durchgeführt haben. Wir\nkönnen hier unsere lokalen Details abrufen und so können wir dieses Projekt hier lokal öffnen und\njetzt nachsehen Hier führen wir unsere Gespräche, also haben wir noch keine Gespräche, aber hier haben wir unsere\nDokumente, also ist das ähm, was wir gecrawlt haben, ähm, hier haben wir unsere Vektoreinbettungen, ähm, und Sie\nkönnen eine Art Codezeilen sehen, ähm, keine Zeilen des Codes, also gibt es auch einige Metadaten, und\ndas sind sozusagen die Zeilen, sodass die Dokumente irgendwie in verschiedene Abschnitte unterteilt sind. Wenn\nwir also auch die Metadaten verwenden, können wir dann einige Filterungen durchführen, was in\nPostgres, wo wir den Json haben, wirklich leistungsstark ist B-Datentyp, sodass wir sozusagen die gesamte Art von Json-Dokumenten in\nähm einfügen können. Sie wissen ja, Sie kennen unsere Dokumente hier als Metadaten. Großartig, also haben wir das jetzt gecrawlt und\nin unserer Datenbank. Jetzt können wir es tatsächlich tun Schauen Sie sich an, wie dieser Crawler funktioniert hat, also\nist das in unserer Pages-API und dann hierher crawlen, also verwenden wir die Längenkette, wir verwenden unsere OpenAI-\nEinbettungen von LangChain und dann verwenden wir den Supabase Vector Store, also ist das wirklich nett\nEine Art Längenkette ist in den Supabase Vector Store integriert und dann\nerhalten wir aus der Abfrage wirklich nur die URLs, die wir indizieren möchten. Wir erstellen eine Art\nDokumentensammlung, also teilen wir sie auf die Abschnitte, um sicherzustellen, dass wir ungefähr die\nrichtige Größe haben, um die Einbettung zu erstellen, damit uns nicht die Token-Größe ausgeht,\num die Art der Dokumente hier aufzuteilen, und dann erstellen wir unsere Durch die Einbettung offener KI-\nEinbettungen erstellen wir unseren Supabase Vector-Shop und fügen\nhier einfach einen Supabase-Administrator-Client ein, sodass der Supabase-Administrator-Client einfach ähm hier verwendet. Wir können sehen, dass er den privaten Schlüssel verwendet, der\nhier unser Servicerollenschlüssel ist, äh, und dann können wir Führen Sie Verwaltungsvorgänge durch, bei denen\ndiese Dokumente eingefügt werden, und dann erstellen wir sozusagen eine Art Dokumentsammlung in unserer Dokumentensammlung,\nfügen alle Dokumente hinzu und speichern sie. Dann haben wir die Dokumente hier in unserer Datenbank\nund können dann Suchen durchführen auf ihnen, also lasst uns dazu übergehen, also müssen wir uns zunächst einmal anmelden.\nWenn wir uns also derzeit unser Projekt hier ansehen, also laufen wir wieder auf localhost, wir führen\nden gesamten äh Supabase-Stack lokal aus und wir tun es nicht Ich habe noch keine Benutzer, also melden wir uns hier bei test dot de und ähm als\nneuen Benutzertester an Schauen Sie in unseren E-Mails nach dem\nKonversationslink, jetzt laufen wir auf localhost, also versenden wir hier keine echten E-Mails,\naber was wir tun können, ist, dass wir den Dienst im Bucket aufgerufen haben, der\nauch ein wirklich sehr, sehr cooler Open-Source-Dienst ist\nWir können hier sehen, dass wir Ihre E-Mail-Adresse bestätigt haben, also wurde diese gerade\nerst gesendet, und wir können auf unsere E-Mail-Adresse klicken und sie bestätigen, und jetzt können wir sehen, dass wir angemeldet sind\nÄhm, unsere Anwendung hier, ich laufe auf localhost, also können wir jetzt mit unseren Dokumenten chatten, also\nfragen wir uns vielleicht, ob Supabase Fernarbeit zulässt. Fragezeichen, also feuern wir das jetzt ab, ähm, wir finden\ndie Übereinstimmungen und können es hier sehen Wir haben herausgefunden, dass unsere Übereinstimmungen diese beiden\nähm-Supabase-Stellenausschreibungen sind, und dann ist das Dokument zu lang, also fassen wir die Informationen aus den\nbeiden Stellenausschreibungen zusammen und stellen dann unsere ähm-Eingabeaufforderung zusammen, damit wir sie hier sehen können Unsere Eingabeaufforderung\nund dann streamen wir die Antwort zurück. Ja, Supabase unterstützt Remote-Arbeit.\nDie vollständige Remote-Kommunikation erfolgt über E-Mail-Video. Yada Yada, und genau das\nfunktioniert ähm, also funktioniert es völlig wie erwartet. Schauen wir uns mal an, wie\nähm das tatsächliche ist Die Chat-Funktionalität funktioniert, also wiederum, ähm, das Herzstück davon ist irgendwie hier\nim Chat Dot TS. Ja, wieder, ähm, irgendwie LangChain, ähm, offene KI, wir haben hier eine Eingabeaufforderungsvorlage,\nähm, und dann haben wir unsere Zusammenfassung und verwenden hier die Auth-Helfer Wir erstellen einen Pages-\nServer-Client, der eine Art Server-Site unseres Clients ist, den wir verwenden können, um authentifizierte\nAbfragen auf dem Server durchzuführen, und deshalb bekommen wir gerade unseren Supabase-Authentifizierungs-\nClient, also kommt unser überwachter Authentifizierungs-Client Von hier unten erstellen wir also\nähm, ähm, Seiten, ähm, Server-Client, ähm, fügen in die Anfragen und die Antwort einige Echtzeitinformationen ein,\nalso deaktivieren wir hier die Ratenbegrenzung, wir können das mit der Minus-Eins machen, also wollen wir einfach nur\nstreamen Irgendein Recht, wir kommen, dann bekommen wir unsere Sitzung und wenn wir\nauthentifiziert sind, dann haben wir hier unser, wenn wir eine Sitzung haben, können wir dann loslegen und unseren Chat bearbeiten,\nähm und was hier passiert, ist so, dass wir es sind Jetzt verwenden wir zunächst einmal unseren Offline-Kanal, um einen\nEchtzeit-Kanal mit der Benutzer-ID zu erhalten. Das ist es, was wir für die Server-Client-Kommunikation verwenden.\nDann fügen wir auch unsere [Musik]-Kommunikation ein,\nalso fangen wir im Grunde an Öffnen Sie eine Konversation für die KI, die uns eine Interaktions-ID gibt, damit\nwir die UID hier verwenden können, ähm, und wir erhalten dann die Konversations-\nUm-Sperr-Historie, also schauen wir uns einfach unsere Datenbank an, damit wir nachsehen können, was\nwir können Schauen Sie sich unser Studio an, also hier haben wir jetzt in Gesprächen, wir haben diese Informationen von\nunserem Benutzer, die Frage und die Antwort hier, also hatte ich vorhin schon ein Gespräch,\nähm, das hier gespeichert ist, dann stellen wir diese Sprachmodellkette irgendwie zusammen Bei unserer\nEingabeaufforderungsvorlage handelt es sich hier um die Anfragevorlage, die sozusagen die folgende Benutzeraufforderung\nund das Konversationsprotokoll enthält und eine entsprechende Antwort formuliert. Die Benutzeraufforderung ist also sozusagen der\nVerlauf der Abfragekonversation, und wir geben hier eine Reihe von\nAnweisungen Und dann erstellen wir unseren Sendekanal, damit wir den\nKanal abonnieren können. Sobald wir abonniert sind, können wir im Grunde eine Sendung senden\n, und hier senden wir gerade, okay, wir fangen an Wir finden Übereinstimmungen, also\nführen wir hier unsere Get-Matches aus Einbettungen durch, also ist dies eine Art Längenkette,\neine Gliederkette sowie überwachte Client-Open-Ai-Einbettungen und der Vektor-Store.\nÄhm, wir führen nur unsere Store-Ähnlichkeitssuche durch Hier also alle Informationen, die Sie durch die Details der Längenkette durchsuchen können\n, aber auf diese Weise führen wir eine Art Ähnlichkeitssuche mit\nLangChain durch, um die relevanten Dokumente für unseren Chat zu finden, damit wir unsere Übereinstimmungen aus den Übereinstimmungen erhalten, die wir\ndann haben Unsere URLs, und wie Sie gesehen haben, haben wir diese URLs über die Konsole abgemeldet, und als letztes\nholen wir uns einfach die Match-Metadaten, besorgen den Text und die URLs, und dann bauen wir im Grunde\nunsere Eingabeaufforderungsvorlage mit den Zusammenfassungen zusammen, also wissen Sie schon von den\nzusammengefassten Details aus unseren Dokumenten, der Frage des Benutzers, dem Konversationsverlauf sowie\nden URLs und dann machen wir einfach unseren ähm ja, offenen KI-Chat hier mit dem GPT 3.5-Turbomodell\nähm und stellen das einfach hier zusammen und dann was wir Was wir tun, ist ähm, sobald wir ähm irgendwelche Updates haben\n, also funktioniert das Streaming hier im Grunde so, also sagen wir, dass Streaming wahr ist, und\njedes Mal, wenn wir eine Art neues Token bekommen, senden wir es über unseren Broadcast-Kanal\nund wo wir es dann auf der Client-Seite erhalten und am Ende, wenn die gesamte LL-Amp-Kette\nirgendwie fertig ist, aktualisieren wir einfach unsere Konversation mit der Interaktions-ID\nin der Datenbank, damit wir auch die haben Antworten von der KI in unserem Konversationsprotokoll\nähm ja, das ist so ziemlich alles, wir können uns hier den Index ansehen, also wissen Sie,\ndass der Index, den wir verwenden, clientseitig gerendert wird, ähm, wir verwenden hier den Supabase uh-Browser-Client von die Supabase-\nAuthentifizierungs-Helfer, ähm, und dann stellen wir im Grunde nur ähm zusammen, wo haben wir das hier? Ja,\nwir stellen hier sozusagen die Authentifizierung zusammen, indem wir die Superface-Authentifizierungskomponente verwenden, und dann\nhaben wir nur noch unseren Channel-Listener, also das hier Unser Supabase-Echtzeitkanal sendet also, wenn\nwir ein Chat-Ereignis\nerhalten, dann\nprüfen wir im Grunde nur, ob das eine Antwort\nist wie wir die Streaming-Art der Verwendung von Supabase in Echtzeit\nerreichen, um unsere Kundengröße zu verbessern Sie sind\ndaran interessiert, mit ähm Supabase zu erstellen, äh mit mehr mit next.js. Weitere Arten von KI-Anwendungen\ngibt es. Wir haben eine xjs-OpenAI-Dokumentsuche und diese verwendet tatsächlich das ähm versal um versal AI SDK.\nWenn Sie also daran interessiert sind, wissen Sie es Wie funktioniert das? Sie können sich das hier ansehen und wir\nhaben auch eine Video-Erklärung dazu. Vielen Dank für Ihr Einschalten und wir sehen uns im nächsten\nVideo"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "hi",
        "plaintext": "नमस्ते, आज हम सुपाबेस\nवेक्टर का उपयोग करके नेक्स्ट.जेएस और लैंगचेन के साथ एक चैटबॉट बनाने पर विचार कर रहे हैं, इसलिए अब हम अपने दस्तावेज़ के साथ चैट कर सकते हैं, तो शायद हम पूछें कि क्या सुपाबेस दूरस्थ कार्य\nप्रश्न चिह्न की अनुमति देता है, इसलिए हम इसे अभी बंद कर रहे हैं उम हम' हम मिलान ढूंढ रहे हैं और हम यहां देख सकते हैं,\nइसलिए हमें अपने मिलान मिल गए, ये दो उम सुपाबेस नौकरी पोस्टिंग हैं और फिर अब दस्तावेज़ बहुत लंबा है\nइसलिए हम दो नौकरी पोस्टिंग से जानकारी को संक्षेप में प्रस्तुत कर रहे हैं और फिर हम एक साथ\nरख रहे हैं हमारा उह प्रॉम्प्ट इसलिए हम यहां अपना प्रॉम्प्ट देख सकते हैं उह और फिर हम\nउत्तर को वापस स्ट्रीम कर रहे हैं उह हां सुपाबेस रिमोट काम का समर्थन करता है अब यह डेमो पाइनकोन उह चैटबॉट डेमो का एक कांटा है\nऔर यह वास्तव में उह रॉय द्वारा किया गया अद्भुत काम है आप ब्लॉग पोस्ट पढ़ सकते हैं, मैं इसे नीचे लिंक करूंगा,\nउम नेक्स्ट.जेएस में लिंक श्रृंखला जेएस के साथ एक बहु-उपयोगकर्ता चैटबॉट बनाने की अवधारणा है और\nउम में कुछ घटक हैं, लेकिन सबसे महत्वपूर्ण बात यह है कि मैं क्या चाहता था। यहां प्रयास करना\nएक तरह से इन उह अंतर सेवाओं में से बहुत सी क्षमताओं को\nसुपाबेस में निर्मित क्षमताओं से बदलना है, इसलिए पाइनकोन के बजाय हम सुपाबेस वेक्टर का उपयोग कर रहे हैं, हम\nकॉकरोचडीबी के बजाय सुपाबेस वास्तविक समय का उपयोग कर रहे हैं, हम इसका उपयोग कर रहे हैं पोस्टग्रेज डेटाबेस जो\nसुपाबेस स्टैक के साथ आता है और फिर फिंगरप्रिंट के बजाय हम सुपाबेस ऑथ का उपयोग कर रहे हैं, इसलिए इन सभी सेवाओं को\nहम केवल सुपाबेस में उबाल रहे हैं और एआई उम को नेक्स्ट.जेएस के साथ यहां\nआर्किटेक्चर के संदर्भ में खोल रहे हैं। चैटबॉट उम, हमारे पास दो प्रकार के घटक हैं, इसलिए हमारे पास एक इंडेक्सर है,\nजो लिखता है, उम एम्बेडिंग एक तरह से हमारे\nयहां सत्य के एम्बेडिंग उत्पन्न करता है, इसलिए हम इंडेक्सर को देख सकते हैं, इसलिए हमारे पास सत्य का हमारा स्रोत है, जो कुछ वेबसाइट है।\nहमारे पास वेबसाइट से उस जानकारी को प्राप्त करने के लिए एक क्रॉलर प्रकार है और फिर लैंगचेन और ओपन एआई का उपयोग करके\nहम अपनी एम्बेडिंग तैयार कर रहे हैं और फिर उन्हें अपने सुपरबेस वेक्टर में संग्रहीत कर रहे हैं और\nफिर जब हम अपनी तरह की सच्चाई के साथ चैट करना चाहते हैं तो मूल रूप से हम लेते हैं उपयोगकर्ता क्वेरी\nफिर से हम उस क्वेरी से एक एम्बेडिंग बनाते हैं, फिर हम\nसत्य के स्रोत के प्रासंगिक उम प्रकार को खोजने के लिए सभी दस्तावेजों के माध्यम से खोज करते हैं, हमने प्रासंगिक\nयूआरएल के प्रकार को अनुक्रमित किया है, हम उस यूआरएल से उस सामग्री को सारांशित करते हैं और फिर कहां हम एक प्रकार की प्रतिक्रिया तैयार कर रहे हैं और\nपर्यवेक्षित वास्तविक समय का उपयोग करके उसे वापस उपयोगकर्ता तक स्ट्रीम कर रहे हैं, अब लैंगचेन के साथ सबसे अच्छी बात यह है कि\nइसमें सुपबेस वेक्टर के लिए अंतर्निहित समर्थन है, इसलिए जिस तरह से हम ऐसा कर सकते हैं वह यह है कि हम बस\nइस स्कीमा को ले सकते हैं यहां और इसे वेक्टर एक्सटेंशन का उपयोग करके हमारे डेटाबेस पर लागू करें और इसलिए यदि आप\nयहां क्लोन करते हैं तो इस लिंक चेन चैटबॉट डेमो को क्लोन करें, यूआरएल विवरण में नीचे भी है,\nहम इसे उदाहरण के लिए बनाम कोड में खोल सकते हैं और हम इसे देख सकते हैं हमारे\nयहां कुछ माइग्रेशन हैं इसलिए ये प्रारंभिक माइग्रेशन हैं जिन्हें हम तब लागू करते हैं जब हम सुपाबेस स्टार्ट चलाते हैं\nताकि हम अपने स्थानीय स्टैक को शुरू करने के लिए सुपाबेस स्टार्ट को यहां चला सकें, मेरे पास यह पहले से ही चल रहा है इसलिए मैं\nस्थानीय प्रकार को देखने के लिए पर्यवेक्षित स्थिति चला सकता हूं क्रेडेंशियल्स और अगर मैं इसे यहां खोलता हूं\nतो हम देख सकते हैं कि हमने इसे लिंक चेन दस्तावेज़ से कॉपी किया है, इसलिए यह वही है जो\nहमारे सुपाबेस वेक्टर को हमारे दस्तावेज़ बनाने में सक्षम बनाता है, इसलिए मूल रूप से लैंगचेन फ्रेमवर्क\nसुपाबेस वेक्टर के साथ काम करता है और फिर एक चीज़ जो मैंने यहां विशेष रूप से\nप्रमाणित उपयोगकर्ताओं के लिए सार्वजनिक दस्तावेजों पर पूछताछ की अनुमति देने की क्षमता जोड़ी है, इसलिए यह यहां उह पंक्ति स्तर की सुरक्षा नीतियों का उपयोग कर रहा है\nऔर इसलिए हम केवल क्लाइंट पक्ष से प्रमाणित उपयोगकर्ताओं के लिए क्वेरी की अनुमति देना चाहते थे।\nक्या हम उदाहरण के लिए इसकी अनुमति दे सकते हैं और अन्यथा यह\nयहां भी वैसा ही है, जिसे यहां भूमिका स्तर की सुरक्षा में जोड़ा गया है और फिर हम\nवार्तालापों को भी संग्रहीत कर रहे हैं, इसलिए मूल रूप से आप पाठ प्रकार को जानते हैं उसमें से जो\nचैट में टाइप किया गया था और फिर एआई ने क्या जवाब दिया, इसलिए हम कन्फ्यूज़र और एआई चैटबॉट\nवार्तालापों को संग्रहीत कर रहे हैं और साथ ही हम चैट के इतिहास को याद रखना चाहते हैं और हम\nउस चैट इतिहास को भी इसमें शामिल कर रहे हैं। पिछली बातचीत के इतिहास को भी जानने के लिए प्रेरित करें\nऔर फिर से हम यहां विशेष रूप से एक प्रकार की भूमिका स्तर की सुरक्षा नीति लागू कर रहे हैं ताकि केवल\nउपयोगकर्ता ही अपनी तरह की बातचीत को देख सके जिसे आप चैटबॉट के साथ जानते हैं।\nउह, तो हम यहां इस तरह की जानकारी को लॉक कर रहे हैं, ठीक है, तो आइए वास्तव में एक नजर डालते हैं,\nउम हम इसे चला सकते हैं, इसलिए हम कह सकते हैं कि एनपीएम रन डीईएफ़, इसलिए सबसे पहले आप जानते हैं कि हमारे पास स्थानीय रूप से चलने वाला सुपाबेस है\nऔर फिर हमारे पास उम भी है। उह चैट बॉट यहां स्थानीय रूप से चल रहा है और यह\nसुपबेस ऑथ के साथ आता है इसलिए यह वास्तव में प्रतिक्रिया के लिए ऑथ यूआई है लेकिन फिर सबसे पहले हम\nकुछ जानकारी क्रॉल करना चाहते हैं और आप जानते हैं कि उदाहरण के लिए हम यहां भर्ती कर रहे हैं यदि आप नहीं जानते थे\nउदाहरण के लिए आप सुपाबेस करियर की जांच कर सकते हैं, हम ग्राहकों के लिए सॉल्यूशंस आर्किटेक्ट को काम पर रख रहे हैं\nऔर यह पूरी नौकरी का विवरण है, यहां बहुत सारी जानकारी है, आप\nजानते हैं जैसे 100 प्रतिशत दूरस्थ कार्य, कंपनी में ईएसओपी, इक्विटी स्वामित्व, उम, हाँ, ढेर सारा\nसामान । तो आप जानते हैं कि आइए अपने जीवन को आसान बनाएं उह और आइए वास्तव में इसे क्रॉल करें इसलिए एपीआई स्लैश क्रॉल\nउम हम यहां अपनी नौकरी का विवरण क्रॉल कर सकते हैं और जो हम देख सकते हैं वह यह है कि अब हम अपने चॉप्स को क्रॉल कर रहे हैं और\nहम क्रॉल भी कर रहे हैं इसलिए क्रॉलर प्रकार कुछ हद तक पुनरावर्ती चीज़ करता है जहां यह\nउम उह पृष्ठों को क्रॉल करता है जो इसमें एक तरह से जुड़े हुए उह भी हैं और फिर हम देख सकते हैं कि ठीक है यह अब हो गया है\nउम इसलिए यदि हम जाते हैं तो हम वास्तव में क्या देख सकते हैं उम सुपाबेस स्टूडियो यहां है इसलिए हमारे पास फिर से लोकलहोस्ट है\nयदि आपको याद नहीं है तो हम पर्यवेक्षित प्रारंभ चलाने के बाद सुपाबेस स्थिति कर सकते हैं हम\nयहां अपना स्थानीय विवरण प्राप्त कर सकते हैं और इसलिए हम इस परियोजना को स्थानीय रूप से यहां खोल सकते हैं और\nअब हम देख सकते हैं हमारी अपनी बातचीत होती है इसलिए हमने अभी तक कोई बातचीत नहीं की है, लेकिन यहां हमारे\nदस्तावेज़ हैं इसलिए यह वह है जिसे हमने क्रॉल किया है, यहां हमारे पास हमारे वेक्टर एम्बेडिंग हैं और आप\nकोड की तरह की लाइनें देख सकते हैं, उह लाइनें नहीं कोड का, इसलिए कुछ मेटाडेटा भी है और\nये एक तरह की लाइनें हैं, इसलिए दस्तावेज़ अलग-अलग खंडों में टूट गए हैं, इसलिए\nमेटाडेटा का उपयोग करके हम कुछ फ़िल्टरिंग भी कर सकते हैं, इसलिए यह\nपोस्टग्रेज़ में वास्तव में शक्तिशाली है जहां हमारे पास JSON है B डेटा प्रकार इसलिए हम पूरे प्रकार के Json दस्तावेज़ों को\num में छोड़ सकते हैं, आप जानते हैं कि आप हमारे दस्तावेज़ों को यहां मेटाडेटा के रूप में जानते हैं, इसलिए अब हमने इसे क्रॉल कर लिया है, हमारे पास\nयह हमारे डेटाबेस में है, इसलिए अब हम जो कर सकते हैं वह वास्तव में है उस क्रॉलर ने कैसे काम किया, इस पर एक नज़र डालें,\nयह हमारे पेज एपीआई में है और फिर यहां क्रॉल करें, इसलिए हम लंबाई श्रृंखला का उपयोग कर रहे हैं, हम\nलैंगचेन से हमारे ओपनई एम्बेडिंग का उपयोग कर रहे हैं और फिर हम सुपाबेस वेक्टर स्टोर का उपयोग कर रहे हैं, इसलिए यह वास्तव में अच्छा है\nएक प्रकार की लंबाई श्रृंखला को सुपबेस वेक्टर स्टोर के साथ एकीकृत किया गया है और फिर वास्तव में\nक्वेरी से हमें यूआरएल मिल रहे हैं जिन्हें हम अनुक्रमित करना चाहते हैं हम एक तरह का\nदस्तावेज़ संग्रह बना रहे हैं इसलिए हम तरह-तरह से विभाजित हो रहे हैं अनुभाग यह सुनिश्चित करने के लिए कि हमारे पास एंबेडिंग बनाने के लिए उम प्रकार का\nअधिकार है जिसे आप आकार उम जानते हैं, ताकि हम यहां दस्तावेजों के\nटोकन आकार उम विभाजन प्रकार से बाहर न निकलें और फिर हम अपना निर्माण कर रहे हैं इतनी खुली एआई\nएम्बेडिंग को एम्बेड करते हुए हम अपना सुपाबेस वेक्टर स्टोर बना रहे हैं, बस यहां एक सुपाबेस एडमिन क्लाइंट डाल रहे हैं,\nइसलिए सुपाबेस एडमिन क्लाइंट यहां केवल um का उपयोग करता है, हम देख सकते हैं कि वह निजी कुंजी का उपयोग करता है जो\nहमारी यहां हमारी सेवा भूमिका कुंजी है और फिर हम कर सकते हैं तरह-तरह के एडमिन ऑपरेशन्स करते हैं जो\nइन दस्तावेज़ों को सम्मिलित कर रहे हैं और इसलिए हम अपने दस्तावेज़ संग्रह में एक तरह का निर्माण कर रहे हैं,\nसभी दस्तावेज़ों को संग्रहीत करने के लिए कुछ जोड़ रहे हैं और फिर हमारे पास हमारे डेटाबेस में दस्तावेज़ हैं\nऔर फिर हम खोज कर सकते हैं उन पर तो चलिए उस पर चलते हैं, इसलिए सबसे पहले हमें लॉग\nइन करना होगा इसलिए वर्तमान में यदि हम यहां अपने प्रोजेक्ट को देखते हैं तो हम लोकलहोस्ट पर फिर से चल रहे हैं, हम\nपूरे उह सुपाबेस स्टैक को स्थानीय रूप से चला रहे हैं और हम नहीं करते हैं अभी तक कोई भी उपयोगकर्ता नहीं है, तो आइए\nयहां टेस्ट डॉट डी और उम पर एक नए उपयोगकर्ता परीक्षक को साइन अप करें, इसलिए यदि हम कहते हैं कि साइन इन करें, तो हम नहीं जानते कि आप अमान्य\nक्रेडेंशियल्स जानते हैं क्योंकि हमने ऐसा नहीं किया है, इसलिए आइए साइन अप करें और फिर हमें इसकी आवश्यकता है।\nवार्तालाप लिंक के लिए हमारे ईमेल की जांच करें, अब हम लोकलहोस्ट पर चल रहे हैं इसलिए हम यहां वास्तविक ईमेल नहीं भेज रहे हैं,\nलेकिन हम क्या कर सकते हैं कि हमारे पास बकेट में कॉल की गई सेवा है जो वास्तव में एक अच्छी ओपन\nसोर्स सेवा भी है और हम यहां देख सकते हैं कि हमारे पास आपके ईमेल की पुष्टि है, इसलिए यह अभी-\nअभी भेजा गया था और हम क्लिक कर सकते हैं और अपने ईमेल पते की पुष्टि कर सकते हैं और अब हम देख सकते हैं कि हम लॉक हो गए हैं\nउम हमारा एप्लिकेशन यहां है, मैं लोकलहोस्ट पर चल रहा हूं, इसलिए अब हम अपने दस्तावेज़ों के साथ चैट कर सकते हैं, इसलिए शायद\nहम पूछें कि क्या सुपाबेस दूरस्थ कार्य प्रश्न चिह्न की अनुमति देता है, इसलिए हम इसे अभी बंद कर रहे हैं, उम हम\nमैच ढूंढ रहे हैं और हम यहां देख सकते हैं हमने अपना मिलान पाया, ये दो उम सुपाबेस नौकरी\nपोस्टिंग हैं और फिर अब दस्तावेज़ बहुत लंबा है इसलिए हम\nदो नौकरी पोस्टिंग से जानकारी को सारांशित कर रहे हैं और फिर हम अपना उम प्रॉम्प्ट एक साथ रख रहे हैं ताकि हम यहां देख सकें हमारा संकेत\nऔर फिर हम उत्तर को वापस स्ट्रीम कर रहे हैं उह हां सुपाबेस दूरस्थ कार्य का समर्थन करता है\nउम पूरी तरह से दूरस्थ संचार ईमेल वीडियो यदा यादा पर होगा और यह बिल्कुल वैसा ही है\nउह इसलिए यह पूरी तरह से उम्मीद के मुताबिक काम कर रहा है आइए एक नजर डालते हैं कि\nवास्तविक स्थिति कैसी है उह चैट कार्यक्षमता फिर से काम कर रही है, उम इसका मुख्य भाग यहाँ\nचैट डॉट टीएस में है हाँ फिर से उह एक प्रकार की लैंगचेन उह सामान खुला एआई हमारे पास यहाँ एक त्वरित टेम्पलेट है\nउम और फिर हमें अपना सारांश मिल गया है और यहाँ प्रामाणिक सहायकों का उपयोग कर रहे हैं हम एक पेज\nसर्वर क्लाइंट बना रहे हैं, जो हमारे क्लाइंट के लिए एक सर्वर साइट की तरह है, जिसका उपयोग हम\nसर्वर पर विभिन्न प्रकार की प्रमाणित क्वेरी करने के लिए कर सकते हैं और इसलिए हम सिर्फ अपना सुपरबेस ऑथ\nक्लाइंट प्राप्त कर रहे हैं, इसलिए हमारा पर्यवेक्षित ऑथ क्लाइंट आ रहा है। यहां नीचे से हम\nउह पेज उह सर्वर क्लाइंट उह बना रहे हैं और अनुरोध और प्रतिक्रिया में कुछ वास्तविक समय की\nजानकारी डाल रहे हैं इसलिए हम यहां दर सीमा को अक्षम कर रहे हैं हम इसे माइनस वन के साथ कर सकते हैं इसलिए हम सिर्फ\nस्ट्रीम करना चाहते हैं किसी भी प्रकार का अधिकार है कि हम आ रहे हैं तो हम अपना सत्र प्राप्त कर रहे हैं और यदि हम\nप्रमाणित हैं तो हमारे पास यहां है यदि हमारे पास एक सत्र है तो हम सक्रिय हो सकते हैं और अपनी चैट को संभाल सकते हैं\nउम और यहां क्या हो रहा है इसलिए हम हैं अब उपयोगकर्ता आईडी के साथ वास्तविक समय चैनल\nप्राप्त करने के लिए सबसे पहले अपने ऑफ़लाइन का उपयोग कर रहे हैं, इसलिए हम सर्वर क्लाइंट संचार के लिए इसका उपयोग कर रहे हैं\n, फिर हम अपना [संगीत] उम संचार भी डाल रहे हैं,\nइसलिए मूल रूप से हम शुरू कर रहे हैं एआई के लिए एक वार्तालाप बंद करें जो हमें एक इंटरेक्शन आईडी देता है ताकि\nहम यहां यूआईडी का उपयोग कर सकें और हम फिर वार्तालाप प्राप्त कर रहे हैं\nउम लॉक इतिहास तो यह सिर्फ हमारे डेटाबेस को देखने जैसा है ताकि हम देख सकें कि हम\nकर सकते हैं हमारे स्टूडियो को देखें, इसलिए अब हमारे पास वार्तालापों में\nहमारे उपयोगकर्ता से यह जानकारी है, यहां प्रश्न और प्रतिक्रिया है, इसलिए मेरे पास पहले से ही एक वार्तालाप था,\nउम जो यहां संग्रहीत है, फिर हम इस प्रकार का उपयोग करके इस भाषा मॉडल श्रृंखला को एक साथ रख रहे हैं हमारा\nप्रॉम्प्ट टेम्प्लेट, यह पूछताछ टेम्प्लेट है, यहां निम्नलिखित उपयोगकर्ता प्रॉम्प्ट\nऔर वार्तालाप लॉग दिए गए हैं, जो प्रासंगिक प्रतिक्रिया तैयार करते हैं, इसलिए उपयोगकर्ता प्रॉम्प्ट एक तरह से\nक्वेरी वार्तालाप इतिहास है और हम इसे यहां निर्देशों का एक समूह दे रहे हैं,\nहम वहां जाते हैं और फिर हम जो कर रहे हैं वह यह है कि हम अपना प्रसारण चैनल बना रहे हैं ताकि हम\nचैनल की सदस्यता ले सकें और मूल रूप से एक बार सदस्यता लेने के बाद हम एक प्रसारण भेज सकते हैं\nऔर इसलिए यहां हम अभी भेज रहे हैं ठीक है हम शुरू कर रहे हैं हम मिलान ढूंढ रहे हैं, इसलिए यहां हम\nएम्बेडिंग से मिलान प्राप्त कर रहे हैं, इसलिए यह एक लंबाई श्रृंखला की तरह है,\nलिंक श्रृंखला भी है, इसलिए पर्यवेक्षित क्लाइंट एआई एम्बेडिंग और वेक्टर स्टोर खोलते हैं,\nहम सिर्फ अपना स्टोर समानता खोज रहे हैं यहां वह सारी जानकारी है जिसे आप\nलंबाई श्रृंखला विवरण के माध्यम से खोज सकते हैं, लेकिन इस तरह हम\nअपनी चैट के लिए प्रासंगिक दस्तावेज़ ढूंढने के लिए लैंगचेन के साथ हमारी समानता खोज रहे हैं ताकि हम अपने मैचों से हमारे मिलान प्राप्त कर सकें\n। हमारे यूआरएल और आपने देखा कि हमने कंसोल से उन यूआरएल को लॉग आउट कर दिया है और फिर अंत में हम\nटेक्स्ट और यूआरएल प्राप्त करने के लिए मैच मेटाडेटा प्राप्त कर रहे हैं और फिर हम मूल रूप से\nसारांश के साथ हमारे प्रॉम्प्ट टेम्पलेट का निर्माण कर रहे हैं ताकि आप जान सकें हमारे दस्तावेज़ों से\nसारांशित विवरण, उपयोगकर्ता से बातचीत के इतिहास के साथ-साथ\nयूआरएल के बारे में प्रश्न और फिर हम जीपीटी 3.5 टर्बो मॉडल\nउम का उपयोग करके यहां अपना उम, हां ओपन एआई चैट कर रहे हैं और बस इसे यहां एक साथ रख रहे हैं और फिर हम क्या कर रहे हैं हम कर रहे हैं, एक बार जब हमारे पास कोई अपडेट होगा\nतो मूल रूप से स्ट्रीमिंग यहां इसी तरह काम करती है, इसलिए हम स्ट्रीमिंग को सही कह रहे हैं और\nजब भी हमें एक नया टोकन मिल रहा है तो हम इसे अपने प्रसारण चैनल के माध्यम से भेज रहे हैं।\nऔर जहां हम इसे क्लाइंट साइड पर प्राप्त करते हैं और फिर अंत में जब उम संपूर्ण एलएल एम्प श्रृंखला\nसमाप्त हो जाती है तो हम डेटाबेस में इंटरेक्शन आईडी के साथ अपनी बातचीत को अपडेट कर रहे हैं\nताकि हमारे पास भी हो हमारे वार्तालाप लॉग में एआई से उत्तर,\nहां, यह काफी हद तक है, हम यहां सूचकांक को देख सकते हैं, इसलिए जिस सूचकांक का हम उपयोग कर रहे हैं, आप जानते हैं\nकि यह क्लाइंट-साइड रेंडर किया गया है, इसलिए हम यहां से सुपाबेस उह ब्राउज़र क्लाइंट का उपयोग कर रहे हैं। सुपाबेस\nऑथ हेल्पर्स उह और फिर काफी हद तक हम बस एक साथ रख रहे हैं उम हमारे पास यह यहां कहां है हां\nहम यहां सुपरफेस ऑथ कंपोनेंट का उपयोग करके ऑथ को एक साथ रख रहे हैं और फिर हमारे\nपास सिर्फ हमारा चैनल श्रोता है इसलिए यह है हमारा सुपबेस उह वास्तविक समय चैनल प्रसारित करता है, इसलिए जब\nहमें कोई चैट इवेंट मिलता है तो हम मूल रूप से बस यह जांचते हैं कि ठीक है क्या यह एक प्रतिक्रिया है, यह एक स्थिति संदेश है\nउह प्रतिक्रिया और आपके पास क्या है और फिर हम बस अपने चैटबॉट संदेश को अपडेट करते हैं उह और यह एक\nतरह का है हम अपने ग्राहक आकार के लिए सुपाबेस वास्तविक समय का उपयोग करके स्ट्रीमिंग प्रकार कैसे प्राप्त करते हैं, हाँ\nउम यह काफी हद तक उम है, इस तरह से आप इन सभी विभिन्न सेवा\nप्रदाताओं को मूल रूप से उह सुपर गति के भीतर बंडल कर सकते हैं ताकि कार्यक्षमता उपलब्ध हो सके आप\nउम सुपाबेस के साथ निर्माण में रुचि रखते हैं, नेक्स्ट.जेएस के साथ और अधिक प्रकार के एआई एप्लिकेशन\nहैं, हमारे पास एक एक्सजेएस ओपनई डॉक खोज है और यह वास्तव में उम वर्सल उम वर्सल एआई एसडीके का उपयोग करता है, इसलिए\nयदि आप इसमें रुचि रखते हैं तो आप इस बारे में जान सकते हैं। यह कैसे काम करता है, आप इसे यहां देख सकते हैं और हमारे पास इसके लिए एक वीडियो स्पष्टीकरण भी\nहै, इसलिए इसमें शामिल होने के लिए बहुत बहुत धन्यवाद और अगले\nविदेशी वीडियो में मिलते हैं"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "id",
        "plaintext": "hai hari ini kita sedang mempertimbangkan untuk membuat chatbot dengan next.js dan LangChain menggunakan Supabase\nVector jadi sekarang kita bisa ngobrol dengan dokumen kita jadi mungkin mari kita bertanya apakah Supabase mengizinkan\ntanda tanya kerja jarak jauh jadi kita meluncurkannya sekarang um kita' sedang menemukan kecocokannya dan kita bisa lihat di sini\njadi kami menemukan kecocokan kami. Ini adalah dua lowongan pekerjaan Supabase ini dan sekarang dokumennya\nterlalu panjang jadi kami merangkum informasi dari dua lowongan pekerjaan itu dan kemudian kami menyusunnya\nbersama-sama um prompt kami jadi um kami dapat melihat di sini prompt kami uh dan kemudian kami mengalirkan kembali jawabannya\nuh ya Supabase mendukung pekerjaan jarak jauh sekarang demo ini adalah cabang dari\ndemo chatbot Pinecone uh dan ini benar-benar karya yang luar biasa dari uh Roy di sini Anda dapat membaca posting blog Saya akan menautkannya di bawah\num semacam konsep membangun chatbot multi-pengguna dengan rantai tautan JS di next.js dan\num ada beberapa komponen di dalamnya tetapi um yang paling penting adalah apa yang saya inginkan untuk mencoba di sini adalah\nmengganti banyak layanan perbedaan uh ini dengan kemampuan yang dibangun\ndi Supabase jadi alih-alih Pinecone kami menggunakan Supabase Vector alih-alih cakap kami\nmenggunakan Supabase real time alih-alih cockroachdb kami menggunakan database postgres yang datang dengan\ntumpukan Supabase dan alih-alih sidik jari kami menggunakan Supabase auth jadi semua Layanan ini\nkami meringkasnya menjadi Supabase saja dan membuka AI um dengan next.js di sini sekarang dalam hal\narsitektur untuk chatbot um kami memiliki dua komponen jadi kami memiliki pengindeks\num yang semacam menulis um embeddings menghasilkan embeddings dari diri kami sendiri. Kebenaran\ndi sini sehingga kami dapat melihat pengindeks sehingga kami memiliki sumber Kebenaran yang merupakan beberapa situs web kami memiliki\njenis perayap yang mendapatkan informasi itu dari situs web dan kemudian menggunakan LangChain dan AI terbuka,\nkami membuat penyematan kami dan kemudian menyimpannya di vektor Supabase kami dan\nkemudian ketika kami ingin mengobrol dengan jenis Kebenaran kami sendiri pada dasarnya kami mengambil kueri pengguna\nlagi kami membuat penyematan dari kueri itu, kami kemudian menelusuri semua dokumen\nuntuk menemukan jenis yang relevan um semacam sumber kebenaran yang kami indeks jenis\nURL yang relevan, kami merangkum konten dari URL itu dan kemudian di mana kami menghasilkan semacam respons dan\nmengalirkannya kembali ke pengguna menggunakan waktu nyata yang diawasi. Sekarang hal hebat tentang LangChain adalah\num ia memiliki dukungan bawaan untuk Supabase Vector jadi cara kami melakukan ini adalah kami cukup mengambil\nskema ini di sini dan menerapkannya ke database kami menggunakan ekstensi vektor dan jadi jika Anda mengkloning\ndi sini mengkloning demo chatbot rantai tautan ini, URL-nya juga ada di bawah dalam deskripsi,\nkami kemudian dapat membukanya dalam kode vs misalnya dan kami dapat melihatnya kami memiliki beberapa migrasi\ndi sini jadi ini adalah migrasi awal yang kami terapkan ketika kami menjalankan Supabase start\nsehingga kami dapat menjalankan Supabase start di sini untuk memulai tumpukan lokal kami. Saya sudah menjalankannya sehingga saya\ndapat menjalankan status diawasi untuk melihat jenis lokal kredensial dan jika saya membukanya di sini\nsehingga kita dapat melihat bahwa kita baru saja menyalin ini dari dokumentasi rantai tautan jadi inilah yang memungkinkan\nVektor Supabase kami membuat dokumen kami sehingga pada dasarnya membuat kerangka LangChain\nberfungsi dengan vektor Supabase dan kemudian satu hal itu Saya telah menambahkan secara khusus di sini\nadalah kemampuan untuk mengizinkan kueri pada dokumen publik untuk pengguna yang diautentikasi jadi ini menggunakan\nkebijakan keamanan tingkat baris di sini jadi kami hanya ingin mengizinkan kueri untuk\npengguna yang diautentikasi dari sisi klien. bisakah kita mengizinkannya misalnya dan sebaliknya sama saja\ndi sini seperti ini yang ditambahkan dalam tingkat keamanan peran di sini dan kemudian kami juga\nmenyimpan percakapan sehingga pada dasarnya um Anda tahu jenis teksnya dari itu diketik\nke dalam obrolan dan kemudian apa yang dibalas AI sehingga kami menyimpan\npercakapan pengacau dan chatbot AI serta kami ingin mengingat riwayat obrolan dan kami juga memasukkan\nriwayat obrolan itu ke dalam diminta untuk juga mengetahui riwayat percakapan sebelumnya\ndan sekali lagi kami menerapkan semacam kebijakan keamanan tingkat peran di sini secara khusus sehingga hanya\npengguna yang dapat melihat jenis percakapan mereka sendiri yang Anda kenal dengan chatbot\nuh jadi kami mengunci jenis informasi di sini oke bagus jadi mari kita lihat\num kita bisa menjalankan ini jadi kita bisa mengatakan npm run def jadi pertama-tama Anda tahu kami menjalankan Supabase\nsecara lokal dan kemudian kami juga memiliki um kami eh chat bot di sini berjalan secara lokal dan\num dilengkapi dengan Supabase auth jadi ini adalah UI auth untuk bereaksi sebenarnya tetapi pertama-tama kami ingin\nmerayapi beberapa informasi dan Anda tahu di sini misalnya kami sedang merekrut jika Anda tidak tahu\nAnda dapat melihat karir Supabase misalnya kami sedang merekrut pelanggan Arsitek solusi\ndan ini adalah keseluruhan deskripsi pekerjaan di sini ada banyak informasi di sana Anda\ntahu seperti 100 persen pekerjaan jarak jauh um ESOP di perusahaan Kepemilikan ekuitas um ya banyak sekali\nbarang jadi tahukah Anda mari kita buat hidup kita lebih mudah uh dan mari kita jelajahi ini jadi perayapan garis miring API\num kita bisa merayapi uraian tugas kita di sini dan apa yang bisa kita lihat adalah sekarang kita sedang merayapi um bagian kita dan\nkita juga merayapi jadi jenis perayap of melakukan sedikit hal rekursif di mana ia merayapi um\nhalaman uh yang tertaut um di dalamnya juga dan kemudian kita bisa melihat oke ini selesai sekarang\num jadi apa yang sebenarnya bisa kita lihat sekarang jika kita pergi ke Supabase Studio di sini jadi kami memiliki localhost\nlagi jika Anda tidak ingat, kami dapat melakukan status Supabase setelah kami menjalankan permulaan yang diawasi, kami\ndapat memperoleh detail lokal kami di sini sehingga kami dapat membuka proyek ini secara lokal di sini dan\nsekarang kami dapat melihat di kami melakukan percakapan jadi kami belum melakukan percakapan apa pun tetapi di sini kami memiliki\ndokumen kami jadi ini um apa yang telah kami jelajahi eh di sini kami memiliki penyematan Vektor kami uh dan Anda\ndapat melihat jenis baris kode um bukan baris kode jadi ada beberapa metadata juga dan\nini adalah semacam baris sehingga dokumen dipecah menjadi beberapa bagian yang berbeda jadi\num dengan menggunakan metadata kita kemudian dapat melakukan beberapa pemfilteran sehingga sangat kuat di\npostgres di mana kita memiliki Json Tipe data B sehingga kami dapat memasukkan seluruh jenis dokumen Json ke\num Anda tahu Anda tahu dokumen kami di sini sebagai metadata yang bagus jadi sekarang kami telah merayapi ini, kami memilikinya\ndi database kami jadi sekarang yang dapat kami lakukan adalah mari kita benar-benar memilikinya lihat bagaimana perayap itu bekerja jadi\nini ada di API Halaman kami dan kemudian merangkak di sini jadi kami menggunakan rantai panjang kami menggunakan\nembeddings openai dari LangChain dan kemudian kami menggunakan toko Supabase Vector jadi ini sangat rapi untuk\nsemacam rantai panjang terintegrasi dengan penyimpanan Supabase Vector dan kemudian benar-benar hanya uh\ndari kueri kami mendapatkan URL yang ingin kami indeks um kami membuat semacam\nkoleksi dokumen jadi kami membagi jenisnya bagian untuk memastikan kami memiliki um jenis yang tepat,\nAnda tahu ukuran um untuk membuat penyematan sehingga kami tidak kehabisan ukuran token\num memisahkan semacam dokumen di sini dan kemudian kami membuat penyematan jadi\npenyematan AI terbuka kami membuat toko Supabase Vector kami hanya memasukkan klien admin Supabase\ndi sini jadi klien admin Supabase hanya menggunakan um di sini kita dapat melihat bahwa menggunakan kunci pribadi yang merupakan\nkunci peran layanan kami di sini uh dan kemudian kita bisa melakukan jenis operasi admin yang\nmemasukkan dokumen-dokumen ini dan jadi kami kemudian um ya membuat semacam koleksi dokumen kami\num menambahkan semacam menyimpan semua dokumen dan kemudian kami memiliki dokumen di sini di database kami\ndan kami kemudian dapat melakukan pencarian pada mereka jadi mari kita lanjutkan ke sana jadi pertama-tama kita harus masuk\nJadi saat ini jika kita melihat proyek kita di sini um jadi kita menjalankannya lagi di localhost kita menjalankan\nseluruh tumpukan uh Supabase secara lokal dan kita tidak belum punya pengguna, jadi ayo daftar\npenguji pengguna baru di test dot de dan um di sini jadi kalau kita bilang masuk um, kita tidak, kamu tahu\nkredensialnya tidak valid karena kita belum, jadi ayo daftar, lalu kita perlu periksa email kami untuk\ntautan percakapan sekarang kami berjalan di localhost jadi kami tidak mengirimkan email sebenarnya di sini\ntapi apa yang bisa kami lakukan adalah kami memiliki layanan yang disebut dalam ember yang\njuga merupakan layanan Sumber Terbuka yang sangat keren dan kita dapat melihat di sini kami telah mengkonfirmasi email Anda jadi yang ini uh baru saja\ndikirim dan kita dapat mengklik dan mengonfirmasi alamat email kami dan sekarang kami dapat melihat bahwa kami terkunci di dalamnya\num aplikasi kita di sini saya berjalan di localhost jadi sekarang kita bisa ngobrol dengan dokumen kita jadi mungkin\nmari kita bertanya apakah Supabase mengizinkan pekerjaan jarak jauh tanda tanya jadi kami meluncurkannya sekarang um kami menemukan\nkecocokan dan kita bisa melihatnya di sini jadi kami menemukan kecocokan kami ini adalah dua\nlowongan pekerjaan um Supabase ini uh dan sekarang dokumennya terlalu panjang jadi kami merangkum informasi dari\ndua lowongan pekerjaan tersebut dan kami kemudian menyusun prompt um kami sehingga um dapat kami lihat di sini permintaan kami\ndan kemudian kami streaming kembali jawabannya uh ya Supabase mendukung pekerjaan jarak jauh\num komunikasi jarak jauh sepenuhnya akan terjadi melalui email video yada yada dan itulah tepatnya\num jadi ini berfungsi uh sepenuhnya seperti yang diharapkan mari kita lihat bagaimana\num sebenarnya fungsionalitas obrolan berfungsi jadi lagi um intinya ada di sini\ndi titik obrolan TS Ya lagi uh semacam LangChain uh barang terbuka AI kami memiliki templat cepat di sini\num dan kemudian kami mendapatkan ringkasan kami dan di sini menggunakan pembantu autentikasi kami membuat\nklien server Pages yang merupakan jenis situs server klien kami yang dapat kami gunakan untuk melakukan semacam\nkueri yang diautentikasi di server, jadi kami baru saja mendapatkan\nklien autentikasi Supabase sehingga klien autentikasi yang diawasi kami akan datang dari sini jadi kami membuat\num uh Halaman uh klien server uh memasukkan permintaan dan respons beberapa\ninformasi real-time jadi kami menonaktifkan batas kecepatan di sini kami bisa melakukannya dengan yang minus jadi kami hanya\ningin streaming baiklah, kami datang lalu kami mendapatkan sesi kami dan jika kami\ndiautentikasi maka kami ada di sini, jika kami memiliki sesi, kami kemudian dapat memulai dan menangani obrolan kami\num dan apa yang terjadi di sini adalah jadi kami sekarang menggunakan offline kita terlebih dahulu untuk mendapatkan\nSaluran real-time dengan ID pengguna jadi itulah yang kita gunakan untuk komunikasi klien server\neh lalu kita juga memasukkan [Musik] um komunikasi kita\num jadi pada dasarnya kita mulai dari percakapan untuk AI yang memberi kita ID interaksi jadi\nkita bisa menggunakan uid di sini um dan kita kemudian mendapatkan percakapan\num riwayat kunci jadi itu hanya melihat database kita jadi um kita bisa melihat\nkita bisa lihat studio kami jadi di sini kami sekarang melakukan percakapan. Kami mendapat informasi ini dari\npengguna kami, pertanyaan dan responsnya di sini, jadi saya sudah melakukan satu percakapan sebelumnya\num yang disimpan di sini, lalu kami menyusun um rantai model bahasa ini menggunakan jenis template prompt kami\nini adalah template pertanyaan di sini diberikan prompt pengguna berikut\ndan log percakapan dirumuskan respons yang relevan sehingga prompt pengguna adalah semacam\nriwayat percakapan kueri dan kami semacam memberikannya banyak instruksi di sini\num ini dia lalu apa yang kita lakukan adalah membuat saluran siaran sehingga kita\nbisa berlangganan Saluran dan pada dasarnya setelah kita berlangganan maka kita bisa mengirim siaran\ndan jadi di sini kita baru saja mengirim oke kita mulai kita sedang menemukan kecocokan jadi di sini kami\nmelakukan pencarian kecocokan dari penyematan jadi ini semacam rantai panjang\num rantai tautan juga jadi klien yang diawasi membuka penyematan Ai dan penyimpanan vektor\num kami hanya melakukan pencarian kesamaan toko kami di sini jadi semua informasi itu dapat Anda gali\nmelalui detail rantai panjang tetapi ini adalah cara kami melakukan pencarian kesamaan dengan\nLangChain untuk menemukan dokumen yang relevan untuk obrolan kami sehingga kami mendapatkan kecocokan dari kecocokan yang\nkemudian kami miliki URL kami dan kami, Anda lihat, kami konsol keluar dari URL tersebut dan terakhir kami\nhanya mendapatkan metadata yang cocok, mendapatkan teks dan urlnya, lalu pada dasarnya kami\nMembangun Bersama template cepat kami dengan ringkasan sehingga Anda tahu jenisnya dari\ndetail yang dirangkum dari dokumen kami pertanyaan dari pengguna riwayat percakapan serta\nURL dan kemudian kami hanya melakukan um ya buka obrolan AI di sini menggunakan model turbo GPT 3.5\num dan hanya menggabungkannya di sini dan kemudian apa yang kami yang kami lakukan adalah um setelah kami mendapatkan um pembaruan apa pun,\njadi pada dasarnya seperti itulah cara kerja streaming di sini, jadi kami mengatakan streaming itu benar dan\nkapan pun kami mendapatkan token baru, kami kemudian mengirimkannya melalui saluran siaran kami\ndan di mana kita kemudian mendapatkannya di sisi klien dan kemudian pada akhirnya ketika um seluruh rantai amp LL sudah\nselesai, kita kemudian hanya memperbarui percakapan kita uh dengan ID interaksi\ndalam database sehingga kita juga memiliki jawaban dari AI di log percakapan kita\num ya itu cukup banyak kita dapat melihat indeks di sini jadi dalam indeks yang kami gunakan, Anda tahu\nini adalah sisi klien yang diberikan um jadi kami menggunakan klien browser Supabase uh di sini dari pembantu autentikasi Supabase\nuh dan kemudian kita hanya menyusunnya um di mana kita memilikinya di sini ya\nkita semacam memasang um menyusun autentikasi menggunakan komponen autentikasi superface di sini dan kemudian kita\nhanya memiliki pendengar Saluran kita jadi ini Supabase kami uh siaran Saluran real-time jadi ketika\nkami mendapatkan acara obrolan, pada dasarnya kami hanya memeriksa oke apakah ini respons ini adalah pesan status\nuh respons dan apa yang Anda uh lalu kami baru saja memperbarui pesan chatbot kami uh dan\nbegitulah tentang bagaimana kami mendapatkan jenis streaming menggunakan Supabase waktu nyata ke um ukuran klien kami ya\num itu cukup banyak um ini adalah bagaimana Anda bisa mendapatkan semua\npenyedia layanan yang berbeda ini dibundel pada dasarnya dalam kecepatan super sehingga fungsionalitas tersedia jika Anda\ntertarik untuk membangun dengan um Supabase uh dengan lebih banyak dengan next.js lebih banyak jenis aplikasi AI\ndi sana kami memiliki pencarian dokumen xjs openai dan ini sebenarnya menggunakan umversal umversal AI SDK jadi\njika Anda tertarik, Anda tahu jenisnya bagaimana cara kerjanya eh kamu bisa lihat ini di sini dan kami juga\npunya video penjelasannya jadi terima kasih banyak sudah menyimak dan sampai jumpa di video berikutnya\n."
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "it",
        "plaintext": "ciao a tutti oggi stiamo cercando di costruire un chatbot con next.js e LangChain usando Supabase\nVector quindi ora possiamo chattare con il nostro documento quindi forse chiediamo se Supabase consente\nil punto interrogativo di lavoro remoto quindi lo stiamo attivando ora ehm noi' stiamo trovando le corrispondenze e possiamo vedere qui\nquindi abbiamo trovato le nostre corrispondenze queste sono queste due offerte di lavoro di Supabase e poi ora il documento è\ntroppo lungo quindi stiamo riassumendo le informazioni delle due offerte di lavoro e poi le stiamo mettendo\ninsieme il nostro prompt um quindi possiamo vedere qui il nostro prompt uh e poi riproduciamo in streaming la\nrisposta uh sì Supabase supporta il lavoro remoto ora questa demo è un fork della\ndemo Pinecone uh chatbot e questo è davvero fantastico lavoro di uh Roy qui puoi leggere il post sul blog, lo collegherò di seguito,\nuna specie di concetto di creazione di un chatbot multiutente con catena di collegamenti JS in next.js e\num, ci sono un paio di componenti ma, soprattutto, quello che volevo provare qui è\nin un certo senso sostituire molti di questi servizi uh differenze con le funzionalità integrate\nin Supabase quindi invece di Pinecone stiamo usando Supabase Vector invece di abilmente stiamo\nusando Supabase real time invece di cockroachdb stiamo usando il postgres fornito con\nlo stack Supabase e quindi invece dell'impronta digitale stiamo utilizzando l'autenticazione Supabase, quindi tutti questi servizi\nli stiamo riducendo solo a Supabase e apriamo AI um con next.js qui ora in termini\ndi architettura per il chatbot um abbiamo una specie di due componenti quindi abbiamo un indicizzatore\num che in un certo senso scrive um incorporamenti in un certo senso genera incorporamenti da noi stessi della Verità\nqui così possiamo guardare l'indicizzatore così abbiamo la nostra fonte di Verità che è un qualche sito web che abbiamo abbiamo\nun tipo di crawler che ottiene tali informazioni dal sito Web e quindi utilizzando LangChain e l'intelligenza artificiale aperta\nstiamo generando i nostri incorporamenti e quindi archiviandoli nel nostro vettore Supabase e\npoi quando vogliamo chattare con il nostro tipo di Verità stessa, in pratica prendiamo di nuovo la query dell'utente\ncreiamo un incorporamento da quella query quindi cerchiamo in tutti i documenti\nper trovare il tipo di fonte di verità pertinente che abbiamo indicizzato il tipo di\nURL pertinenti riassumiamo il contenuto da quegli URL e poi dove stiamo generando una sorta di risposta e\ntrasmettendola all'utente utilizzando il tempo reale supervisionato, ora la cosa bella di LangChain è\nche ha il supporto integrato per Supabase Vector, quindi il modo in cui possiamo farlo è semplicemente prendere\nquesto schema qui e applicalo al nostro database utilizzando l'estensione vettoriale e quindi se cloni\nqui clona questa demo di chatbot della catena di collegamenti, l'URL è anche sotto nella descrizione,\npossiamo quindi aprirlo nel codice vs per esempio e possiamo guardarlo così abbiamo alcune migrazioni\nqui, quindi queste sono migrazioni iniziali che applichiamo quando eseguiamo un avvio di Supabase\nin modo da poter eseguire Supabase avvia qui per avviare il nostro stack locale Lo ho già in esecuzione, quindi posso\neseguire lo stato supervisionato per vedere il tipo di locale credenziali e se lo apro qui\ncosì possiamo vedere che lo abbiamo appena copiato dalla documentazione della catena di collegamenti, quindi questo è ciò che consente\nal nostro Supabase Vector di creare i nostri documenti, quindi in pratica fa funzionare il framework LangChain\ncon il vettore Supabase e quindi una cosa che Ho aggiunto specificamente qui\nc'è la possibilità di consentire l'interrogazione sui documenti pubblici per gli utenti autenticati, quindi\nqui si utilizzano le politiche di sicurezza a livello di riga e quindi volevamo solo consentire l'interrogazione per\ngli utenti autenticati dal lato client noi possiamo permetterlo, ad esempio, e altrimenti è uguale\nqui come questo che viene aggiunto nella sicurezza a livello di ruolo qui e poi stiamo anche\nmemorizzando le conversazioni, quindi è fondamentalmente ehm, conosci l'ordinamento del testo di ciò che è stato digitato\nnella chat e poi ciò che l'IA ha risposto, quindi stiamo archiviando le\nconversazioni del confusore e del chatbot dell'IA, nonché vogliamo ricordare la cronologia della chat e stiamo anche inserendo\nquella cronologia della chat nel chiedi anche di conoscere un po' la cronologia delle conversazioni precedenti\ne ancora una volta stiamo applicando una sorta di policy di sicurezza a livello di ruolo in modo specifico per cui solo\nl'utente può vedere il proprio tipo di conversazioni che conosci con il chatbot\nuh quindi stiamo bloccando una specie di informazioni qui okay fantastico, quindi diamo un'occhiata\num possiamo eseguirlo in modo da poter dire npm run def quindi prima di tutto sai che abbiamo Supabase in esecuzione\nlocalmente e poi abbiamo anche um nostro uh chat bot qui in esecuzione localmente ed è\num viene fornito con l'autenticazione Supabase quindi questa è l'interfaccia utente di autenticazione per reagire in realtà ma poi prima di tutto vogliamo\neseguire la scansione di alcune informazioni e sai che qui ad esempio stiamo assumendo se non lo sapevi\npuoi controllare le carriere di Supabase, ad esempio stiamo assumendo per i clienti Architetto di soluzioni\ne questa è l'intera descrizione del lavoro qui ci sono molte informazioni lì dentro sai\ncome lavoro remoto al 100% um ESOP nell'azienda Proprietà azionaria um sì tonnellate di\ncose quindi sai, semplifichiamoci la vita e effettuiamo la scansione di questo in modo che la barra API esegua la scansione\num possiamo eseguire la scansione della descrizione del nostro lavoro qui e quello che possiamo vedere è che ora stiamo eseguendo la scansione, ehm, delle nostre capacità e\nstiamo anche scansionando quindi il tipo crawler di fa una cosa un po' ricorsiva in cui esegue la\nscansione delle pagine che sono collegate in esso e poi possiamo vedere okay, ora è fatto,\nquindi quello che possiamo vedere adesso se andiamo al Supabase Studio qui quindi abbiamo\ndi nuovo l'host locale se non ricordi possiamo eseguire lo stato di Supabase dopo aver eseguito un avvio supervisionato possiamo\nottenere i nostri dettagli locali qui e quindi possiamo aprire questo progetto localmente qui e\nora possiamo guardare a abbiamo le nostre conversazioni quindi non abbiamo ancora nessuna conversazione ma qui abbiamo i nostri\ndocumenti quindi questo è quello che abbiamo scansionato uh qui abbiamo i nostri incorporamenti vettoriali uh e puoi\nvedere una specie di righe di codice ehm non righe di codice quindi ci sono anche alcuni metadati e\nqueste sono una sorta di righe quindi i documenti sono suddivisi in diverse sezioni quindi\nutilizzando anche i metadati possiamo quindi eseguire alcuni filtri quindi è davvero potente in\nPostgres dove abbiamo Json Tipo di dati B in modo che possiamo inserire l'intero tipo di documenti JSON in\num sai che conosci i nostri documenti qui come metadati fantastici, quindi ora che abbiamo eseguito la scansione di questo\nlo abbiamo nel nostro database quindi ora quello che possiamo fare è effettivamente avere uno sguardo a come funzionava il crawler, quindi\nquesto è nella nostra API Pages e poi esegui la scansione qui, quindi utilizziamo la catena di lunghezza, utilizziamo i nostri\nincorporamenti openai da LangChain e quindi utilizziamo il negozio Supabase Vector, quindi è davvero utile per\nuna sorta di catena di lunghezze è integrata con il negozio Supabase Vector e poi, in realtà,\ndalla query otteniamo gli URL che vogliamo indicizzare, stiamo creando una sorta di\nraccolta di documenti, quindi li dividiamo in un certo senso le sezioni per assicurarci di avere il\ndiritto di conoscere la dimensione per creare l'incorporamento in modo da non esaurire la dimensione del token\ndividendo il tipo di documenti qui e poi stiamo creando il nostro incorporando incorporamenti AI così aperti\nstiamo creando il nostro negozio Supabase Vector semplicemente inserendo un client di amministrazione di Supabase\nqui quindi il client di amministrazione di Supabase usa semplicemente um qui possiamo vedere che utilizza la chiave privata che è\nqui la nostra chiave del ruolo di servizio uh e quindi possiamo eseguire una sorta di operazione di amministrazione che consiste\nnell'inserire questi documenti e quindi stiamo creando una sorta di raccolta di documenti nella nostra raccolta di documenti,\naggiungendo in una sorta di archiviazione di tutti i documenti e quindi abbiamo i documenti qui nel nostro database\ne possiamo quindi eseguire ricerche su di essi quindi passiamo a quello, quindi prima di tutto dovremo accedere Quindi\nattualmente se guardiamo nel nostro progetto qui um quindi stiamo eseguendo di nuovo su localhost stiamo eseguendo\nl'intero uh stack Supabase localmente e non non abbiamo ancora utenti quindi iscriviamo un\nnuovo utente tester al test punto de e um qui quindi se diciamo accedi um non conosciamo\ncredenziali non valide perché non le abbiamo quindi iscriviamoci e poi dobbiamo farlo controlla la nostra email per il\ncollegamento alla conversazione ora siamo in esecuzione su localhost quindi non stiamo inviando email reali qui\nma quello che possiamo fare è avere il servizio chiamato in bucket che è\nanche un servizio Open Source davvero interessante e qui possiamo vedere che abbiamo la conferma della tua email, quindi questa è stata appena\ninviata e possiamo fare clic e confermare il nostro indirizzo email e ora possiamo vedere che siamo bloccati\num la nostra applicazione qui è in esecuzione su localhost quindi ora possiamo chattare con i nostri documenti quindi forse\nchiediamo se Supabase consente il lavoro remoto punto interrogativo quindi lo stiamo attivando ora um stiamo trovando\nle corrispondenze e possiamo vedere qui così abbiamo trovato le nostre corrispondenze, queste sono queste due\nofferte di lavoro di Supabase uh e poi ora il documento è troppo lungo quindi stiamo riassumendo le informazioni delle\ndue offerte di lavoro e poi stiamo mettendo insieme il nostro prompt così possiamo vedere qui il nostro messaggio\ne poi riproduciamo in streaming la risposta uh sì Supabase supporta il lavoro a distanza\num la comunicazione completamente remota avverrà tramite e-mail video yada yada ed è esattamente così\num quindi funziona perfettamente come previsto diamo un'occhiata a come\num il reale la funzionalità di chat funziona, quindi di nuovo, um, il nocciolo della questione è più o meno qui\nnella chat punto TS Sì, di nuovo, uh una specie di LangChain, uh roba aperta AI, abbiamo un modello di prompt qui,\num, e poi abbiamo il nostro riepilogo e qui utilizziamo gli aiutanti di autenticazione stiamo creando un\nclient server Pages che è una specie di sito server che possiamo utilizzare per eseguire una sorta di\nquery autenticate sul server e quindi stiamo semplicemente ottenendo il nostro\nclient di autenticazione Supabase quindi il nostro client di autenticazione supervisionato sta arrivando da qui in basso quindi stiamo creando\num uh Pagine uh client server uh inserendo nelle richieste e nella risposta alcune\ninformazioni in tempo reale quindi stiamo disabilitando il limite di velocità qui possiamo farlo con il meno uno quindi vogliamo solo\neseguire lo streaming qualsiasi diritto stiamo arrivando, allora avremo la nostra sessione e se siamo\nautenticati allora abbiamo qui il nostro se abbiamo una sessione possiamo quindi avviare e gestire la nostra chat\nehm e cosa sta succedendo Ecco quindi siamo ora usiamo innanzitutto offline per ottenere un\ncanale in tempo reale con l'ID utente, quindi è quello che usiamo per la comunicazione client server\nuh poi stiamo anche inserendo la nostra comunicazione [Musica]\num quindi in pratica stiamo iniziando da una conversazione per l'intelligenza artificiale che ci fornisce un ID di interazione in modo che\npossiamo usare l'uid qui um e poi riceviamo la conversazione\num cronologia dei blocchi quindi è semplicemente come guardare il nostro database così um possiamo guardare che\npossiamo guarda il nostro studio quindi qui ora abbiamo conversazioni abbiamo queste informazioni dal\nnostro utente la domanda e la risposta qui quindi ho già avuto una conversazione prima\num che è memorizzata qui quindi stiamo mettendo insieme um questa catena di modelli linguistici usando una specie di il nostro\nmodello di prompt questo è il modello di richiesta qui in un certo senso dato il seguente prompt dell'utente\ne il registro delle conversazioni ha formulato una risposta pertinente in modo che il prompt dell'utente sia una specie di\ncronologia delle conversazioni delle query e gli stiamo dando un sacco di istruzioni qui\num eccoci qua e poi quello che stiamo facendo è creare il nostro canale di trasmissione in modo da poterci\niscrivere al canale e sostanzialmente una volta che siamo iscritti possiamo inviare una trasmissione\ne quindi eccoci qui proprio ora, ok, stiamo iniziando stiamo trovando corrispondenze, quindi qui stiamo\nottenendo corrispondenze dagli incorporamenti, quindi questa è una specie di catena di lunghezza,\nnonché una catena di collegamenti, quindi il client supervisionato apre gli incorporamenti Ai e il negozio di vettori,\nehm, stiamo solo facendo la ricerca di somiglianza del negozio ecco quindi tutte queste informazioni che puoi scavare\nnei dettagli della catena di lunghezza, ma questo è il modo in cui stiamo effettuando una sorta di ricerca di somiglianza con\nLangChain per trovare i documenti rilevanti per la nostra chat in modo da ottenere le nostre corrispondenze dalle corrispondenze che\nabbiamo poi i nostri URL e come hai visto, la console ci ha disconnesso da tali URL e infine stiamo\nsemplicemente ottenendo i metadati della corrispondenza ottenendo il testo e gli URL e poi stiamo praticamente\ncostruendo insieme il nostro modello di prompt con i riepiloghi, quindi sai bene dei\ndettagli riepilogati dai nostri documenti la domanda dell'utente la cronologia delle conversazioni nonché\ngli URL e poi stiamo semplicemente facendo la nostra chat AI aperta qui utilizzando il modello turbo GPT 3.5\num e mettendoli insieme qui e poi quello che noi quello che stai facendo è una volta che avremo degli aggiornamenti,\nquindi in pratica è così che funziona lo streaming qui, quindi diciamo streaming vero e\nogni volta che riceviamo una sorta di nuovo token lo inviamo tramite il nostro canale di trasmissione\ne dove poi lo otteniamo dal lato client e poi alla fine, quando l'intera catena di amplificatori LL è\nquasi terminata, stiamo semplicemente aggiornando la nostra conversazione con l'ID di interazione\nnel database in modo da avere anche il risposte dall'intelligenza artificiale nel nostro registro delle conversazioni\num sì, è più o meno tutto, possiamo guardare l'indice qui quindi nell'indice che stiamo utilizzando sai\nche questo è reso dal lato client um quindi stiamo usando il client browser Supabase uh qui da gli\naiutanti di autenticazione di Supabase uh e poi praticamente stiamo solo mettendo insieme um dove lo abbiamo qui sì,\nstiamo mettendo su um mettendo insieme l'autenticazione usando il componente di autenticazione di superface qui e poi abbiamo\nsolo il nostro ascoltatore del canale quindi questo è il nostro canale Supabase uh trasmette in tempo reale, quindi quando\nriceviamo un evento di chat controlliamo semplicemente okay, è una risposta questo è un messaggio di stato\nuh risposta e cos'hai uh e poi aggiorniamo semplicemente il nostro messaggio chatbot uh e quindi è\ngentile di come otteniamo il tipo di streaming utilizzando Supabase in tempo reale per um la dimensione del nostro client sì\num questo è praticamente tutto um ecco come puoi in un certo senso raggruppare tutti questi diversi\nfornitori di servizi fondamentalmente all'interno di un ritmo super in modo che la funzionalità sia disponibile se sei\ninteressato a costruire con um Supabase uh con altro con next.js più tipi di applicazioni AI\nc'è abbiamo una ricerca di documenti xjs openai e questo in realtà utilizza l'SDK um versal um versal AI quindi\nse sei interessato conosci il tipo di come funziona uh puoi guardarlo qui e abbiamo anche\nun video di spiegazione quindi grazie mille per esserti sintonizzato e ci vediamo al prossimo\nvideo"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "ja",
        "plaintext": "こんにちは、今日は Supabase\nVector を使用して next.js と LangChain でチャットボットを構築することを検討しています。これでドキュメントとチャットできるようになりました。それでは、Supabase ではリモート作業が許可されているかを尋ねましょう\n。一致するものを見つけました。ここで見ることができます。\n一致するものを見つけました。これらはこれら 2 つの Supabase の求人情報です。文書が\n長すぎるため、2 つの求人情報からの情報を要約し、まとめています\n。私たちのプロンプトですので、ここでプロンプトを見ることができます えー、それから\n答えをストリーミングして返します えーはい、Supabase はリモートワークをサポートしています、このデモは Pinecone のチャットボット デモのフォークです\n。これは本当に素晴らしい作品です、えー Roy による作品です。ブログ投稿を読むことができます。以下にリンクします。next.js\nのリンク チェーン JS を使用してマルチユーザー チャットボットを構築するというコンセプトのようなもの\nです。それにはいくつかのコンポーネントがありますが、最も重要なのは私が望んでいたものです。ここで試してみることは、\nこれらの違いのサービスの多くを\nSupabase に組み込まれている機能に置き換えることです。そのため、Pinecone の代わりに Supabase Vector を使用し、\ncockroachdb の代わりに Supabase リアルタイムを使用します。 Supabase スタック に付属する postgres データベース\nと、フィンガープリントの代わりに Supabase 認証を使用しているため、これらすべてのサービスを\nSupabase だけに要約し、\nアーキテクチャに関して は next.js で AI をオープンしています。 チャットボット えーっと、2 つのコンポーネントがあるので、インデクサーがあります。\nえー、埋め込みを書き込むようなもので、\nここで真実の埋め込みを生成します。それでインデクサーを確認できるので、真実のソースが得られます。これは、あるウェブサイトです。\nウェブサイトからその情報を取得するようなクローラー があり\n、LangChain とオープン AI を使用して 埋め込みを生成し、それを Supabase ベクターに保存します。\nその後、ある種の真実そのものとチャットしたいときは、基本的に次のようにします。ユーザークエリを\n再度作成し、そのクエリから埋め込みを作成します。その後、すべてのドキュメントを検索して、インデックスを\n作成した関連する信頼できる情報源を見つけます。関連する\nURL を要約します。その URL からコンテンツを要約します。ある種の応答を生成し、\nそれを監視付きリアルタイムでユーザーにストリーミングしています。LangChain の優れている点は、\nSupabase Vector のサポートが組み込まれているため、これを行う方法は、\nこのスキーマ を使用するだけです。 ここで、ベクター拡張機能を使用してそれをデータベースに適用します。したがって、\nここでクローンを作成すると、このリンク チェーン チャットボットのデモのクローンが作成されます。URL も説明の下にあります。\nこれを、たとえば vs コードで開くと、確認できます。 ここには いくつかの移行がある\nため、これらは Supabase start を実行するときに適用する初期移行です\n。これにより、ここで Supabase start を実行してローカル スタックを起動できます。既に実行しているので、\n監視ステータスを実行してローカル スタックの種類を確認できます。これをここで開くと、\nリンク チェーンのドキュメントからコピーしたことがわかります。これにより、\nSupabase Vector がドキュメントを作成できるようになり、基本的に LangChain フレームワークが\nSupabase Vector と連携できるようになります。ここで特に追加したのは、\n認証されたユーザーのパブリック ドキュメントに対するクエリを許可する機能です。これはここで行レベルのセキュリティ ポリシーを使用しているため、\nクライアント側からの認証されたユーザーに対するクエリのみを\n許可したかったのです 。 たとえばそれを許可できますか、そうでない場合は、\nここでの役割レベルのセキュリティに追加されたものと同じです。また、\n会話を保存しているので、基本的にはテキストの並べ替えです。 チャットに 入力された内容\nと AI が応答した内容を分析するため、コンフューザーと AI チャットボットの\n会話を保存するとともに、チャットの履歴も記憶しておき、\nそのチャット履歴をまた、以前の会話の履歴を知るように求めるプロンプトが表示されます。\nまた、ここでは役割レベルのセキュリティ ポリシーのようなものを適用しています。具体的には、\nチャットボットとの会話をユーザーだけが閲覧できるようにしています。\nええと、ここでは情報をロックダウンしています。わかりました、それでは実際に見てみましょう。ええと、\nこれを実行できるので、npm run def と言うことができます。まず第一に、ローカルで Supabase が実行されていることを知ってください。\nそして、私たちのものもあります。えー、ここでチャット ボットがローカルで実行されています。これは\nSupabase 認証が付属しているので、これは実際に反応するための認証 UI ですが、まず最初に\nいくつかの情報をクロールしたいと思います。たとえば、ここで私たちが採用していることをご存知ですか、もしあなたが知らなかったなら\nSupabaseのキャリアをチェックしてみてください。たとえば、私たちは顧客向けにソリューションアーキテクトを募集しています\n。これが職務内容の全体です。そこには、100パーセントのリモートワーク、社内のESOPなど、知っている情報がたくさんあります。\n株式の所有権、ええと、たくさんの\nこと です。 それで、私たちの生活を楽にしましょう ええと、実際にこれをクロールしましょう API スラッシュ クロール ええと、\nここで私たちの職務記述書をクロールできます。そして、私たちが見ることができるのは、今私たちがクロールしていることです、ええ、チョップ、そして\n私たちもクロールしているので、クローラーの種類of は、ちょっとした再帰的な処理を行います。\nその中でリンクされているページもクロールします。すると、これで完了したことがわかります。\nそれで、実際に何が表示されるかは、 Supabase Studio がここにあるので、ローカルホストを\n再度取得します。覚えていない場合は、監視付き開始を実行した後に Supabase ステータスを実行できます。\nここでローカルの詳細を取得できるので、ここでこのプロジェクトをローカルで開くことができ、\n確認できるように なります。 ここで会話をしているので、まだ会話はありませんが、ここに\nドキュメントがあるので、これが私たちがクロールしたものです、えー、ここにベクター埋め込みがあります、えー、\n行ではなく、コードのような行が見えますコードの一部なのでメタデータもあり、\nこれらは一種の行であり、ドキュメントはさまざまなセクションに分割されているため、\nメタデータも使用してフィルタリングを実行できるため、\nJson がある postgres では非常に強力です B データ型なので、あらゆる種類の Json ドキュメントをこの中にドロップすることができます\n。ご存知のとおり、ここにあるドキュメントはメタデータとして優れています。これでこれをクロールし、\nデータベースに保存しました。それで、実際にできることは次のとおりです。そのクローラーがどのように動作したかを見て、\nこれは Pages API にあり、次にここでクロールするので、長さチェーンを使用します。LangChain\nからの openai 埋め込みを使用し、次に Supabase Vector ストアを使用します。これは、\nある種の長さのチェーンが Supabase Vector ストアと統合されており、\nクエリからインデックスを作成したい URL を取得しています。まあ、ある種の\nドキュメント コレクションを作成しているので、ある種の分割を行っています。 埋め込みを作成するための適切なサイズ があることを確認するためのセクションです。\nトークン サイズが不足しないように、\nここでドキュメントを分割してから、埋め込みなので、AI\n埋め込みをオープンにします。Supabase Vector ストアを作成しています。ここに Supabase 管理クライアントを入れます。\nそのため、Supabase 管理クライアントは使用するだけです。ここで、秘密キーを使用していることがわかります。これが\nサービス ロール キーです。それから、次のことができます。 これらのドキュメントを挿入する 一種の管理操作を実行し\n、ドキュメント コレクションに一種のドキュメントを作成し、\nすべてのドキュメントを保存するようなものを追加します。その後、データベースにドキュメントが保存され、\n検索を実行できるようになります。それらにあるので、それに移りましょう。まず最初にログインする必要があります\n。それで、現在、ここでプロジェクトを見ると、ええと、ローカルホストで再び実行しています\n。ええと、Supabase スタック全体をローカルで 実行しています。\nまだユーザーがいないので、テスト ドット デで新しいユーザー テスターに​​サインアップしましょう。\nそして、ここでサインインと言ったら、無効な 資格情報を 知っていますか? メールで\n会話リンクを確認してください。現在、ローカルホストで実行しているので、ここでは実際のメールは送信しません\nが、できることは、サービスをバケット内で呼び出すことです。これは非常に優れたオープン\nソース サービスでもあり、ここに確認メールが表示されているので、これは\nちょうど今送信されたメールです。メール アドレスをクリックして確認すると、ロックされていることがわかります。\nええと、私たちのアプリケーションはここにあります。ローカルホストで実行しているので、ドキュメントとチャットできるようになりました。それでは、\nSupabase はリモートワークを許可しますか?\n一致するものが見つかりました。これらはこれら 2 つの えー、Supabase の求人\n情報です 。そして、文書が長すぎるため、えー、\n2 つの求人情報からの情報を要約し、えー、ここで確認できるようにプロンプ​​トをまとめています。私たちのプロンプト\nと、答えをストリーミングで返します ええと、Supabase はリモート作業をサポートしています\nええと、完全なリモート通信は電子メールビデオで行われます、やだやだ、それがまさにその通りです、ええと、\nこれは完全に予想どおりに機能しています ええと 、実際の\n動作を見てみましょう チャット機能は動作しているので、もう一度、その中心は\nチャットドット TS のようなものです。はい、もう一度、ああ、LangChain のようなものです。オープン AI ここにプロンプ​​ト テンプレートがあります。\nそして、サマライザがあり、ここでは認証ヘルパーを使用しています。私たちはサーバーサイトの一種である Pages\nサーバークライアントを作成しています。これはサーバー上で認証されたクエリのようなものを実行するために使用できます。\nつまり、Supabase 認証クライアントを取得したところです。\nつまり、監視付き認証クライアントが登場します。ここから下にあるので、\nえー、ページを作成しています、えー、サーバー クライアント、えー、リクエストと応答にリアルタイムの\n情報を入力します。そこでレート制限を無効にします。マイナス 1 でそれができるので、\nストリーミングしたい だけです。 どういうわけか、私たちは来ます、そして私たちはセッションを取得します、そして私たちが\n認証されたら、私たちはここにいます、私たちがセッションを持っているなら、私たちはチャットを開始して処理することができます、\nえーっと、何が起こっているのかここにあります今、オフラインを使用して、まず\nユーザー ID を持つリアルタイム チャネルを取得します。これをサーバー クライアント通信に使用しています。\nそれから、[音楽] 通信も挿入します。\nそれで、基本的に開始します。 AI との会話からインタラクション ID が得られるので、\nここで uid を使用できます。その後、会話を取得し、\nロック履歴を取得します。それで、データベースを調べているようなものです。そうすれば、できることを確認できます\n。私たちのスタジオをご覧ください。それで今、会話をしています。\nユーザーからの情報、質問と回答がここにあります。それで、以前にすでに 1 つの会話を行っていました。\nええと、それはここに保存されています。その後、この言語モデル チェーンを、ある種のものを使用してまとめています。私たちの\nプロンプトテンプレートです。これは問い合わせテンプレートです。ここでは、次のユーザープロンプトと会話ログを考慮して、\n関連する応答を作成しました。つまり、ユーザープロンプトはクエリの会話履歴のようなもので\n、ここで大量の指示を与えることになります\n。そして、私たちがやっていることは、\nチャンネル登録ができるようにブロードキャスト チャンネルを作成することです。基本的に、一度登録したら、ブロードキャストを送信できるようになります\n。つまり、ここでは送信を開始します。一致を見つけているので、ここでは\nエンベディングから一致を取得しています。これは、長さのチェーン、リンク チェーンの一種\nであり、監視されたクライアントのオープン Ai エンベディングと\nベクトル ストアです。ええと、ストアの類似性検索を行っているだけです。ここにあるすべての情報は、\nチェーンの長さの詳細を調べることができますが、これは、チャットに関連するドキュメントを見つけるために LangChain を使用して類似性検索を実行し\n、一致 した ものから一致を取得する方法です。\n私たちの URL と、あなたが見たとおり、コンソールはそれらの URL をログアウトしました。そして最後に、\nテキストと URL を取得して一致メタデータを取得しています。それから、基本的に\n概要を含むプロンプト テンプレートを一緒に構築しています。 私たちのドキュメントから要約された 詳細、\nユーザーからの質問、会話履歴と\nURL、そして、ここで GPT 3.5 ターボ モデルを使用してオープン AI チャットを実行し\n、それをここでまとめて、次に何をするかです。やっているのは、ええと、何か更新があれば\n、基本的にはストリーミングがここでどのように機能するかのようなものなので、ストリーミングが真であると言い、\n新しいトークンのようなものを取得するたびに、これをブロードキャストチャネルを通じて送信します\nそしてそれをクライアント側で取得し、最後に LL アンプ チェーン全体が\nある程度完了し たら、 データベース内の\nインタラクション ID を使用して会話を更新するだけです。 会話ログの AI からの回答 ええと、\nこれでほぼ終わりです。ここでインデックスを確認できます。つまり、使用しているインデックスでは、\nこれがクライアント側でレンダリングされていることがわかります。それで、ここでは Supabase えー、ブラウザ クライアントを使用しています。 Supabase\n認証ヘルパーです。えーっと、ほとんどまとめているところです。えっと、ここにはどこがありますか。はい、\nここで superface 認証コンポーネントを使用して認証をまとめています。そして、\nチャンネル リスナーがあるだけです。これは次のとおりです。私たちの Supabase えー、リアルタイム チャンネル ブロードキャストなので、\nチャット イベントを受け取ったら、基本的には、「わかりましたか、これはステータス メッセージですか、応答ですか」を確認するだけです。\nえー、何かあります か 、それからチャットボット メッセージを更新するだけです。\nSupabase を使用してリアルタイムでストリーミングを取得する方法について、クライアントのサイズについて、はい、\nこれでほぼ完了です。これは、これらのさまざまなサービス\nプロバイダーをすべて基本的にスーパー ペース内にバンドルして、その機能が利用できるように する方法です。\nSupabase で構築することに興味があります。 next.js でさらに多くの種類の AI アプリケーションを構築することに興味が\nあり ます 。 xjs openai ドキュメント検索があり、これは実際に um versal um versal AI SDK を使用します\n。それがどのように機能するかについては、ここでご覧いただけます。また、\nこれについてのビデオ説明もありますので、ご視聴いただきありがとうございます。次のビデオでお会いしましょう\n。"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "ko",
        "plaintext": "안녕하세요 오늘 우리는 Supabase\nVector를 사용하여 next.js 및 LangChain으로 챗봇을 구축하는 방법을 살펴보고 있습니다. 이제 문서와 채팅할 수 있으므로 Supabase가 원격 작업 물음표를 허용하는지 물어보겠습니다.\n이제 시작하겠습니다 음 우리' 일치하는 항목을 다시 찾고 있는데 여기에서 볼 수 있으므로\n일치하는 항목을 찾았습니다. 이것은 음 Supabase 채용 공고 2개입니다. 그런데 이제 문서가\n너무 길어서 음 두 개의 채용 공고에서 정보를 요약하고 합치는 중입니다\n. 음 프롬프트 그래서 음 여기에서 프롬프트를 볼 수 있습니다 어 그리고\n답변을 다시 스트리밍하고 있습니다 어 예 Supabase는 원격 작업을 지원합니다. 이제 이 데모는 Pinecone 어 챗봇 데모의 포크입니다.\n이것은 어 Roy가 만든 정말 멋진 작업입니다. 아래에 링크할 블로그 게시물을 읽을 수 있습니다.\n음 next.js에 링크 체인 JS가 포함된 다중 사용자 챗봇을 구축하는 개념이 있습니다.\n음 여기에는 몇 가지 구성 요소가 있지만 음 가장 중요한 것은 제가 원했던 것입니다. 여기서 시도하는 것은\n이러한 많은 차이 서비스를 Supabase에 내장된 기능으로 대체하는 것 입니다\n. 따라서 Pinecone 대신 abil 대신 Supabase Vector를 사용하고 있으며\nCockroachdb 대신 Supabase 실시간을 사용하고 있습니다. Supabase 스택 과 함께 제공되는 postgres 데이터베이스\n그리고 지문 대신 Supabase 인증을 사용하므로 이러한 모든 서비스를\nSupabase로 요약하고 여기의\n아키텍처 측면에서 next.js를 사용하여 AI를 엽니다. 챗봇에는 두 가지 구성 요소가 있으므로 인덱서가 있습니다.\n음 임베딩은 여기에서 진실의 임베딩을 생성하므로\n인덱서를 볼 수 있으므로 진실의 소스가 있습니다. 크롤러 가\n웹사이트에서 해당 정보를 얻은 다음 LangChain과 개방형 AI를 사용하여\n임베딩을 생성한 다음 이를 Supabase 벡터에 저장하고\n우리가 일종의 진실 자체와 대화하고 싶을 때 기본적으로 다음을 수행합니다. 사용자 쿼리를\n다시 사용하여 해당 쿼리에서 임베딩을 생성한 다음 모든 문서를 검색하여\n관련성 있는 음, 우리가 인덱싱한 진실의 소스를 찾습니다. 관련\nURL을 검색하고 해당 URL에서 해당 콘텐츠를 요약합니다. 우리는 일종의 응답을 생성하고\n이를 실시간 감독을 사용하여 사용자에게 다시 스트리밍하고 있습니다. 이제 LangChain의 가장 좋은 점은 음 Supabase Vector에 대한 지원이 내장되어 있다는 것입니다.\n그래서 우리가 할 수 있는 방법은 이 스키마를 사용하면 된다는 것입니다.\n여기에서 벡터 확장을 사용하여 이를 데이터베이스에 적용합니다. 따라서\n여기에서 복제하면 이 링크 체인 챗봇 데모를 복제하면 URL도 설명 아래에 있습니다.\n예를 들어 vs 코드에서 이를 열 수 있으며 이를 볼 수 있습니다. 여기에 몇 가지 마이그레이션이 있습니다\n. 이는 Supabase start를 실행할 때 적용하는 초기 마이그레이션이므로\n여기에서 Supabase start를 실행하여 로컬 스택을 시작할 수 있습니다. 이미 실행 중이므로\n감독 상태를 실행하여 로컬 상태를 확인할 수 있습니다. 자격 증명을 여기에서 열면\n링크 체인 문서에서 방금 복사한 것을 볼 수 있습니다. 이것이\nSupabase Vector가 문서를 생성할 수 있게 하여 기본적으로 LangChain 프레임워크가\nSupabase 벡터와 함께 작동하도록 만드는 것입니다. 여기에 특별히 추가한\n것은 인증된 사용자에 대해 공개 문서에 대한 쿼리를 허용하는 기능입니다. 여기서는 어 행 수준 보안 정책을 사용하고 있으므로\n우리는 클라이언트 측에서 인증된 사용자에 대한 쿼리만 허용하고 싶었습니다.\n예를 들어 허용할 수 있나요? 그렇지 않으면\n여기에 역할 수준 보안에 추가된 것과 동일합니다. 그런 다음\n기본적으로 음 텍스트 정렬을 알 수 있도록 대화를 저장합니다. 그 중 채팅에 입력된 내용\n과 AI가 응답한 내용이 있으므로 혼동자와 AI 챗봇 대화를 저장하고\n채팅 기록을 기억하고 싶고\n해당 채팅 기록을 음 이전 대화 기록도 알라는 메시지가 표시됩니다.\n여기서는 특히 음 사용자\n만 자신의 음 종류의 대화를 볼 수 있도록 일종의 역할 수준 보안 정책을 적용하고 있습니다.\n어, 여기에 정보를 잠그고 있는 중이군요 알겠습니다 좋습니다. 실제로 한 번 살펴보겠습니다. 음\n이것을 실행할 수 있으므로 npm run def라고 말할 수 있습니다. 먼저 Supabase가\n로컬로 실행되고 있다는 것을 아실 것입니다. 어 여기 로컬로 실행되는 채팅 봇이 있고 음\nSupabase 인증과 함께 제공되므로 실제로는 반응을 위한 인증 UI이지만 먼저 우리는\n일부 정보를 크롤링하고 싶고 여기에서 알 수 있습니다. 예를 들어 모르신다면 채용할 예정입니다.\n예를 들어 우리가 고객을 위해 채용하고 있는 Supabase 경력을 확인할 수 있습니다. 솔루션 설계자\n이며 이것이 전체 직무 설명입니다. 거기에는\n100% 원격 작업 음, 회사의 ESOP 등 많은 정보가 있습니다. 지분 소유권 음, 예, 수많은\n정보 가 있습니다. 그럼 우리 삶을 더 쉽게 만들자 어 그리고 실제로 이것을 크롤링해 보겠습니다. API 슬래시 크롤링\n음 여기서 작업 설명을 크롤링할 수 있고 우리가 볼 수 있는 것은 이제 크롤링하고 있다는 것입니다. 음,\n우리는 크롤러 종류도 크롤링하고 있습니다. of는 약간의 재귀적 작업을 수행하여\n음, 어, 일종의 연결된 페이지도 크롤링하고 그러면 우리는 알 수 있습니다. 이제 이 작업이 완료되었습니다. 음, 음, 음,\n다음으로 이동하면 실제로 볼 수 있는 것이 무엇인지 알 수 있습니다. 여기에 Supabase Studio가 있으므로 로컬 호스트가\n다시 있으므로 감독된 시작을 실행한 후 Supabase 상태를 확인할 수 있습니다.\n여기에서 로컬 세부 정보를 얻을 수 있으므로 여기에서 이 프로젝트를 로컬로 열고\n이제 살펴볼 수 있습니다. 대화 중이므로 아직 대화가 없지만 여기에\n문서가 있으므로 음 우리가 크롤링한 내용은 다음과 같습니다. 어 여기에 벡터 임베딩이 있습니다. 어 그리고\n줄이 아닌 코드 줄을 볼 수 있습니다. 코드가 있으므로 일부 메타데이터도 있고\n이것들은 일종의 라인이므로 문서가 여러 섹션으로 분류되므로\n음 메타데이터를 사용하여 몇 가지 필터링을 수행할 수 있으므로\nJson이 있는 postgres 에서 정말 강력합니다. B 데이터 유형을 사용하여 모든 종류의 Json 문서를 여기에 넣을 수 있습니다.\n음 여기 있는 문서가 메타데이터로 훌륭하다는 것을 알고 있으므로 이제 이를 크롤링하여\n데이터베이스에 있으므로 이제 우리가 할 수 있는 일은 실제로 크롤러가 어떻게 작동했는지 살펴보세요.\nPages API에 있고 여기에서 크롤링하므로 길이 체인을 사용하고\nLangChain의 개방형 임베딩을 사용하고 Supabase Vector 저장소를 사용하므로 정말 좋습니다.\n일종의 길이 체인이 Supabase Vector 저장소와 통합된 다음 실제로\n쿼리에서 우리는 음 색인화하려는 URL을 얻습니다. 음 우리는 일종의\n문서 컬렉션을 생성하므로 일종의 분할을 합니다. 음 임베딩을 생성하기 위한 음 크기 에 대한 권리가 있는지 확인하는 섹션으로,\n음 여기에서 문서를 분할하여 토큰 크기가 부족하지 않도록 합니다. 개방형 AI 임베딩을 포함하여\nSupabase Vector 저장소를 생성하고 있습니다. 여기에 Supabase 관리 클라이언트를 넣기만 하면\nSupabase 관리 클라이언트가 음 여기서는\n여기서 서비스 역할 키인 개인 키를 사용하는 것을 볼 수 있습니다.\n이러한 문서를 삽입 하는 일종의 관리 작업을 수행\n하고 음 그래 우리 문서 컬렉션에 일종의 생성을 하고 음\n모든 문서를 저장하는 일종의 추가를 하고 여기 데이터베이스에 문서가 있고\n검색을 수행할 수 있습니다. 그것에 대해 살펴보겠습니다. 먼저 로그인해야 합니다.\n현재 여기에서 프로젝트를 보면 음, localhost에서 다시 실행 중입니다.\n전체 Supabase 스택을 로컬에서 실행 중이고, 그렇지 않습니다. 아직 사용자가 없으므로\ntest dot de 및 음 여기에서 새 사용자 테스터를 등록하겠습니다. 로그인이라고 하면 잘못된\n자격 증명을 알지 못하기 때문에 등록한 다음 다음 작업을 수행해야 합니다. 이메일에서\n대화 링크를 확인하세요. 이제 우리는 localhost에서 실행 중이므로 여기에서 실제 이메일을 보내지는 않습니다.\n하지만 우리가 할 수 있는 일은 버킷에 호출되는 서비스가 있다는 것입니다. 이는\n역시 정말 멋진 오픈 소스 서비스 입니다. 여기서 볼 수 있는 이메일 확인이 있습니다. 이 이메일은 어\n방금 전송된 것입니다. 이메일 주소를 클릭하여 확인하면 이제 우리가 잠겨 있는 것을 볼 수 있습니다.\n음 여기 애플리케이션이 로컬 호스트에서 실행 중이므로 이제 문서와 채팅할 수 있으니\nSupabase가 원격 작업을 허용하는지 물음표를 허용하는지 물어보겠습니다. 이제 시작하겠습니다. 음\n일치하는 항목을 찾는 중이고 여기에서 볼 수 있습니다. 일치하는 항목을 찾았습니다. 이것은 음 Supabase 채용 공고입니다.\n어 그런데 문서가 너무 길어서 음\n두 채용 공고의 정보를 요약한 다음 음 프롬프트를 구성하고 있으므로 음 여기서 볼 수 있습니다. 프롬프트를 표시\n한 다음 답변을 다시 스트리밍합니다. 어 예 Supabase는 원격 작업을 지원합니다\n음 완전 원격 통신은 이메일 비디오를 통해 이루어집니다. 음, 그렇군요\n음 그래서 이것은 완전히 예상대로 작동하고 있습니다. 음 실제\n어떻게 되는지 살펴보겠습니다. 채팅 기능이 다시 작동하고 있습니다. 음 핵심은 여기\n채팅 도트 TS입니다. 예, 다시 어 일종의 LangChain입니다. 어, 개방형 AI 여기에 프롬프트 템플릿이 있습니다.\n음, 그런 다음 요약자가 있고 여기에 인증 도우미를 사용합니다. 우리는\n서버에서 일종의 인증된 쿼리를 수행하는 데 사용할 수 있는 일종의 서버 사이트인\n페이지 서버 클라이언트를 만들고 있습니다. 그래서 우리는 Supabase 인증 어\n클라이언트를 가져오고 감독 인증 클라이언트가 올 것입니다. 여기 아래에서는 음 어 페이지 어 서버 클라이언트를 생성 중입니다.\n요청과 응답에 실시간\n정보를 추가하므로 여기에서 속도 제한을 비활성화합니다. 마이너스 1로 그렇게 할 수 있으므로\n스트리밍만 하려고 합니다. 어쨌든 우리는 세션을 가져오고 인증되면\n여기에 있습니다. 세션이 있으면 시작하고 채팅을 처리할 수 있습니다.\n음 여기서 무슨 일이 일어나고 있는지는 다음과 같습니다. 이제 우선 오프라인을 사용하여\n사용자 ID가 포함된 실시간 채널을 가져오고 이것이 서버 클라이언트 통신에 사용하는 것입니다.\n그런 다음 [음악] 음 통신도 삽입합니다.\n음 기본적으로 시작하겠습니다. 상호 작용 ID를 제공하는 AI에 대한 대화를 종료하여\n여기에서 uid를 사용할 수 있도록 하고 대화 기록을 가져오면\n음 잠금 기록이 표시되므로 데이터베이스를 살펴보는 것과 같습니다. 음 우리가 할 수\n있는 것을 볼 수 있습니다 우리 스튜디오를 보세요. 여기서 우리는 대화를 하고 있습니다.\n여기에는 사용자의 질문과 응답이 있습니다. 이전에 이미 한 번의 대화를 나눴습니다. 음\n여기에 저장된 내용을 사용하여 음 이 언어 모델 체인을 구성하고 있습니다. 우리의\n프롬프트 템플릿은 다음과 같은 사용자 프롬프트\n와 관련 응답을 공식화한 대화 로그가 주어지는 문의 템플릿입니다. 따라서 사용자 프롬프트는 쿼리 대화 기록의 일종이며\n여기에 여러 가지 지침을 제공하고 있습니다. 음, 여기\n입니다. 그런 다음 우리가 하는 일은\n채널 구독을 할 수 있도록 방송 채널을 만드는 것입니다. 기본적으로 일단 구독하면 방송을 보낼 수 있습니다\n. 이제 막 전송을 보내는 중입니다. 시작하겠습니다. 일치하는 항목을 찾는 중이므로\n임베딩에서 일치 항목을 가져오는 중입니다. 음, 일종의 길이 체인이고,\n음, 링크 체인이고, 감독되는 클라이언트 오픈 Ai 임베딩과 벡터 저장소입니다.\n음, 우리는 매장 유사성 검색을 수행하고 있습니다. 여기에서 모든 정보를\n길이 체인 세부 정보를 통해 파헤칠 수 있지만 이것이\n채팅에 대한 관련 문서를 찾기 위해 LangChain과 유사성 검색을 수행하는 방법이므로 우리가\n가지고 있는 일치 항목에서 일치 항목을 얻습니다. URL과 콘솔에서 해당 URL을 로그아웃한 다음 마지막으로\n텍스트와 URL을 가져오는 일치 메타데이터를 가져오는 중이고 기본적으로\n요약이 포함된 프롬프트 템플릿을 함께 구축하는 중 입니다. 문서의 요약된 세부 정보\n사용자의 질문 대화 기록 및\nURL 그리고 우리는 여기서 GPT 3.5 터보 모델을 사용하여 AI 채팅을 열고 음\n여기에서 이를 종합한 다음 우리가 할 일은 음 업데이트가 있으면\n기본적으로 이것이 스트리밍이 작동하는 방식이므로 스트리밍이 사실이라고 말하고\n언제든지 새로운 토큰을 얻을 때마다 방송 채널을 통해 보냅니다.\n그런 다음 클라이언트 측에서 이를 가져오고 마지막에 음 전체 LL 앰프 체인이 어느 정도 완료되면\n음 데이터베이스의 상호 작용 ID로 대화를 업데이트하여\n대화 로그에 있는 AI의 답변\n음 네 그게 거의 전부입니다. 여기서 인덱스를 볼 수 있으므로 우리가 사용하는 인덱스에서\n이것이 클라이언트측 렌더링이라는 것을 알 수 있습니다. 음 그래서 여기서는 Supabase 어 브라우저 클라이언트를 사용하고 있습니다. Supabase\n인증 도우미 어 그리고 거의 우리는 함께 구성하고 있습니다 음 여기 어디에 있나요? 예\n우리는 음 여기서 superface 인증 구성 요소를 사용하여 인증을 함께 구성하는 중이고\n채널 수신기만 있습니다. 우리 Supabase uh 실시간 채널 방송이 있어서\n채팅 이벤트가 오면 기본적으로 이게 응답인지 확인만 해요 이건 상태 메시지\nuh 응답이고 뭐죠 uh 그런 다음 챗봇 메시지를 업데이트하면 uh 그럼\n친절 하네요 Supabase를 실시간으로 사용하여 스트리밍 종류를 얻는 방법에 대해 음 클라이언트 크기 예 음\n그게 거의 다입니다 음 이것이\n기본적으로 어 슈퍼 속도 내에서 이러한 다양한 서비스 제공자를 모두 번들로 묶어 다음과 같은 경우에 기능을 사용할 수 있는 방법입니다. 음 Supabase로 구축하는 데 관심이 있으신가요?\nnext.js를 사용하여 더 많은 종류의 AI 응용 프로그램이\n있습니다. xjs openai 문서 검색이 있으며 이는 실제로 음 Versal 음 Versal AI SDK를 사용하므로\n관심이 있으시면 종류를 아실 것입니다. 그게 어떻게 작동하는지 어 여기에서 볼 수 있고\n이에 대한 동영상 설명도 있으니 시청해 주셔서 정말 감사합니다. 다음 동영상에서 뵙겠\n습니다"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "pl",
        "plaintext": "cześć, dzisiaj zastanawiamy się nad zbudowaniem chatbota z next.js i LangChain przy użyciu Supabase\nVector, więc teraz możemy rozmawiać z naszym dokumentem, więc może zapytajmy, czy Supabase umożliwia pracę zdalną,\nznak zapytania, więc odpalamy to teraz, hm, my” ponownie znajdujemy dopasowania i możemy zobaczyć tutaj,\nwięc znaleźliśmy nasze dopasowania. To są te dwie oferty pracy w Supabase, a teraz dokument jest\nza długi, więc podsumowujemy informacje z dwóch ofert pracy, a następnie łączymy je\nw całość nasz monit, więc hm, możemy zobaczyć tutaj nasz znak zachęty, uh, a następnie przesyłamy strumieniowo odpowiedź,\nuh tak, Supabase obsługuje pracę zdalną, teraz to demo jest rozwidleniem wersji\ndemonstracyjnej chatbota Pinecone, uh, i to jest naprawdę niesamowita praca, uh Roy tutaj możesz przeczytać post na blogu. Podlinkuję go poniżej,\nhm, to rodzaj koncepcji zbudowania chatbota dla wielu użytkowników z łańcuchem łączy JS w next.js i\nhm, jest w tym kilka komponentów, ale co najważniejsze, tego właśnie chciałem spróbować tutaj, to\nw pewnym sensie zastąpić wiele z tych usług różnicowych możliwościami wbudowanymi\nw Supabase, więc zamiast Pinecone używamy Supabase Vector zamiast Able, używamy\nSupabase w czasie rzeczywistym zamiast karalucha, używamy postgres, która jest dostarczana ze\nstosem Supabase, a następnie zamiast odcisku palca używamy uwierzytelniania Supabase, więc wszystkie te usługi\nsprowadzamy to do Supabase i otwieramy sztuczną inteligencję za pomocą next.js tutaj, teraz pod względem\narchitektury dla chatbot, hm, mamy dwa komponenty, więc mamy indeksator,\nktóry w pewnym sensie zapisuje osadzanie, w pewnym sensie generuje osadzanie z nas samych Prawdy,\nwięc możemy spojrzeć na indeksator, więc mamy nasze źródło Prawdy, którym jest jakaś witryna, którą możemy mamy\nrobota, który pobiera te informacje ze strony internetowej, a następnie używając LangChain i otwartej sztucznej inteligencji,\ngenerujemy nasze osady, a następnie przechowujemy je w naszym wektorze Supabase, a\nnastępnie, kiedy chcemy porozmawiać z naszym rodzajem Prawdy, w zasadzie bierzemy ponownie zapytanie użytkownika,\ntworzymy osadzenie na podstawie tego zapytania, następnie przeszukujemy wszystkie dokumenty,\naby znaleźć odpowiednie źródło prawdy, które zaindeksowaliśmy, rodzaj odpowiednich\nadresów URL, podsumowujemy tę treść z tych adresów URL, a następnie gdzie generujemy rodzaj odpowiedzi i\nprzesyłamy ją z powrotem do użytkownika za pomocą nadzorowanego czasu rzeczywistego. Wspaniałą rzeczą w LangChain jest\nto, że ma wbudowaną obsługę Supabase Vector, więc możemy to zrobić w ten sposób, że możemy po prostu skorzystać z\ntego schematu tutaj i zastosuj to do naszej bazy danych za pomocą rozszerzenia wektorowego, więc jeśli sklonujesz\ntutaj, sklonuj tę wersję demonstracyjną chatbota z łańcuchem linków, adres URL jest również poniżej w opisie,\nmożemy następnie otworzyć to na przykład w kodzie vs i możemy spojrzeć na to mamy\ntutaj pewne migracje, więc są to początkowe migracje, które stosujemy, gdy uruchamiamy Supabase start,\nabyśmy mogli uruchomić Supabase start tutaj, aby uruchomić nasz lokalny stos. Już go uruchomiłem, więc mogę\nuruchomić status nadzorowany, aby zobaczyć rodzaj lokalnego dane uwierzytelniające i jeśli otworzę to tutaj,\nabyśmy mogli zobaczyć, że właśnie skopiowaliśmy to z dokumentacji łańcucha łączy, dzięki temu\nnasz Supabase Vector tworzy nasze dokumenty, dzięki czemu framework LangChain\nwspółpracuje z wektorem Supabase, a następnie jedną rzeczą, która Dodałem tutaj szczególnie\nmożliwość zezwolenia uwierzytelnionym użytkownikom na wysyłanie zapytań do dokumentów publicznych, więc używa się\ntutaj zasad bezpieczeństwa na poziomie wiersza, więc chcieliśmy tylko zezwolić na wysyłanie zapytań do uwierzytelnionych\nużytkowników w pewnym sensie ze strony klienta, czy możemy na przykład na to pozwolić, w przeciwnym razie jest tak\nsamo tutaj, jak to, które zostało dodane tutaj w ramach zabezpieczeń na poziomie roli, a następnie przechowujemy\nrozmowy, więc w zasadzie, hm, znasz sortowanie tekstu tego, co zostało wpisane\nna czacie, a następnie tego, co odpowiedziała sztuczna inteligencja, więc przechowujemy\nrozmowy z dezorientatorem i chatbotem AI, a także chcemy pamiętać historię czatu, a także wprowadzamy\ntę historię czatu do poproś, aby poznać także historię poprzednich rozmów\ni ponownie stosujemy tutaj rodzaj polityki bezpieczeństwa na poziomie roli, w szczególności, że tylko\nużytkownik może zobaczyć swój własny rodzaj rozmów, hm, z którymi znasz się za pomocą chatbota\nuh, więc blokujemy tutaj trochę informacji, OK, świetnie, więc przyjrzyjmy się,\nmożemy to uruchomić, więc możemy powiedzieć npm run def, więc przede wszystkim wiesz, że Supabase działa\nlokalnie, a potem też mamy nasze uh, chat bot działa tutaj lokalnie i jest\nwyposażony w autoryzację Supabase, więc jest to interfejs autoryzacji do reagowania, ale przede wszystkim chcemy\nzaindeksować pewne informacje i wiesz, tutaj na przykład zatrudniamy, jeśli nie wiesz\nmożesz sprawdzić kariery w Supabase, na przykład zatrudniamy dla klientów Architekt rozwiązań\ni to jest cały opis stanowiska, jest tam wiele informacji, które znasz,\njak 100% praca zdalna, hm, ESOP w firmie Posiadanie kapitału, um tak, mnóstwo\nrzeczy więc wiesz, że ułatwimy nam życie uh i faktycznie przeszukajmy to, więc przeszukajmy API z ukośnikiem,\num, możemy zaindeksować nasz opis stanowiska tutaj i widzimy, że teraz czołgamy się, um, nasze kotlety i\nmy też się czołgamy, więc rodzaj robota of działa trochę rekurencyjnie, przeszukuje\nhmm strony, które są w nim w pewnym sensie połączone i wtedy możemy zobaczyć, OK, to już zrobione,\nwięc co możemy teraz zobaczyć, jeśli przejdziemy do Supabase Studio tutaj, więc znowu mamy localhost,\njeśli nie pamiętasz, możemy zrobić status Supabase po przeprowadzeniu nadzorowanego startu, możemy\nuzyskać nasze lokalne dane tutaj, abyśmy mogli otworzyć ten projekt lokalnie tutaj i możemy\nteraz szukać w: prowadzimy rozmowy, więc nie prowadzimy jeszcze żadnych rozmów, ale tutaj mamy nasze\ndokumenty, więc to jest to, co przeszukaliśmy, uh, tutaj mamy nasze osadzanie wektorów, uh i widać\nrodzaj linii kodu, a nie linie kodu, więc jest też trochę metadanych i\nsą to pewnego rodzaju linie, więc dokumenty są w pewnym sensie podzielone na różne sekcje, więc\nhm, używając również metadanych, możemy następnie przeprowadzić pewne filtrowanie, co jest naprawdę potężne w\npostgresie, gdzie mamy Json typ danych B, abyśmy mogli wrzucić do niego pełny rodzaj dokumentów Json,\nwiesz, że znasz nasze dokumenty jako świetne metadane, więc teraz to przeszukaliśmy, mamy\nto w naszej bazie danych, więc teraz możemy tylko mieć spójrz, jak działał ten robot, więc\njest to w naszym Pages API, a następnie przeszukaj tutaj, więc używamy łańcucha długości, używamy naszych\nosadzań openai z LangChain, a następnie używamy sklepu Supabase Vector, więc jest to naprawdę fajne\nrodzaj łańcucha długości jest zintegrowany ze sklepem Supabase Vector i tak naprawdę po prostu\nz zapytania otrzymujemy adresy URL, które, hm, chcemy zaindeksować, hm, tworzymy coś w rodzaju\nkolekcji dokumentów, więc w pewnym sensie dzielimy sekcje, aby upewnić się, że mamy odpowiedni\nrozmiar, um, aby utworzyć osadzanie, więc nie zabraknie nam rozmiaru tokena,\num, dzielimy tutaj rodzaje dokumentów, a następnie tworzymy nasz osadzając tak otwarte\nosadzanie AI, tworzymy nasz sklep Supabase Vector, po prostu umieszczamy\ntutaj klienta administracyjnego Supabase, więc klient administracyjny Supabase po prostu używa um tutaj, widzimy, że używa klucza prywatnego, który jest\ntutaj naszym kluczem roli usługi, uh i wtedy możemy wykonujemy pewnego rodzaju operacje administracyjne, czyli\nwstawiamy te dokumenty, więc następnie, hm, tak, tworzymy coś w rodzaju naszej kolekcji dokumentów,\nhm, dodając coś w rodzaju przechowywania wszystkich dokumentów, a następnie mamy dokumenty tutaj w naszej bazie danych\ni możemy następnie przeprowadzać wyszukiwania na nich, więc przejdźmy do tego, więc przede wszystkim będziemy musieli się zalogować.\nWięc obecnie, jeśli zajrzymy tutaj do naszego projektu, hm, więc znowu działamy na localhost, uruchamiamy\ncały stos Supabase lokalnie i nie nie mam jeszcze żadnych użytkowników, więc zarejestrujmy\nnowego testera użytkowników w test dot de i um tutaj, więc jeśli powiemy zaloguj się, um, nie jesteśmy, znasz nieprawidłowe\ndane uwierzytelniające, ponieważ nie mamy, więc zarejestrujmy się, a potem musimy sprawdź nasz e-mail, aby znaleźć\nlink do rozmowy, teraz działamy na localhost, więc nie wysyłamy tutaj prawdziwych e-maili,\nale jedyne, co możemy zrobić, to mieć usługę o nazwie w wiadrze, która jest\nrównież naprawdę fajną usługą Open Source i widzimy tutaj, że mamy potwierdzenie Twojego adresu e-mail, więc ten został właśnie\nwysłany, możemy kliknąć i potwierdzić nasz adres e-mail i teraz widzimy, że jesteśmy zablokowani\nhm, nasza aplikacja tutaj. Działam na localhost, więc teraz możemy rozmawiać z naszymi dokumentami, więc może\nzapytajmy, czy Supabase pozwala na pracę zdalną, znak zapytania, więc odpalamy to teraz, hm, znajdujemy\ndopasowania i możemy tutaj zobaczyć, więc znaleźliśmy pasujące osoby. To są te dwie\noferty pracy w Supabase, uh, a teraz dokument jest za długi, więc podsumowujemy informacje z\ndwóch ogłoszeń o pracę, a następnie łączymy w jedną całość naszą zachętę, abyśmy mogli zobaczyć tutaj nasz monit\n, a następnie przesyłamy strumieniowo odpowiedź, tak, Supabase obsługuje pracę zdalną,\nhm, w pełni zdalna komunikacja będzie odbywać się za pośrednictwem wideo e-mail, tak, tak, i to jest dokładnie to,\num, więc to działa całkowicie zgodnie z oczekiwaniami, przyjrzyjmy się, jak to wygląda w\nrzeczywistości funkcja czatu działa, więc znowu, hm, jej sercem jest coś w rodzaju\nchat dot TS. Tak, znowu, uh, rodzaj LangChain, uh, otwarte AI. Mamy tutaj szablon podpowiedzi,\na potem mamy nasz podsumowanie i tutaj używamy pomocników uwierzytelniania tworzymy\nklienta serwera Pages, który jest rodzajem witryny serwera, naszego klienta, którego możemy używać do wykonywania pewnego rodzaju\nuwierzytelnionych zapytań na serwerze, więc właśnie otrzymujemy naszego\nklienta autoryzacji Supabase, więc nadchodzi nasz nadzorowany klient autoryzacji stąd na dole, więc tworzymy\nhm uh Pages uh klient serwera uh, umieszczamy żądania i odpowiedzi pewne\ninformacje w czasie rzeczywistym, więc wyłączamy tutaj limit szybkości, możemy to zrobić za pomocą minus jeden, więc chcemy po prostu\nprzesyłać strumieniowo jakiekolwiek prawo, przychodzimy, wtedy robimy naszą sesję i jeśli jesteśmy\nuwierzytelnieni, to mamy tutaj nasze, jeśli mamy sesję, możemy wtedy odpalić i zająć się naszym czatem,\nhm, i co się tutaj dzieje, więc jesteśmy teraz używamy przede wszystkim naszego trybu offline, aby uzyskać\nkanał w czasie rzeczywistym z identyfikatorem użytkownika, więc tego używamy do komunikacji z klientem serwera,\na potem wstawiamy także naszą komunikację [Muzyka],\num, więc w zasadzie zaczynamy wyłączamy rozmowę dla sztucznej inteligencji, która daje nam identyfikator interakcji, więc\nmożemy w pewnym sensie użyć tutaj identyfikatora uid, a następnie otrzymujemy\nhistorię rozmowy, hm, historię blokad, więc to tylko rodzaj patrzenia na naszą bazę danych, więc możemy sprawdzić,\nczy możemy spójrz na nasze studio, więc tutaj mamy teraz rozmowy, mamy informacje od\nnaszego użytkownika, pytanie i odpowiedź tutaj, więc odbyłem już jedną rozmowę wcześniej,\nhm, która jest tutaj przechowywana, a następnie składamy razem, hm, ten łańcuch modeli językowych przy użyciu pewnego rodzaju nasz\nszablon podpowiedzi To jest szablon zapytania, w pewnym sensie biorąc pod uwagę następujący monit użytkownika\ni dziennik konwersacji, sformułowaną odpowiednią odpowiedź, więc monit użytkownika jest rodzajem\nhistorii konwersacji zapytania i w pewnym sensie podajemy mu tutaj szereg instrukcji,\nhm, zaczynamy a następnie tworzymy nasz kanał nadawczy, abyśmy\nmogli go subskrybować i zasadniczo, kiedy już zasubskrybujemy, możemy wysłać transmisję\n, więc tutaj właśnie wysyłamy, OK, zaczynamy szukamy dopasowań, więc tutaj pobieramy\ndopasowania z osadzania, więc jest to rodzaj łańcucha długości,\num łańcuch ogniw, a także nadzorowany klient otwiera osadzanie AI i magazyn wektorów,\nhm, po prostu przeprowadzamy wyszukiwanie podobieństw w naszym sklepie tutaj, więc wszystkie te informacje można w pewnym sensie przeszukać\nszczegóły łańcucha długości, ale w ten sposób przeprowadzamy rodzaj wyszukiwania podobieństw za pomocą\nLangChain, aby znaleźć odpowiednie dokumenty dla naszego czatu, abyśmy mogli uzyskać dopasowania z dopasowań, które\nnastępnie mamy nasze adresy URL i jak widzieliśmy, wylogowaliśmy je z konsoli, a na koniec\npo prostu uzyskujemy metadane dopasowania, pobieramy tekst i adresy URL, a następnie w zasadzie\nbudujemy razem nasz szablon podpowiedzi z podsumowaniami, więc to jest miłe podsumowanych szczegółów\nz naszych dokumentów, pytanie użytkownika, historia rozmów oraz\nadresy URL, a następnie po prostu przeprowadzamy nasz, hmm, otwarty czat AI, używając modelu turbo GPT 3.5,\num i po prostu składamy to tu i tam, co robimy To, co robimy, to hm, kiedy już będziemy mieć jakieś aktualizacje\n, więc w zasadzie tak tutaj działa przesyłanie strumieniowe, więc mówimy, że przesyłanie strumieniowe jest prawdziwe i\nza każdym razem, gdy otrzymamy nowy token, wysyłamy to za pośrednictwem naszego kanału transmisji\ni gdzie następnie dostajemy to po stronie klienta, a na końcu, kiedy cały łańcuch wzmacniaczy LL jest w\npewnym sensie skończony, po prostu aktualizujemy naszą rozmowę, uh, za pomocą identyfikatora interakcji\nw bazie danych, abyśmy także mieli odpowiedzi od sztucznej inteligencji w naszym dzienniku rozmów,\nhm, tak, to w zasadzie tyle, możemy spojrzeć na indeks tutaj, więc w indeksie, którego używamy, wiesz,\nże jest renderowany po stronie klienta, hm, więc używamy klienta przeglądarki Supabase uh tutaj z pomocnicy autoryzacji Supabase\n, uh, a potem w zasadzie po prostu składamy razem, hm, gdzie to mamy tutaj, tak,\nw pewnym sensie tworzymy, hm, składamy autoryzację za pomocą komponentu autoryzacji superface tutaj, a potem\nmamy tylko naszego słuchacza kanału, więc to jest nasza transmisja na kanale Supabase w czasie rzeczywistym, więc kiedy\notrzymamy wydarzenie na czacie, po prostu po prostu sprawdzamy, czy to jest odpowiedź, to jest wiadomość o statusie,\nodpowiedź, i co tam masz, a potem po prostu aktualizujemy wiadomość do naszego chatbota, uh, i to jest\nmiłe tego, w jaki sposób uzyskujemy rodzaj przesyłania strumieniowego za pomocą Supabase w czasie rzeczywistym, hm, wielkość naszego klienta, tak,\nhm, to w zasadzie tyle, hm, w ten sposób można w pewnym sensie\npołączyć wszystkich tych różnych dostawców usług w zasadzie w super tempie, aby funkcjonalność była dostępna, jeśli jesteś\nzainteresowany budowaniem z Supabase, uh, z większą ilością aplikacji next.js, jest więcej rodzajów aplikacji AI,\nmamy wyszukiwarkę dokumentów xjs Openai, która faktycznie korzysta z um versal um versal AI SDK, więc\njeśli jesteś zainteresowany, wiesz, rodzaj jak to działa, możesz to obejrzeć tutaj.\nMamy też wyjaśnienie w formie wideo, więc bardzo dziękujemy za włączenie się i do zobaczenia w następnym filmie\nzagranicznym"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "pt",
        "plaintext": "Olá, hoje estamos pensando em construir um chatbot com next.js e LangChain usando Supabase\nVector, então agora podemos conversar com nosso documento, então talvez vamos perguntar se o Supabase permite\nponto de interrogação de trabalho remoto, então estamos disparando isso agora, hum, nós ' estamos encontrando as correspondências e podemos ver aqui,\nentão encontramos nossas correspondências, essas são essas duas ofertas de emprego da Supabase e agora o documento é\nmuito longo, então estamos resumindo as informações das duas ofertas de emprego e então estamos\njuntando nosso prompt, então podemos ver aqui nosso prompt uh e então estamos transmitindo de volta a\nresposta uh sim Supabase suporta trabalho remoto agora esta demonstração é um fork da\ndemonstração Pinecone uh chatbot e este é um trabalho realmente incrível de uh Roy aqui você pode ler a postagem do blog, vou colocar um link abaixo de\num tipo de conceito de construção de um chatbot multiusuário com cadeia de links JS em next.js e\nhá alguns componentes nele, mas o mais importante é o que eu meio que queria tentar aqui é\nsubstituir muitos desses serviços de diferença pelos recursos integrados\nao Supabase, então, em vez do Pinecone, estamos usando o Supabase Vector em vez de habilmente, estamos\nusando o Supabase em tempo real, em vez do cockroachdb, estamos usando o banco de dados postgres que vem com\na pilha Supabase e, em vez de impressão digital, estamos usando a autenticação Supabase, então todos esses serviços\nestamos resumindo-os em apenas Supabase e abrindo AI com next.js aqui agora em termos\nde arquitetura para o chatbot, temos dois componentes, então temos um indexador,\nque meio que escreve um embeddings, que gera embeddings de nós mesmos da Verdade\naqui para que possamos olhar o indexador para que tenhamos nossa fonte da Verdade, que é algum site que nós temos\num rastreador para obter essas informações do site e, em seguida, usando LangChain e IA aberta,\nestamos gerando nossos embeddings e, em seguida, armazenando-os em nosso vetor Supabase e\nentão, quando queremos conversar com nosso tipo de Verdade em si, basicamente pegamos a consulta do usuário\nnovamente, criamos uma incorporação a partir dessa consulta e, em seguida, pesquisamos em todos os documentos\npara encontrar o tipo de fonte de verdade relevante que indexamos os\nURLs relevantes, resumimos o conteúdo desses URLs e então onde estamos gerando uma espécie de resposta e\ntransmitindo isso de volta para o usuário usando tempo real supervisionado, agora a grande vantagem do LangChain é\nque ele tem suporte integrado para Supabase Vector, então a maneira como podemos fazer isso é simplesmente pegar\nesse esquema aqui e aplique isso ao nosso banco de dados usando a extensão vetorial e, se você clonar\naqui, clonar esta demonstração do chatbot da cadeia de links, o URL também está abaixo na descrição,\npodemos então abri-lo no código vs, por exemplo, e podemos ver isso temos algumas migrações\naqui, então essas são migrações iniciais que aplicamos quando executamos um Supabase start\npara que possamos executar o Supabase start aqui para iniciar nossa pilha local Eu já o tenho em execução para que\npossa executar o status supervisionado para ver o tipo de local credenciais e se eu abrir isso aqui\npara que possamos ver que acabamos de copiar isso da documentação da cadeia de links, então é isso que permite que\nnosso vetor Supabase crie nossos documentos, basicamente faz com que a estrutura LangChain\nfuncione com o vetor Supabase e então uma coisa que Eu adicionei especificamente aqui\na capacidade de permitir a consulta em documentos públicos para usuários autenticados, então isso está usando\npolíticas de segurança em nível de linha aqui e então queríamos apenas permitir a consulta para\nusuários autenticados do lado do cliente, nós podemos permitir isso, por exemplo, caso contrário, é o\nmesmo aqui que este, que é adicionado na segurança do nível de função aqui e também estamos\narmazenando as conversas, de modo que é basicamente um, você sabe a classificação do texto daquilo que foi digitado\nno chat e depois o que a IA respondeu, então estamos armazenando as\nconversas do confusor e do chatbot da IA, bem como queremos lembrar o histórico do chat e também estamos injetando\nesse histórico de chat no solicita também saber um tipo de histórico de conversas anteriores\ne, novamente, estamos aplicando uma espécie de política de segurança em nível de função aqui, especificamente, para que apenas\no usuário possa ver seu próprio tipo de conversa, com o qual você conhece o chatbot\nuh, então estamos bloqueando algumas informações aqui, ok, ótimo, então vamos dar uma olhada,\npodemos executar isso para que possamos dizer npm run def, então, primeiro de tudo, você sabe que temos o Supabase rodando\nlocalmente e também temos nosso uh, bot de bate-papo aqui rodando localmente e vem\ncom autenticação Supabase, então esta é a UI de autenticação para reagir, na verdade, mas primeiro de tudo, queremos\nrastrear algumas informações e você sabe aqui, por exemplo, estamos contratando se você não não sabe\nvocê pode conferir as carreiras da Supabase, por exemplo, estamos contratando para clientes Arquiteto de soluções\ne esta é toda a descrição do trabalho aqui, há muitas informações lá, você\nsabe, como trabalho 100% remoto, ESOP na empresa Propriedade de capital, sim, toneladas de\ncoisas então você sabe, vamos tornar nossas vidas mais fáceis, uh, e vamos realmente rastrear isso, então API slash crawl,\npodemos rastrear nossa descrição de trabalho aqui e o que podemos ver é que agora estamos rastreando nossos recursos e\ntambém estamos rastreando, então o tipo rastreador do faz uma coisa um pouco recursiva, onde rastreia\nas páginas que estão vinculadas a ele também e então podemos ver que tudo bem, isso foi feito agora,\nentão o que podemos ver na verdade agora, se formos para o Supabase Studio aqui, então temos o localhost\nnovamente, se você não se lembra, podemos fazer o status do Supabase depois de executarmos um início supervisionado, podemos\nobter nossos detalhes locais aqui e para que possamos abrir este projeto localmente aqui e\nagora podemos olhar temos nossas conversas, então não temos nenhuma conversa ainda, mas aqui temos nossos\ndocumentos, então é isso que rastreamos, uh, aqui temos nossos embeddings de vetor, uh e você\npode ver algumas linhas de código, não linhas de código, então há alguns metadados também e\nessas são algumas linhas, então os documentos são divididos em seções diferentes, então,\nusando os metadados também, podemos realizar alguma filtragem, então isso é realmente poderoso no\npostgres onde temos o Json Tipo de dados B para que possamos colocar todos os tipos de documentos Json em\num, você sabe que conhece nossos documentos aqui como ótimos metadados, então agora que rastreamos isso, temos\nem nosso banco de dados, então agora o que podemos fazer é vamos realmente ter uma olhada em como esse rastreador funcionou, então\nisso está em nossa API de páginas e, em seguida, rastreie aqui, então estamos usando a cadeia de comprimento, estamos usando nossos\nembeddings openai do LangChain e, em seguida, estamos usando a loja Supabase Vector, então isso é realmente legal para\numa espécie de cadeia de comprimento é integrada ao armazenamento Supabase Vector e então, na verdade,\na partir da consulta, estamos obtendo os URLs que queremos indexar, estamos criando uma espécie de\ncoleção de documentos, então estamos dividindo uma espécie de as seções para ter certeza de que temos o\ntamanho certo, você sabe, um para criar a incorporação, para que não fiquemos sem o tamanho do token\ne dividindo os documentos aqui e então estamos criando nosso incorporando embeddings de IA tão abertos,\nestamos criando nossa loja Supabase Vector apenas colocando um cliente administrador Supabase\naqui, então o cliente administrador Supabase apenas usa um aqui, podemos ver que usa a chave privada que é\nnossa aqui nossa chave de função de serviço uh e então podemos realizar um tipo de operação administrativa que é\ninserir esses documentos e então estamos criando uma espécie de em nossa coleção de documentos\ne adicionando uma espécie de armazenamento de todos os documentos e então temos os documentos aqui em nosso banco de dados\ne podemos então realizar pesquisas neles, então vamos ver isso, então, primeiro de tudo, precisaremos fazer login.\nAtualmente, se olharmos em nosso projeto aqui, estamos executando novamente no localhost, estamos executando\ntoda a pilha do Supabase localmente e não ainda não temos nenhum usuário, então vamos inscrever um\nnovo testador de usuário em test dot de e hum aqui, então se dissermos login, você não conhece\ncredenciais inválidas porque ainda não o fizemos, então vamos nos inscrever e então precisamos verifique nosso e-mail para obter o\nlink da conversa, agora estamos executando no localhost, então não estamos enviando e-mails reais aqui,\nmas o que podemos fazer é ter o serviço chamado no bucket, que\ntambém é um serviço de código aberto muito legal e podemos ver aqui que confirmamos seu e-mail, então este foi\nenviado agora há pouco e podemos clicar e confirmar nosso endereço de e-mail e agora podemos ver que estamos bloqueados\nhum, nosso aplicativo aqui estou executando no localhost, então agora podemos conversar com nossos documentos, então talvez\nvamos perguntar se o Supabase permite ponto de interrogação para trabalho remoto, então estamos iniciando isso agora, estamos encontrando\nas correspondências e podemos ver aqui então encontramos nossas correspondências, essas são essas duas\nofertas de emprego da Supabase, uh, e agora o documento é muito longo, então estamos resumindo as informações das\nduas ofertas de emprego e, em seguida, estamos montando nosso prompt para que possamos ver aqui nosso prompt\ne então estamos transmitindo de volta a resposta uh sim Supabase suporta trabalho remoto\numa comunicação totalmente remota acontecerá por e-mail vídeo blá blá e é exatamente isso,\nentão isso está funcionando perfeitamente como esperado, vamos dar uma olhada em como\nhum o real a funcionalidade de bate-papo está funcionando, então, novamente, o cerne disso está aqui\nno bate-papo ponto TS Sim, novamente, uh, tipo LangChain, uh, coisas abertas, AI, temos um modelo de prompt aqui\n, e então temos nosso resumidor e aqui usando os auxiliares de autenticação estamos criando um\ncliente de servidor Pages que é uma espécie de site de servidor, nosso cliente, que podemos usar para realizar\nconsultas autenticadas no servidor e, portanto, estamos apenas obtendo nosso\ncliente de autenticação Supabase, para que nosso cliente de autenticação supervisionado esteja chegando daqui de baixo, então estamos criando\num uh Páginas uh cliente servidor uh colocando nas solicitações e na resposta algumas\ninformações em tempo real, então estamos desabilitando o limite de taxa aqui, podemos fazer isso com o menos um, então só queremos\ntransmitir de qualquer forma, estamos chegando, então estamos recebendo nossa sessão e se estivermos\nautenticados, então temos aqui, se tivermos uma sessão, podemos então iniciar e lidar com nosso bate-papo\ne o que está acontecendo aqui é então estamos agora usando nosso offline primeiro de tudo para obter um\ncanal em tempo real com o ID do usuário, então é isso que estamos usando para a comunicação servidor-cliente,\nentão também estamos inserindo nossa [Música] em comunicação,\nentão basicamente estamos começando uma conversa para a IA que nos dá um ID de interação para que\npossamos usar o uid aqui, e então estamos obtendo a conversa e\num histórico de bloqueio, então isso é apenas uma espécie de olhar para nosso banco de dados para que possamos ver,\npodemos olhe para o nosso estúdio, então aqui agora temos conversas, temos essas informações do\nnosso usuário, a pergunta e a resposta aqui, então eu já tive uma conversa anterior\nque foi armazenada aqui, então estamos montando essa cadeia de modelos de linguagem usando uma espécie de nosso\nmodelo de prompt, este é o modelo de consulta aqui, dado o seguinte prompt do usuário\ne o registro de conversa formularam uma resposta relevante, então o prompt do usuário é uma espécie de\nhistórico de conversa de consulta e estamos dando um monte de instruções aqui,\nvamos lá e então o que estamos fazendo é criar nosso canal de transmissão para que possamos\nassinar o canal e basicamente, uma vez que estivermos inscritos, podemos enviar uma transmissão\ne então aqui estamos enviando agora, ok, estamos começando, nós estamos encontrando correspondências, então aqui estamos\nobtendo correspondências de embeddings, então este é um tipo de cadeia de comprimento,\numa cadeia de links, bem como embeddings Ai abertos do cliente supervisionado e o armazenamento de vetores,\nestamos apenas fazendo nossa pesquisa de similaridade de loja aqui, então, todas essas informações você pode pesquisar\nnos detalhes da cadeia de comprimento, mas é assim que estamos fazendo nossa pesquisa de similaridade com\nLangChain para encontrar os documentos relevantes para nosso bate-papo, para que possamos obter nossas correspondências a partir das correspondências que\ntemos então nossos URLs e você viu que desconectamos esses URLs pelo console e, por último, estamos\napenas obtendo os metadados de correspondência, obtendo o texto e os URLs e, em seguida, estamos basicamente\nconstruindo juntos nosso modelo de prompt com os resumos, para que você saiba, tipo dos\ndetalhes resumidos de nossos documentos a pergunta do usuário sobre o histórico de conversas, bem como\nos URLs e então estamos apenas fazendo nosso sim, abra o bate-papo de IA aqui usando o modelo turbo GPT 3.5\nhum e apenas juntando isso aqui e então o que nós O que estamos fazendo é assim que tivermos alguma atualização,\nentão basicamente é assim que o streaming funciona aqui, então estamos dizendo que o streaming é verdadeiro e\nsempre que recebermos um novo token, enviaremos isso através de nosso canal de transmissão\ne onde o obtemos no lado do cliente e, no final, quando toda a cadeia de amplificadores LL estiver\nconcluída, estamos apenas atualizando nossa conversa, uh, com o ID de interação\nno banco de dados para que também tenhamos o respostas da IA ​​em nosso log de conversa,\nsim, é isso, podemos olhar o índice aqui, então no índice que estamos usando, você sabe\nque isso é renderizado do lado do cliente, então estamos usando o cliente de navegador Supabase uh aqui de os\najudantes de autenticação do Supabase, uh, e então estamos apenas montando, onde temos isso aqui, sim,\nestamos meio que montando a autenticação usando o componente de autenticação superface aqui e então\ntemos apenas nosso ouvinte de canal, então este é nossa Supabase, uh, transmissão do canal em tempo real, então, quando\nrecebemos um evento de bate-papo, basicamente apenas verificamos, ok, isso é uma resposta, isso é uma mensagem de status,\nuh, resposta e o que você tem, uh, e então apenas atualizamos nossa mensagem do chatbot, uh, e isso é\ngentil de como obtemos o tipo de streaming usando Supabase em tempo real para o tamanho do nosso cliente, sim,\né basicamente isso, é assim que você pode obter todos esses diferentes\nprovedores de serviços agrupados basicamente dentro de um super ritmo para que a funcionalidade esteja disponível se você está\ninteressado em construir com um Supabase uh com mais com next.js mais tipos de aplicativos de IA,\ntemos uma pesquisa de documento xjs openai e isso realmente usa o SDK de IA um versal um versal, então\nse você estiver interessado em você sabe o tipo de como isso funciona, você pode ver isso aqui e também temos\num vídeo de explicação para este, então muito obrigado por assistir e até o próximo vídeo\nestrangeiro"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "es",
        "plaintext": "Hola, hoy estamos buscando construir un chatbot con next.js y LangChain usando Supabase\nVector, así que ahora podemos chatear con nuestro documento, así que tal vez preguntemos si Supabase permite el trabajo remoto.\nSigno de interrogación, así que estamos activando esto ahora. Estamos encontrando las coincidencias y podemos ver aquí,\nasí que encontramos nuestras coincidencias. Estas son estas dos ofertas de trabajo de Supabase y ahora el documento es\ndemasiado largo, así que estamos resumiendo la información de las dos ofertas de trabajo y luego estamos\nreuniendo nuestro mensaje um así que podemos ver aquí nuestro mensaje uh y luego transmitiremos la\nrespuesta uh sí Supabase admite el trabajo remoto ahora esta demostración es una bifurcación de la demostración del chatbot Pinecone uh\ny este es un trabajo realmente increíble de uh Roy aquí puedes leer la publicación del blog. Lo vincularé a continuación.\nEs una especie de concepto de construcción de un chatbot multiusuario con cadena de enlaces JS en next.js y\ntiene un par de componentes, pero lo más importante es lo que quería. Intentar aquí es\nreemplazar muchos de estos servicios diferentes con las capacidades integradas\nen Supabase, por lo que en lugar de Pinecone estamos usando Supabase Vector en lugar de Hablemente estamos\nusando Supabase en tiempo real en lugar de cockroachdb estamos usando base de datos de postgres que viene con\nla pila de Supabase y luego, en lugar de la huella digital, usamos la autenticación de Supabase, por lo que todos estos servicios\nlos estamos reduciendo a solo Supabase y abrimos AI um con next.js aquí ahora en términos\nde la arquitectura para el chatbot um tenemos una especie de dos componentes, así que tenemos un indexador\num que escribe um incrustaciones como que genera incrustaciones de nosotros mismos de la Verdad\naquí para que podamos mirar el indexador y tener nuestra fuente de la Verdad, que es algún sitio web que tenemos\nun rastreador que obtiene esa información del sitio web y luego usamos LangChain y AI abierta,\ngeneramos nuestras incrustaciones y luego las almacenamos en nuestro vector Supabase y\nluego, cuando queremos conversar con nuestro tipo de Verdad misma, básicamente tomamos la consulta del usuario\nnuevamente creamos una incrustación a partir de esa consulta, luego buscamos en todos los documentos\npara encontrar la fuente de verdad relevante que indexamos, las URL relevantes,\nresumimos ese contenido de esas URL y luego dónde Estamos generando una especie de respuesta y\ntransmitiéndola al usuario usando tiempo real supervisado. Ahora lo mejor de LangChain es\nque tiene soporte integrado para Supabase Vector, así que la forma en que podemos hacer esto es simplemente tomar\neste esquema. aquí y aplíquelo a nuestra base de datos usando la extensión vectorial, por lo que si clona\naquí, clona esta demostración de chatbot de cadena de enlaces, la URL también se encuentra debajo en la descripción,\nluego podemos abrir esto en el código vs, por ejemplo, y podemos verlo. tenemos algunas migraciones\naquí, así que estas son migraciones iniciales que aplicamos cuando ejecutamos un inicio de Supabase\npara que podamos ejecutar el inicio de Supabase aquí para iniciar nuestra pila local. Ya lo tengo ejecutándose, por lo que puedo\nejecutar el estado supervisado para ver el tipo de local. credenciales y si abro esto aquí\npara que podamos ver que acabamos de copiar esto de la documentación de la cadena de enlaces, esto es lo que permite que\nnuestro Supabase Vector cree nuestros documentos, así que básicamente hace que el marco LangChain\nfuncione con el vector Supabase y luego una cosa que He agregado específicamente aquí\nla capacidad de permitir la consulta de documentos públicos para usuarios autenticados, por lo que esto utiliza\npolíticas de seguridad de nivel de fila aquí, por lo que solo queríamos permitir la consulta para\nusuarios autenticados desde el lado del cliente. ¿Podemos permitir eso, por ejemplo? De lo contrario, es lo\nmismo aquí que esto, que se agrega en la seguridad de nivel de rol aquí y luego también estamos\nalmacenando las conversaciones, así que eso es básicamente, ya sabes, el tipo de texto. de eso que se escribió\nen el chat y luego lo que respondió la IA, por lo que estamos almacenando las\nconversaciones del confusor y del chatbot de IA, así como también queremos recordar el historial del chat y también estamos inyectando\nese historial de chat en el Solicite también conocer el historial de conversaciones anteriores\ny nuevamente estamos aplicando una especie de política de seguridad a nivel de rol aquí específicamente para que solo\nel usuario pueda ver su propio tipo de conversaciones con el chatbot.\nuh, entonces estamos bloqueando el tipo de información aquí, está bien, así que echemos un vistazo\n, podemos ejecutar esto para que podamos decir npm run def, así que primero que nada, sabes que tenemos Supabase ejecutándose\nlocalmente y luego también tenemos nuestro uh, el bot de chat se ejecuta localmente y\nviene con autenticación de Supabase, por lo que esta es la interfaz de usuario de autenticación para reaccionar, pero primero que nada queremos\nrastrear cierta información y usted sabe aquí, por ejemplo, que estamos contratando si no lo sabía.\npuede consultar las carreras de Supabase, por ejemplo, estamos contratando para clientes Arquitecto de soluciones\ny esta es la descripción completa del trabajo aquí, hay mucha información allí, ya sabe,\ncomo trabajo 100 por ciento remoto, um ESOP en la empresa, propiedad accionaria, um, sí, toneladas de\ncosas . Entonces, ya sabes, hagamos nuestras vidas más fáciles, y realmente rastreemos esto para que API rastree con barra diagonal,\npodemos rastrear la descripción de nuestro trabajo aquí y lo que podemos ver es que ahora estamos rastreando nuestras habilidades y\ntambién estamos rastreando para que el tipo de rastreador. hace algo recursivo en el que rastrea\nlas páginas que están vinculadas en ellas también y luego podemos ver, está bien, esto ya está hecho,\nasí que lo que podemos ver ahora si vamos al Supabase Studio aquí para que tengamos el host local\nnuevamente, si no lo recuerda, podemos hacer el estado de Supabase después de haber ejecutado un inicio supervisado, podemos\nobtener nuestros detalles locales aquí y podemos abrir este proyecto localmente aquí y\nahora podemos mirar. Tenemos nuestras conversaciones, así que aún no tenemos ninguna conversación, pero aquí tenemos nuestros\ndocumentos, así que esto es lo que hemos rastreado. Aquí tenemos nuestras incrustaciones de vectores. Y puedes\nver líneas de código, no líneas. de código, por lo que también hay algunos metadatos y\nestas son una especie de líneas, por lo que los documentos se dividen en diferentes secciones, por lo que\nal usar los metadatos también podemos realizar algunos filtrados, lo que es realmente poderoso en\npostgres donde tenemos el Json. Tipo de datos B, por lo que podemos colocar documentos Json completos en\num, sabes, conoces nuestros documentos aquí como metadatos geniales, así que ahora que hemos rastreado esto,\nlo tenemos en nuestra base de datos, así que ahora lo que podemos hacer es tener un vistazo a cómo funcionó ese rastreador, así que\nesto está en nuestra API de páginas y luego rastreamos aquí, así que usamos la cadena de longitud, usamos nuestras\nincrustaciones openai de LangChain y luego usamos la tienda Supabase Vector, por lo que esto es realmente genial para\nse integra una especie de cadena de longitud con la tienda Supabase Vector y luego,\nde la consulta, obtenemos las URL que queremos indexar, estamos creando una especie de\ncolección de documentos, por lo que estamos dividiendo una especie de las secciones para asegurarnos de que tenemos el\ntamaño correcto, ya sabes, para crear la incrustación para que no nos quedemos sin el tamaño del token,\ndividiendo los documentos aquí y luego estamos creando nuestro incrustando incrustaciones de IA tan abiertas,\nestamos creando nuestra tienda Supabase Vector simplemente colocando un cliente de administración de Supabase\naquí para que el cliente de administración de Supabase solo use um aquí, podemos ver que usa la clave privada, que es\nnuestra aquí, nuestra clave de función de servicio, uh, y luego podemos realizar tipo de operaciones de administración que consisten en\ninsertar estos documentos y entonces estamos, um, sí, creando una especie de en nuestra colección de documentos,\num agregando una especie de almacenamiento de todos los documentos y luego tenemos los documentos aquí en nuestra base de datos\ny luego podemos realizar búsquedas. en ellos, así que vayamos a eso, así que primero que nada necesitaremos iniciar sesión.\nActualmente, si miramos nuestro proyecto aquí, estamos ejecutando nuevamente en localhost, estamos ejecutando\ntoda la pila de Supabase localmente y no Todavía no tenemos usuarios, así que registremos un\nnuevo usuario probador en test dot de y um aquí, así que si decimos iniciar sesión, no sabemos que\nlas credenciales no son válidas porque no las tenemos, así que registrémonos y luego debemos revise nuestro correo electrónico para ver el\nenlace de conversación ahora que estamos ejecutando en localhost, por lo que no enviaremos correos electrónicos reales aquí,\npero lo que podemos hacer es tener el servicio llamado en el depósito, que\ntambién es un servicio de código abierto realmente genial y Podemos ver aquí que tenemos nuestro correo electrónico de confirmación, así que este se acaba de\nenviar y podemos hacer clic y confirmar nuestra dirección de correo electrónico y ahora podemos ver que estamos bloqueados.\nUm, nuestra aplicación aquí, la estoy ejecutando en localhost, así que ahora podemos chatear con nuestros documentos, así que tal vez\npreguntemos: ¿Supabase permite el trabajo remoto? Signo de interrogación, así que estamos activando esto ahora. Estamos encontrando\nlas coincidencias y podemos verlas aquí. encontramos nuestras coincidencias, estas son estas dos\nofertas de trabajo de Supabase uh y ahora el documento es demasiado largo, así que estamos resumiendo la información de las\ndos ofertas de trabajo y luego estamos armando nuestro mensaje para que podamos ver aquí nuestro mensaje\ny luego estamos transmitiendo la respuesta uh sí, Supabase admite el trabajo remoto\num comunicación completamente remota se realizará a través de video por correo electrónico yada yada y eso es exactamente eso,\nasí que esto está funcionando completamente como se esperaba, echemos un vistazo a cómo\nfunciona realmente la funcionalidad de chat está funcionando, así que nuevamente, el corazón de esto está aquí\nen chat dot TS Sí, de nuevo, una especie de LangChain, cosas con IA abierta, tenemos una plantilla de aviso aquí\n, y luego tenemos nuestro resumidor y aquí usamos los ayudantes de autenticación. Estamos creando un\ncliente de servidor de Pages, que es una especie de sitio de servidor, nuestro cliente, que podemos usar para realizar tipos de\nconsultas autenticadas en el servidor, por lo que estamos obteniendo nuestro\ncliente de autenticación Supabase para que nuestro cliente de autenticación supervisado esté disponible. desde aquí abajo, así que estamos creando\npáginas, cliente servidor, poniendo en las solicitudes y la respuesta\ninformación en tiempo real, así que deshabilitamos el límite de velocidad. Aquí podemos hacer eso con el menos, así que solo queremos\ntransmitir. tipo de derecho vamos, entonces obtendremos nuestra sesión y si estamos\nautenticados entonces tenemos aquí nuestro si tenemos una sesión entonces podemos iniciar y manejar nuestro chat\num y lo que está sucediendo aquí es así que estamos ahora usamos nuestra conexión fuera de línea en primer lugar para obtener un\ncanal en tiempo real con la identificación del usuario, así que eso es lo que estamos usando para la comunicación del cliente del servidor,\nluego también estamos insertando nuestra comunicación [Música],\nasí que básicamente estamos comenzando. desconectamos una conversación para la IA que nos da una identificación de interacción para que\npodamos usar el uid aquí y luego obtenemos el\nhistorial de bloqueo de la conversación, así que eso es simplemente mirar nuestra base de datos para que podamos mirar\n. mire nuestro estudio, así que ahora tenemos en las conversaciones esta información de\nnuestro usuario, la pregunta y la respuesta aquí, así que ya tuve una conversación antes,\neso se almacenó aquí y luego estamos armando esta cadena de modelo de lenguaje usando una especie de nuestra\nplantilla de aviso, esta es la plantilla de consulta aquí, dada la siguiente solicitud de usuario\ny el registro de conversación, se formuló una respuesta relevante, por lo que la solicitud de usuario es una especie de\nhistorial de conversación de consulta y le estamos dando un montón de instrucciones aquí,\num, ahí vamos. y luego lo que estamos haciendo es crear nuestro canal de transmisión para que podamos\nsuscribirnos al canal y básicamente una vez que estemos suscritos podemos enviar una transmisión\ny aquí estamos enviando, está bien, estamos comenzando. Estamos encontrando coincidencias, así que aquí estamos\nobteniendo coincidencias de incrustaciones, por lo que esta es una especie de cadena de longitud,\nuna cadena de eslabones, así que el cliente supervisado abre incrustaciones de Ai y la tienda de vectores.\nSolo estamos haciendo nuestra búsqueda de similitudes en la tienda. Aquí, toda esa información se puede profundizar\nen los detalles de la cadena de longitud, pero así es como estamos haciendo nuestra búsqueda de similitudes con\nLangChain para encontrar los documentos relevantes para nuestro chat, de modo que obtengamos nuestras coincidencias de las coincidencias que\ntenemos. nuestras URL y, como vio, cerramos la sesión de la consola en esas URL y, por último,\nsimplemente obtenemos los metadatos coincidentes, obtenemos el texto y las URL y luego, básicamente, estamos\nconstruyendo juntos nuestra plantilla de mensajes con los resúmenes, así que ya sabe. de los\ndetalles resumidos de nuestros documentos, la pregunta del usuario, el historial de conversaciones y\nlas URL y luego simplemente estamos haciendo nuestro um, sí, abrimos el chat AI aquí usando el modelo turbo GPT 3.5\num y simplemente juntamos eso aquí y luego lo que Lo que estamos haciendo es una vez que tenemos alguna actualización,\nasí que básicamente así es como funciona la transmisión aquí, así que decimos que la transmisión es verdadera y\ncada vez que recibimos una especie de token nuevo, lo enviamos a través de nuestro canal de transmisión.\ny donde luego lo obtenemos en el lado del cliente y luego al final, cuando toda la cadena de amplificador LL está\nterminada, entonces simplemente actualizamos nuestra conversación con el ID de interacción\nen la base de datos para que también tengamos el respuestas de la IA en nuestro registro de conversación\num sí, eso es más o menos, podemos ver el índice aquí, así que en el índice que estamos usando, ya sabes,\nesto está renderizado en el lado del cliente, así que estamos usando el cliente de navegador Supabase uh aquí desde los\nayudantes de autenticación de Supabase uh y luego básicamente estamos reuniendo um, ¿dónde lo tenemos aquí? Sí,\nestamos como poniendo um juntando la autenticación usando el componente de autenticación de superficie aquí y luego\nsolo tenemos nuestro oyente de canal, así que esto es nuestra Supabase uh transmisión de canal en tiempo real, así que cuando\ntenemos un evento de chat, básicamente simplemente verificamos si esto es una respuesta, este es un mensaje de estado,\nuh, respuesta y qué tienes, y luego simplemente actualizamos nuestro mensaje de chatbot, uh, y eso es\namable. de cómo conseguimos el tipo de transmisión usando Supabase en tiempo real para el tamaño de nuestro cliente, sí,\neso es todo, así es como puedes obtener todos estos diferentes\nproveedores de servicios agrupados básicamente en un súper ritmo para que la funcionalidad esté disponible si está\ninteresado en construir con um Supabase uh con más con next.js más tipos de aplicaciones de IA.\nTenemos una búsqueda de documentos xjs openai y esto en realidad usa el SDK de AI um versal um versal, así que\nsi está interesado, ya sabe. de cómo funciona eso, puedes ver esto aquí y también tenemos\nuna explicación en video para esto, así que muchas gracias por sintonizarnos y nos vemos en el próximo video\n."
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "th",
        "plaintext": "สวัสดี วันนี้เรากำลังดูการสร้างแชทบอทด้วย next.js และ LangChain โดยใช้ Supabase\nVector ดังนั้นตอนนี้เราสามารถแชทกับเอกสารของเราได้ บางทีลองถามดูว่า Supabase อนุญาตให้ใช้\nเครื่องหมายคำถามการทำงานระยะไกลหรือไม่ ดังนั้นเราจะเริ่มดำเนินการตอนนี้ เอิ่ม เรา' กำลังค้นหาคู่ที่ตรงกันและเราสามารถดูได้ที่นี่\nเราจึงพบว่าคู่ของเราคือสองประกาศรับสมัครงาน Supabase และตอนนี้เอกสาร\nยาวเกินไป ดังนั้นเราจึงสรุปข้อมูลจากประกาศรับสมัครงานทั้งสองรายการ แล้วเราก็รวบรวม\nเข้าด้วยกัน เอ่อ แจ้งของเรา แล้วเราจะเห็นที่นี่ เอ่อ แล้วเราจะสตรีมคำ\nตอบกลับ เอ่อ ใช่ Supabase รองรับการทำงานระยะไกล ตอนนี้การสาธิตนี้เป็นทางแยกของ\nการสาธิต Pinecone uh chatbot และนี่เป็นงานที่ยอดเยี่ยมจริงๆ โดย uh Roy ที่นี่ คุณสามารถอ่านโพสต์บนบล็อกได้ ฉันจะลิงก์ไว้ด้านล่าง\nอืม เป็นแนวคิดของการสร้างแชทบอทที่มีผู้ใช้หลายคนด้วยลิงก์เชน JS ใน next.js และ\nอืม มีองค์ประกอบอยู่สองสามอย่าง แต่ที่สำคัญที่สุดคือสิ่งที่ฉันต้องการ การลองที่นี่เป็นการ\nแทนที่บริการที่แตกต่างเหล่านี้ด้วยความสามารถที่มีอยู่\nใน Supabase ดังนั้นแทนที่จะเป็น Pinecone เราจะใช้ Supabase Vector แทนที่จะใช้ความสามารถที่เรา\nใช้ Supabase แบบเรียลไทม์แทนแมลงสาบ db เรากำลังใช้ ฐานข้อมูล postgres ที่มาพร้อมกับ\nSupabase stack จากนั้นแทนที่จะใช้ลายนิ้วมือ เราใช้ Supabase auth ดังนั้นบริการทั้งหมดนี้\nเราจึงต้มมันให้เหลือแค่ Supabase และเปิด AI อืมด้วย next.js ที่นี่ตอนนี้ในแง่\nของสถาปัตยกรรมสำหรับ chatbot เอ่อ เรามีองค์ประกอบสองอย่าง ดังนั้นเราจึงมีตัวทำดัชนี\nอืม ซึ่งประเภทการเขียน อืม การฝัง ชนิดของการสร้างการฝังจาก Truth ของเราเอง\nที่นี่ เพื่อให้เราสามารถดูตัวทำดัชนีได้ ดังนั้นเราจึงมีแหล่งที่มาของความจริง ซึ่งเป็นบางเว็บไซต์ที่เรา มี\ncrawler คอยรับข้อมูลนั้นจากเว็บไซต์ จากนั้นใช้ LangChain และ open AI\nเรากำลังสร้าง embeddings ของเรา จากนั้นจัดเก็บไว้ในเวกเตอร์ Supabase ของเรา และ\nเมื่อเราต้องการแชทกับ Truth ของเราเอง โดยพื้นฐานแล้วเราจะทำ ข้อความค้นหาของผู้ใช้\nอีกครั้งเราสร้างการฝังจากข้อความค้นหานั้น จากนั้นเราค้นหาผ่านเอกสารทั้งหมด\nเพื่อค้นหาแหล่งที่มาของความจริงที่เกี่ยวข้อง ซึ่งเราได้จัดทำดัชนีประเภท\nURL ที่เกี่ยวข้อง เราสรุปเนื้อหานั้นจาก URL นั้นและที่ใด เรากำลังสร้างการตอบสนองและ\nสตรีมมิ่งที่กลับไปยังผู้ใช้โดยใช้เวลาจริงภายใต้การดูแล ตอนนี้สิ่งที่ยอดเยี่ยมสำหรับ LangChain ก็คือ\nอืม มันมีการรองรับ Supabase Vector ในตัว ดังนั้นวิธีที่เราสามารถทำได้คือเราแค่ใช้\nสคีมานี้ ที่นี่ และนำไปใช้กับฐานข้อมูลของเราโดยใช้ส่วนขยายเวกเตอร์ ดังนั้นหากคุณโคลน\nที่นี่ โคลนการสาธิตแชทบอตแบบโซ่ลิงก์นี้ URL ก็อยู่ด้านล่างในคำอธิบาย\nเช่นกัน เราสามารถเปิดสิ่งนี้ขึ้นมาในโค้ด vs เป็นตัวอย่าง และเราสามารถดูได้ เรามีการย้ายข้อมูลบางส่วน\nที่นี่ ดังนั้นนี่คือการย้ายข้อมูลครั้งแรกที่เรานำไปใช้เมื่อเราเรียกใช้ Supabase start\nเพื่อให้เราสามารถเรียกใช้ Supabase start ที่นี่เพื่อเริ่มต้นสแต็กในเครื่องของเรา ฉันกำหนดให้มันทำงานอยู่แล้ว ดังนั้นฉัน\nสามารถเรียกใช้สถานะภายใต้การดูแลเพื่อดูประเภทของท้องถิ่น credentials และถ้าฉันเปิดสิ่งนี้ที่นี่\nเพื่อให้เราเห็นว่าเราเพิ่งคัดลอกสิ่งนี้จากเอกสารประกอบของ link chain ดังนั้นนี่คือสิ่งที่ช่วยให้\nSupabase Vector ของเราสร้างเอกสารของเรา ดังนั้นโดยพื้นฐานแล้วจะทำให้กรอบงาน LangChain\nทำงานร่วมกับเวกเตอร์ Supabase แล้วสิ่งหนึ่งที่ ฉันได้เพิ่มไว้โดยเฉพาะที่นี่\nคือความสามารถในการอนุญาตการสืบค้นในเอกสารสาธารณะสำหรับผู้ใช้ที่ได้รับการรับรองความถูกต้อง ดังนั้นนี่คือการใช้\nนโยบายความปลอดภัยระดับแถวที่นี่ ดังนั้นเราจึงต้องการอนุญาตให้มีการสืบค้นสำหรับ\nผู้ใช้ที่ได้รับการรับรองความถูกต้องเท่านั้นจากฝั่งไคลเอ็นต์ที่เรา เราอนุญาตแบบนั้นได้ไหม มิฉะนั้น มันก็\nเหมือนกับที่นี่ ซึ่งถูกเพิ่มเข้ามาในการรักษาความปลอดภัยระดับบทบาทที่นี่ จากนั้นเราก็\nจัดเก็บการสนทนา ดังนั้น โดยพื้นฐานแล้ว คุณรู้จักการจัดเรียงข้อความ ของสิ่งที่ถูกพิมพ์\nลงในแชท และสิ่งที่ AI ตอบกลับ ดังนั้นเราจึงจัดเก็บความสับสนและ\nการสนทนาแชทบอทของ AI รวมทั้งเราต้องการจดจำประวัติของการแชท และเรายังฉีด\nประวัติการแชทนั้นเข้าไปใน แจ้งให้ทราบประวัติของการสนทนาก่อนหน้านี้ด้วย\nและอีกครั้งที่เรากำลังใช้นโยบายความปลอดภัยระดับบทบาทที่นี่ โดยเฉพาะว่ามีเพียง\nผู้ใช้เท่านั้นที่สามารถเห็นการสนทนาของตนเอง อืม ที่คุณรู้จักด้วยแชทบอต\nเอ่อ เรากำลังล็อคข้อมูลบางอย่างไว้ที่นี่ โอเค เยี่ยมมาก มาดูกันว่า\nเราสามารถเรียกใช้สิ่งนี้ได้ แล้วบอกว่า npm run def ก่อนอื่นเลย คุณรู้ว่าเรามี Supabase ที่ทำงาน\nอยู่ในเครื่อง แล้วเราก็มี um ของเราด้วย เอ่อ แชทบอทที่นี่ทำงานในพื้นที่และมัน\nมาพร้อมกับ Supabase auth ดังนั้นนี่คือ UI การตรวจสอบสิทธิ์สำหรับการตอบสนองจริงๆ แต่ก่อนอื่นเลยเราต้องการ\nรวบรวมข้อมูลบางอย่าง และคุณรู้ไหมว่านี่คือตัวอย่างที่เรากำลังจ้างงานหากคุณไม่รู้\nคุณสามารถดูอาชีพของ Supabase ได้ เช่น เรากำลังจ้างลูกค้า สถาปนิกโซลูชัน\nและนี่คือรายละเอียดงานทั้งหมดที่นี่ มีข้อมูลมากมายในนั้น คุณ\nรู้ไหม เช่น งานระยะไกล 100 เปอร์เซ็นต์ อืม ESOP ในบริษัท ความเป็นเจ้าของหุ้น อืม ใช่ สิ่งต่างๆ มากมาย\nเพื่อให้คุณรู้ว่ามาทำให้ชีวิตของเราง่ายขึ้น เอ่อ และเรามารวบรวมข้อมูลนี้กันจริงๆ เพื่อที่ API slash crawl\nเอิ่ม เราสามารถรวบรวมข้อมูลรายละเอียดงานของเราได้ที่นี่ และสิ่งที่เราเห็นคือตอนนี้เรากำลังรวบรวมข้อมูล อืม สับของเรา และ\nเราก็รวบรวมข้อมูลด้วย ดังนั้นโปรแกรมรวบรวมข้อมูลประเภท ของทำสิ่งที่เรียกซ้ำเล็กน้อยโดยรวบรวม\nข้อมูลหน้า uh ที่มีการเชื่อมโยงอยู่ในนั้นด้วย จากนั้นเราจะเห็นได้ โอเค สิ่งนี้เสร็จสิ้นแล้ว\nเอิ่ม ดังนั้นสิ่งที่เราเห็นได้จริงตอนนี้ ถ้าเราไปที่ Supabase Studio ที่นี่ เพื่อให้เรามี localhost\nอีกครั้ง หากคุณจำไม่ได้ว่าเราสามารถดำเนินการสถานะ Supabase ได้ หลังจากที่เราดำเนินการเริ่มต้นแบบมีการดูแลแล้ว เรา\nจะสามารถรับรายละเอียดในพื้นที่ของเราได้ที่นี่ และเพื่อให้เราสามารถเปิดโครงการนี้ในเครื่องได้ที่นี่ และ\nตอนนี้เราสามารถดูได้ เมื่อเรามีการสนทนา เราก็เลยไม่มีการสนทนาใดๆ แต่ที่นี่ เรามี\nเอกสารของเรา ดังนั้นนี่คือสิ่งที่เรารวบรวมข้อมูล เอ่อ ที่นี่ เรามีการฝังเวกเตอร์ เอ่อ และคุณ\nจะเห็นบรรทัดของโค้ด เอ่อ ไม่ใช่บรรทัด ของโค้ดดังนั้นจึงมีข้อมูลเมตาบางส่วนเช่นกัน และ\nนี่คือบรรทัดต่างๆ ดังนั้นเอกสารจึงถูกแบ่งออกเป็นส่วนต่างๆ ดังนั้น\nใช้ข้อมูลเมตาด้วย จากนั้นเราก็สามารถทำการกรองบางอย่างได้ เพื่อให้มีประสิทธิภาพมากใน\npostgres ที่เรามี Json ประเภทข้อมูล B เพื่อให้เราสามารถวางเอกสาร Json เต็มรูปแบบลงใน\nเอิ่ม คุณรู้ว่าเอกสารของเราที่นี่เป็นเมตาดาต้าที่ยอดเยี่ยม ดังนั้นตอนนี้เราได้รวบรวมข้อมูลนี้แล้ว เรามี\nมันในฐานข้อมูลของเรา ดังนั้นตอนนี้สิ่งที่เราทำได้คือเรามามีข้อมูลจริง ๆ กันดีกว่า ดูว่าโปรแกรมรวบรวมข้อมูลนั้นทำงานอย่างไร โดยให้\nอยู่ใน Pages API ของเรา จากนั้นจึงรวบรวมข้อมูลที่นี่ เพื่อให้เราใช้ length chain เราใช้ openai\nembeddings จาก LangChain จากนั้นเราใช้ Supabase Vector store ดังนั้นนี่จึงเรียบร้อยมากสำหรับ\nสายโซ่ยาวชนิดหนึ่งถูกรวมเข้ากับร้านค้า Supabase Vector จากนั้นจริงๆ แล้ว เอ่อ\nจากข้อความค้นหาที่เราได้รับ URL ที่เราต้องการจัดทำดัชนี เรากำลังสร้างคอลเลก\nชันเอกสารประเภทหนึ่ง ดังนั้นเราจึงแยกประเภท ส่วนต่าง ๆ เพื่อให้แน่ใจว่าเรามีสิทธิ์แบบที่\nคุณทราบ ขนาด อืม ในการสร้างการฝัง เพื่อที่เราจะได้ไม่หมดขนาดของโทเค็น\nอืม การแยกประเภทเอกสารที่นี่ จากนั้นเราก็สร้าง การฝัง ดังนั้นการฝัง AI แบบเปิด\nเรากำลังสร้างร้าน Supabase Vector ของเรา เพียงแค่ใส่ไคลเอ็นต์ผู้ดูแลระบบ Supabase\nที่นี่ ดังนั้นไคลเอ็นต์ผู้ดูแลระบบ Supabase ก็ใช้ um ที่นี่ เราจะเห็นว่ามันใช้รหัสส่วนตัว ซึ่งเป็น\nรหัสบทบาทบริการของเรา เอ่อ แล้วเราก็ทำได้ ดำเนินการแบบผู้ดูแลระบบโดย\nแทรกเอกสารเหล่านี้ ดังนั้นเราจึงสร้างเอกสารในคอลเลกชันเอกสารของเรา\nอืมเพิ่มประเภทการจัดเก็บเอกสารทั้งหมด จากนั้นเราก็มีเอกสารที่นี่ในฐานข้อมูลของเรา\nจากนั้นเราก็สามารถดำเนินการค้นหาได้ มาดูเรื่องนั้นกันก่อนเลย ก่อนอื่นเราจะต้องเข้าสู่\nระบบ ดังนั้นตอนนี้ถ้าเราดูในโปรเจ็กต์ของเราที่นี่ เอิ่ม ดังนั้นเราจึงทำงานอีกครั้งบน localhost เรากำลังรัน\nuh Supabase stack ทั้งหมดภายในเครื่องและเราทำไม่ได้ ยังไม่มีผู้ใช้ ดังนั้นมาลงทะเบียน\nผู้ทดสอบผู้ใช้ใหม่ที่ test dot de และที่นี่ ถ้าเราบอกว่าลงชื่อเข้าใช้ อืม เราไม่ใช่ คุณรู้\nข้อมูลรับรองที่ไม่ถูกต้องเพราะเรายังไม่มี มาสมัครกัน จากนั้นเราจำเป็นต้อง ตรวจสอบอีเมลของเราเพื่อดู\nลิงก์การสนทนา ตอนนี้เรากำลังใช้งานบน localhost ดังนั้นเราจะไม่ส่งอีเมลจริงๆ ที่นี่\nแต่สิ่งที่เราทำได้คือเรามีบริการที่เรียกว่าใน bucket ซึ่งเป็น\nบริการ Open Source ที่ยอดเยี่ยมจริงๆ เช่นกัน และ เราเห็นตรงนี้ว่าเราได้ยืนยันอีเมลของคุณแล้ว ดังนั้นอีเมลนี้เพิ่ง\nส่งไปเมื่อครู่นี้ และเราสามารถคลิกและยืนยันที่อยู่อีเมลของเรา และตอนนี้เราเห็นว่าเราล็อคอินไว้แล้ว\nแอปพลิเคชันของเราที่นี่ ฉันทำงานบน localhost ดังนั้นตอนนี้เราสามารถแชทกับเอกสารของเราได้ ลอง\nถาม Supabase อนุญาตเครื่องหมายคำถามการทำงานระยะไกลหรือไม่ ดังนั้นเราจึงเริ่มดำเนินการตอนนี้ เรากำลังค้นหา\nรายการที่ตรงกัน และเราจะเห็นได้ที่นี่ เราพบว่ารายการที่ตรงกันของเราคือสอง\nประกาศรับสมัครงาน Supabase เอ่อ แล้วตอนนี้เอกสารก็ยาวเกินไป ดังนั้นเราจึงสรุปข้อมูลจาก\nประกาศรับสมัครงานทั้งสองรายการ จากนั้นเราจะรวบรวมข้อความแจ้งเตือน อืม เราจะเห็นได้ที่นี่ พร้อมท์ของเรา\nแล้วเราจะตอบกลับคำตอบ เอ่อ ใช่ Supabase รองรับการทำงานระยะไกล\nการสื่อสารทางไกลโดยสมบูรณ์จะเกิดขึ้นผ่านวิดีโออีเมล ญาดา ญาดา และนั่นก็เป็นเช่นนั้นเอง\nดังนั้นนี่จึงได้ผลตามที่คาดไว้ มาดูกันว่า\nจริง ๆ แล้วเป็น อย่างไร ฟังก์ชั่นการแชทใช้งานได้อีกแล้ว หัวใจสำคัญของมันคือที่นี่\nในแชทดอท TS ใช่อีกครั้ง เอ่อ เป็น LangChain เอ่อ อะไรเปิด AI เรามีเทมเพลตพร้อมต์ที่นี่\nอืม จากนั้นเราก็มีตัวสรุปของเรา และที่นี่ใช้ตัวช่วยตรวจสอบสิทธิ์ เรากำลังสร้าง\nไคลเอนต์เซิร์ฟเวอร์ Pages ซึ่งเป็นไซต์เซิร์ฟเวอร์ชนิดหนึ่งที่ไคลเอนต์ของเราที่เราสามารถใช้เพื่อดำเนินการเรียงลำดับของ\nการสืบค้นที่ได้รับการตรวจสอบสิทธิ์บนเซิร์ฟเวอร์ ดังนั้นเราจึงเพิ่งได้รับ\nไคลเอ็นต์ Supabase auth uh ของเรา ดังนั้นไคลเอ็นต์การตรวจสอบสิทธิ์ภายใต้การดูแลของเรากำลังจะมา จากที่นี่ เรากำลังสร้าง\nเอ่อ เพจ เอ่อ ไคลเอนต์เซิร์ฟเวอร์ เอ่อ ใส่คำขอและการตอบกลับ\nข้อมูลเรียลไทม์ ดังนั้นเราจึงปิดการจำกัดอัตราที่นี่ เราทำได้โดยใช้เครื่องหมายลบ ดังนั้นเราจึง\nต้องการสตรีม สิทธิ์ใดๆ ที่เรากำลังมา เราก็จะได้รับเซสชั่นของเรา และหากเราได้\nรับการรับรอง เราก็จะได้รับเซสชั่นของเรา หากเรามีเซสชั่น เราก็สามารถจัดการแชทของเราได้เลย\nและเกิดอะไรขึ้น นี่คือดังนั้นเราจึง ตอนนี้ใช้ออฟไลน์ก่อนอื่นเพื่อรับ\nช่องแบบเรียลไทม์พร้อม ID ผู้ใช้ นั่นคือสิ่งที่เราใช้สำหรับการสื่อสารกับเซิร์ฟเวอร์ไคลเอ็นต์\nเอ่อ จากนั้นเราก็แทรกการสื่อสาร [เพลง] ของเราด้วย\nอืม โดยพื้นฐานแล้วเราจะเริ่มต้น ออกจากการสนทนาสำหรับ AI ซึ่งให้ ID การโต้ตอบแก่เรา เพื่อให้\nเราสามารถใช้ uid ที่นี่ อืม แล้วเราก็ได้รับ\nประวัติการสนทนา อืม การล็อก นั่นเป็นเพียงการดูฐานข้อมูลของเรา เพื่อที่เราจะได้ดูว่า\nเราทำได้ ดูที่สตูดิโอของเราสิ ตอนนี้เรามีข้อมูลในการสนทนาจาก\nผู้ใช้ของเรา คำถามและคำตอบที่นี่ ดังนั้นฉันจึงมีการสนทนาหนึ่งก่อนหน้านี้\nอืม ซึ่งเก็บไว้ที่นี่ จากนั้นเราก็รวบรวม อืม ห่วงโซ่โมเดลภาษานี้โดยใช้ชนิดของ เทมเพลตข้อความแจ้ง ของเรา\nนี่คือเทมเพลตการสอบถามที่นี่ โดยให้พรอมต์ผู้ใช้\nและบันทึกการสนทนาต่อไปนี้กำหนดการตอบสนองที่เกี่ยวข้อง ดังนั้นพรอมต์ผู้ใช้จึงเหมือนกับ\nประวัติการสนทนาในการสืบค้น และเรากำลังให้คำแนะนำมากมายที่นี่\nอืม ไปกันเลย จากนั้นสิ่งที่เรากำลังทำคือเรากำลังสร้างช่องออกอากาศของเรา เพื่อให้เรา\nสามารถสมัครรับข้อมูลช่องได้ และโดยพื้นฐานแล้วเมื่อเราสมัครรับข้อมูลแล้ว เราก็สามารถส่งการออกอากาศได้\nและที่นี่เราแค่ส่งตอนนี้ โอเค เรากำลังเริ่มต้น กำลังค้นหาการจับคู่ ดังนั้นที่นี่เรากำลัง\nรับการจับคู่จากการฝัง ดังนั้นนี่คือห่วงโซ่ความยาว\nเอ่อ ลิงก์เชน เช่นเดียวกับไคลเอนต์ที่ได้รับการดูแล เปิดการฝัง Ai และร้านค้าเวกเตอร์\nอืม เราแค่ทำการค้นหาความคล้ายคลึงกันของร้านค้าของเรา ที่นี่ ดังนั้นข้อมูลทั้งหมดนั้นคุณสามารถขุด\nผ่านรายละเอียดของ length chain ได้ แต่นี่คือวิธีที่เราทำการค้นหาความคล้ายคลึงกับ\nLangChain เพื่อค้นหาเอกสารที่เกี่ยวข้องสำหรับการแชทของเรา เพื่อให้เราได้รับแมตช์จากแมตช์ที่เรา\nมี URL ของเราและเราเห็นว่าเราคอนโซลออกจากระบบ URL เหล่านั้น และสุดท้าย เราก็\nแค่ได้รับข้อมูลเมตาที่ตรงกัน รับข้อความและ URL จากนั้นโดยพื้นฐานแล้ว เรากำลัง\nสร้างเทมเพลตพร้อมท์พร้อมข้อมูลสรุปร่วมกัน เพื่อให้คุณรู้ว่าใจดี ของ\nรายละเอียดโดยสรุปจากเอกสารของเรา คำถามจากผู้ใช้ ประวัติการสนทนาตลอดจน\nURL จากนั้นเราก็กำลังทำการเอิ่ม เปิดแชท AI ที่นี่โดยใช้ GPT 3.5 รุ่นเทอร์โบ\nเอิ่ม แล้วรวมมันเข้าด้วยกันตรงนี้ แล้วสิ่งที่เรา เรากำลังดำเนินการอยู่เมื่อเรามีการอัปเดตใดๆ\nโดยพื้นฐานแล้วนั่นคือวิธีการสตรีมมิ่งที่นี่ ดังนั้นเราจึงบอกว่าการสตรีมเป็นจริง และ\nทุกครั้งที่เราได้รับโทเค็นใหม่ เราก็จะส่งสิ่งนี้ผ่านช่องออกอากาศของเรา\nและจุดที่เราได้รับมันจากฝั่งไคลเอ็นต์ และในตอนท้ายเมื่อ อืม LL แอมป์เชนทั้งหมดเสร็จ\nสิ้น เราก็เพียงแค่อัปเดตการสนทนาของเรา เอ่อ ด้วย ID การโต้ตอบ\nในฐานข้อมูล เพื่อที่เราจะได้มี คำตอบจาก AI ในบันทึกการสนทนาของเรา\nใช่แล้ว ค่อนข้างมาก เราสามารถดูดัชนีได้ที่นี่ ดังนั้นในดัชนีที่เราใช้อยู่ คุณรู้ว่า\nนี่คือการแสดงผลฝั่งไคลเอ็นต์ ดังนั้นเราจึงใช้ Supabase เอ่อ เบราว์เซอร์ไคลเอ็นต์ที่นี่จาก ตัวช่วยตรวจสอบสิทธิ์ Supabase\nเอ่อ แล้วเราก็กำลังรวบรวมมัน เรามีมันที่ไหนที่นี่ ใช่แล้ว\nเรากำลังรวบรวม เอ่อ รวมการตรวจสอบสิทธิ์เข้าด้วยกันโดยใช้ส่วนประกอบการตรวจสอบสิทธิ์ superface ที่นี่ จากนั้นเรา\nก็มี Channel Listener ของเรา ดังนั้นนี่คือ Supabase เอ่อ ออกอากาศทางช่องเรียลไทม์ของเรา ดังนั้นเมื่อ\nเราได้รับกิจกรรมแชท เราก็แค่ตรวจสอบ โอเค นี่คือการตอบกลับ นี่คือข้อความสถานะ\nเอ่อ ตอบกลับ แล้วคุณล่ะ เอ่อ แล้วเราก็อัปเดตข้อความแชทบอทของเรา เอ่อ ก็ดีเหมือน\nกัน วิธีที่เราใช้การสตรีมโดยใช้ Supabase แบบเรียลไทม์กับขนาดลูกค้าของเรา ใช่\nอืม ค่อนข้างมาก นี่คือวิธีที่คุณสามารถรวม\nผู้ให้บริการต่างๆ เหล่านี้เข้าด้วยกันโดยพื้นฐานภายในความเร็วขั้นสุดยอด เพื่อให้ฟังก์ชันการทำงานใช้งานได้หาก คุณ\nสนใจที่จะสร้างด้วย um Supabase เอ่อด้วยมากกว่านั้นด้วย next.js แอปพลิเคชัน AI ประเภทอื่น ๆ\nเรามีการค้นหาเอกสาร xjs openai และนี่ใช้ um versal um versal AI SDK ดังนั้น\nหากคุณสนใจคุณก็รู้ว่าใจดี มันทำงานยังไง คุณสามารถดูได้ที่นี่ และเรายัง\nมีคำอธิบายวิดีโอสำหรับอันนี้ด้วย ขอบคุณมากที่ติดตาม และเจอกันในวิดีโอ\nหน้าต่างประเทศ"
      },
      {
        "srtUrl": null,
        "type": "user_generated",
        "language": "tr",
        "plaintext": "merhaba bugün next.js ve LangChain ile Supabase Vector kullanarak bir sohbet robotu oluşturmayı düşünüyoruz,\nböylece artık belgemizle sohbet edebiliriz, belki de Supabase'in uzaktan çalışmaya izin verip vermediğini soralım\nsoru işareti o yüzden bunu şimdi kapatıyoruz um Eşleşmeleri buluyoruz ve burada görebiliyoruz,\nböylece eşleşmelerimizi bulduk, bunlar bu iki Supabase iş ilanı ve sonra belge\nçok uzun, bu yüzden iki iş ilanındaki bilgileri özetliyoruz ve sonra\nbir araya getiriyoruz ımm istemimiz yani umm istemimizi burada görebiliriz uh ve sonra yanıtı geri aktarıyoruz\nuh evet Supabase uzaktan çalışmayı destekliyor artık bu demo Pinecone uh chatbot demosunun bir çatalı\nve bu gerçekten Roy'un harika bir çalışması. next.js'de bağlantı zinciri JS ile çok kullanıcılı bir sohbet robotu oluşturma konsepti hakkında\naşağıya bağlantı vereceğim blog yazısını okuyabilirsiniz ve\nbunun birkaç bileşeni var ama en önemlisi benim istediğim şey Burada deneyeceğimiz şey,\nbu fark servislerinin çoğunu\nSupabase'de yerleşik olan yeteneklerle değiştirmek, dolayısıyla Pinecone yerine Supabase Vector kullanıyoruz, Sable yerine Supabase Vector kullanıyoruz,\nCockroachdb yerine gerçek zamanlı Supabase kullanıyoruz. Supabase yığınıyla birlikte gelen postgres veritabanını kullanıyoruz\nve parmak izi yerine Supabase auth kullanıyoruz, bu nedenle tüm bu Hizmetleri\nsadece Supabase'e indiriyoruz ve AI um'u şimdi burada next.js ile\nmimari açısından açıyoruz. sohbet robotu, iki tür bileşenimiz var, yani bir indeksleyicimiz var,\nbu da bir nevi yerleştirmeler yazıyor, bir nevi kendimizden Hakikat yerleştirmeleri üretiyor,\nböylece indeksleyiciye bakabiliyoruz, böylece Hakikat kaynağımız var, ki bu da bazı web siteleridir\nBu bilgiyi web sitesinden alan bir tarayıcıya sahibiz ve ardından LangChain ve açık yapay zekayı kullanarak\nyerleştirmelerimizi oluşturuyoruz ve ardından bunları Supabase vektörümüzde saklıyoruz ve\nsonra kendi türümüzdeki Gerçeklik ile sohbet etmek istediğimizde temel olarak alıyoruz kullanıcı sorgusu\nyine bu sorgudan bir yerleştirme oluştururuz, ardından tüm belgelerde arama yaparak\nilgili türde bir tür doğruluk kaynağı buluruz, ilgili\nURL'lerin türünü dizine ekleriz, söz konusu URL'lerdeki içeriği özetleriz ve sonra nerede bir tür yanıt oluşturuyoruz ve\nbunu denetimli gerçek zamanlı kullanarak kullanıcıya geri aktarıyoruz, şimdi LangChain'in en güzel yanı\nSupabase Vector için yerleşik desteğe sahip olması ve bunu yapabilmemizin yolu şu:\nbu şemayı alabiliriz buraya ve vektör uzantısını kullanarak bunu veritabanımıza uygulayın ve eğer\nburaya klonlarsanız bu bağlantı zinciri sohbet robotu demosunu kopyalarsanız URL de aşağıdadır Açıklamada aşağıdadır,\ndaha sonra bunu örneğin vs kodunda açabiliriz ve şöyle bakabiliriz burada bazı geçişler var\n, yani bunlar bir Supabase start çalıştırdığımızda uyguladığımız ilk geçişler,\nböylece yerel yığınımızı başlatmak için Supabase start'ı burada çalıştırabiliriz. Onu zaten çalıştırıyorum, böylece\nyerelin türünü görmek için denetimli durumu çalıştırabilirim. kimlik bilgileri ve bunu burada açarsam,\nbunu bağlantı zinciri belgelerinden kopyaladığımızı görebiliriz, yani\nSupabase Vektörümüzün belgelerimizi oluşturmasını sağlayan şey budur, yani temel olarak LangChain çerçevesinin\nSupabase vektörüyle birlikte çalışmasını sağlar ve sonra bir şey Buraya özellikle\nkimliği doğrulanmış kullanıcılar için genel belgelerde sorgulamaya izin verme yeteneğini ekledim\n, bu nedenle burada satır düzeyinde güvenlik politikaları kullanılıyor ve bu nedenle yalnızca kimliği doğrulanmış\nkullanıcılar için bir tür istemci tarafından sorgulamaya izin vermek istedik. örneğin buna izin verebilir miyiz, aksi halde\nburada da bununla aynıdır, bu da buradaki rol seviyesi güvenliğine bir nevi eklenmiştir ve ayrıca\nkonuşmaları da saklıyoruz, yani temelde metin sıralamasını biliyorsunuz sohbete yazılanların\nve ardından yapay zekanın yanıtladığı şeyin, kafa karıştırıcı ve yapay zeka sohbet robotu konuşmalarını saklıyoruz,\nayrıca sohbetin geçmişini hatırlamak istiyoruz ve aynı zamanda\nbu sohbet geçmişini sohbete enjekte ediyoruz. önceki konuşmaların geçmişini de bilmenizi ister\nve yine burada bir tür rol düzeyinde güvenlik politikası uyguluyoruz, özellikle de yalnızca\nkullanıcının chatbot ile bildiğiniz gibi kendi sohbet türlerini görebilmesi\nuh, yani burada bir tür bilgiyi kilitliyoruz tamam harika, o zaman hadi bir bakalım,\nbunu çalıştırabiliriz, böylece npm run def diyebiliriz, yani her şeyden önce,\nyerel olarak çalışan Supabase'imiz olduğunu biliyorsunuz ve sonra da elimizde bir tane var. uh sohbet botu burada yerel olarak çalışıyor ve\nSupabase kimlik doğrulamasıyla birlikte geliyor, yani bu aslında tepki vermek için kimlik doğrulama arayüzüdür ama sonra her şeyden önce\nbazı bilgileri taramak istiyoruz ve burada biliyorsunuz, örneğin bilmiyorsanız işe alıyoruz\nSupabase kariyerlerine göz atabilirsiniz, örneğin müşteriler için işe alım yapıyoruz Çözüm mimarı\nve tüm iş tanımı burada burada\nyüzde 100 uzaktan çalışma ve şirketteki ESOP gibi bildiğiniz birçok bilgi var Hisse sahipliği ve evet tonlarca\nşey yani biliyorsunuz hadi hayatımızı kolaylaştıralım ve hadi bunu gerçekten tarayalım, böylece API eğik çizgi taraması\num burada iş tanımımızı tarayabiliriz ve görebildiğimiz şey şu ki artık pirzolalarımızda sürünüyoruz ve\naynı zamanda tarayıcı türü olarak da tarıyoruz bir miktar özyinelemeli bir şey yapar ve burada bir nevi bağlantılı olan sayfaları da tarar\nve sonra bunun tamam olduğunu görebiliriz,\npeki şimdi eğer şuraya gidersek aslında ne görebiliriz? Supabase Studio burada, böylece localhost'u\nyeniden elimizde tutuyoruz, eğer hatırlamıyorsanız, denetimli bir başlangıç ​​yaptıktan sonra Supabase durumunu yapabiliriz,\nyerel ayrıntılarımızı buradan alabiliriz ve böylece bu projeyi burada yerel olarak açabiliriz ve\nşimdi bakabiliriz konuşmalarımız var yani henüz bir konuşmamız yok ama burada belgelerimiz var\nyani bu da taradığımız şey işte burada Vektör yerleştirmelerimiz var ve\nbir tür kod satırlarını görebilirsiniz, satırları değil kodun bazı meta verileri de var ve\nbunlar bir tür satırlar, yani belgeler bir nevi farklı bölümlere ayrılmış, bu yüzden\nmeta verileri de kullanarak daha sonra bazı filtrelemeler yapabiliriz, böylece\nJson'a sahip olduğumuz postgres'te gerçekten güçlüdür B veri türü, böylece tam türden Json belgelerini içine bırakabiliriz,\nbiliyorsunuz, buradaki belgelerimizi meta veriler olarak harika olarak biliyorsunuz, bu yüzden şimdi bunu taradık,\nveritabanımızda var, yani şimdi yapabileceğimiz şey şu: hadi gerçekten sahip olalım bu tarayıcının nasıl çalıştığına bir göz atın,\nbu Sayfalar API'mizdedir ve sonra buraya tarayın, böylece uzunluk zincirini kullanıyoruz,\nLangChain'den openai yerleştirmelerimizi kullanıyoruz ve sonra Supabase Vector mağazasını kullanıyoruz, bu yüzden bu gerçekten güzel\nSupabase Vector mağazası ile bir tür uzunluk zinciri entegre edilmiştir ve sonra gerçekten de\nsorgudan indekslemek istediğimiz URL'leri alıyoruz, bir çeşit belge koleksiyonu yaratıyoruz,\nbu yüzden bir nevi bölüyoruz Gömmeyi oluşturmak için bildiğiniz doğru boyuta sahip olduğumuzdan emin olmak için bölümler var,\nböylece belirteç boyutunun tükenmemesini ve\nbelgelerin bölünmesini burada sağlıyoruz ve sonra kendi bölümümüzü oluşturuyoruz. açık AI\nyerleştirmelerini yerleştiriyoruz, Supabase Vector mağazamızı oluşturuyoruz, buraya sadece bir Supabase yönetici istemcisi yerleştiriyoruz,\nböylece Supabase yönetici istemcisi sadece burada kullanıyor , burada bizim hizmet rol anahtarımız\nolan özel anahtarı kullandığını görebiliyoruz ve sonra yapabiliriz bu belgeleri ekleyen bir tür yönetici işlemi gerçekleştiriyoruz\nve böylece evet, belge koleksiyonumuzda bir tür oluşturuyoruz\nve tüm belgeleri bir nevi saklıyoruz ve ardından belgeleri burada veritabanımızda tutuyoruz\nve ardından aramalar gerçekleştirebiliyoruz onlar üzerinde o yüzden hadi buna geçelim, yani her şeyden önce oturum açmamız gerekecek.\nYani şu anda buradaki projemize bakarsak, yani tekrar localhost üzerinde çalıştırıyoruz,\ntüm Supabase yığınını yerel olarak çalıştırıyoruz ve bunu yapmıyoruz. Henüz hiç kullanıcımız yok, bu yüzden test dot de'de yeni bir kullanıcı test cihazına kaydolalım\nve burada oturum aç dersek, geçersiz kimlik bilgilerini bilmiyoruz\nçünkü henüz kaydolmadık ve sonra kaydolmamız gerekiyor. konuşma bağlantısı için e-postamızı kontrol edin,\nşimdi localhost üzerinde çalışıyoruz, bu nedenle burada gerçek e-postalar göndermiyoruz\nancak yapabileceğimiz şey,\naynı zamanda gerçekten harika bir Açık Kaynak hizmeti olan kova adı verilen bir hizmete sahip olmamız ve burada görebiliyoruz, e-postanızı onayladık, yani bu az\nönce gönderildi ve tıklayıp e-posta adresimizi onaylayabiliriz ve şimdi kilitlendiğimizi görebiliriz\nuygulamamızı burada localhost üzerinde çalıştırıyorum bu yüzden artık belgelerimiz ile sohbet edebiliriz o yüzden belki\nSupabase'in uzaktan çalışmaya izin verip vermediğini soralım soru işareti yani bunu şimdi kapatıyoruz um\neşleşmeleri buluyoruz ve burada görebiliyoruz yani eşleşmelerimizi bulduk bunlar şu iki Supabase iş\nilanı ve sonra belge çok uzun, bu yüzden iki iş ilanındaki bilgileri özetliyoruz\nve ardından tüm istemimizi bir araya getiriyoruz, böylece burada görebiliriz istemimiz\nve ardından cevabı geri aktarıyoruz uh evet Supabase uzaktan çalışmayı destekliyor\nveya tamamen uzaktan iletişim e-posta videosu veya yada üzerinden gerçekleşecek ve bu tam olarak bu\nyani bu tamamen beklendiği gibi çalışıyor hadi gerçekte nasıl olduğuna bir göz atalım\nsohbet işlevi tekrar çalışıyor, bunun kalbi bir nevi burada\nsohbet noktası TS Evet yine bir nevi LangChain uh şeyler açık AI burada bir bilgi istemi şablonumuz var\nve sonra özetleyicimizi aldık ve burada kimlik doğrulama yardımcılarını kullanıyoruz istemcimizin\nsunucuda kimlik doğrulaması yapılmış sorgular gerçekleştirmek için kullanabileceği bir tür sunucu sitesi olan\nbir Pages sunucu istemcisi oluşturuyoruz ve bu nedenle sadece Supabase kimlik doğrulama\nistemcimizi alıyoruz, böylece denetlenen kimlik doğrulama istemcimiz geliyor buradan aşağıdan yani ım uh Sayfalar uh sunucu istemcisi oluşturuyoruz,\nuh istekleri ve yanıtları bazı gerçek zamanlı\nbilgileri koyuyoruz, böylece hız sınırını devre dışı bırakıyoruz, bunu eksi bir ile yapabiliriz, bu yüzden sadece\nyayın yapmak istiyoruz herhangi bir şekilde geliyoruz, sonra oturumumuzu alıyoruz ve eğer kimliğimiz doğrulandıysa,\no zaman buradayız, eğer bir oturumumuz varsa, o zaman ateş edebilir ve sohbetimizi halledebiliriz\nve burada ne oluyor, yani biz şimdi çevrimdışımızı her şeyden önce\nkullanıcı kimliğiyle birlikte gerçek zamanlı bir Kanal elde etmek için kullanıyoruz, yani sunucu-istemci iletişimi için bunu kullanıyoruz,\nsonra [Müzik] iletişimimizi de ekliyoruz,\nyani temel olarak başlıyoruz Bize bir etkileşim kimliği veren yapay zeka için bir konuşma yapıyoruz, böylece\nburadaki kullanıcı kimliğini kullanabiliriz ve daha sonra sohbetin\nkilit geçmişini alıyoruz, bu da bir nevi veritabanımıza bakıyoruz, böylece\nbakabiliriz Stüdyomuza bakın, yani burada şimdi konuşmalarımız var, kullanıcımızdan bu bilgiyi aldık,\nsoru ve yanıt burada, yani daha önce zaten bir konuşma yapmıştım,\nbu burada saklandı, sonra bu dil modeli zincirini bir tür kullanarak bir araya getiriyoruz bilgi istemi şablonumuz\n, buradaki sorgulama şablonu, bir nevi aşağıdaki kullanıcı istemi\nve konuşma günlüğü verilmiş, ilgili yanıt formüle edilmiş, yani kullanıcı istemi, bir tür\nsorgu konuşma geçmişidir ve biz ona bir nevi bir sürü talimat veriyoruz,\nişte başlıyoruz ve sonra yaptığımız şey şu: yayın kanalımızı oluşturuyoruz, böylece\nKanala abone olabiliyoruz ve temel olarak abone olduğumuzda bir yayın gönderebiliyoruz\nve işte şimdi gönderiyoruz tamam, başlıyoruz Eşleşmeleri buluyoruz, bu yüzden burada\nyerleştirmelerden eşleşmeler alıyoruz, yani bu bir tür uzunluk zinciri\nve bağlantı zinciri, yani denetlenen müşteri açık Ai yerleştirmeleri ve vektör mağazasını açıyor,\nbiz sadece mağaza benzerliği aramamızı yapıyoruz burada tüm bu bilgileri uzunluk zinciri ayrıntılarına inerek inceleyebilirsiniz\n, ancak sohbetimizle ilgili belgeleri bulmak için LangChain ile benzerlik aramamızı bu şekilde yapıyoruz,\nböylece eşleşmelerimizi daha sonra sahip olduğumuz maçlardan alıyoruz.\nURL'lerimiz ve gördüğünüz gibi, konsolda bu URL'lerden çıkış yaptık ve son olarak\nbir nevi eşleşme meta verilerini alıyoruz, metni ve URL'leri alıyoruz ve ardından temel olarak\nbilgi istemi şablonumuzu özetlerle birlikte oluşturuyoruz, yani bu sizin bildiğiniz tür belgelerimizden özetlenmiş ayrıntılar,\nkullanıcıdan gelen soru, konuşma geçmişi ve\nURL'ler ve sonra burada GPT 3.5 turbo modelini kullanarak açık yapay zeka sohbetimizi yapıyoruz\nve bunu burada bir araya getiriyoruz ve sonra ne yapıyoruz? Herhangi bir güncelleme aldığımızda bunu yapıyoruz\n, yani temelde akış burada böyle çalışıyor, bu yüzden akışın doğru olduğunu söylüyoruz ve\nne zaman yeni bir jeton alsak bunu yayın kanalımız aracılığıyla gönderiyoruz\nve daha sonra bunu istemci tarafında alırız ve sonunda tüm LL amp zinciri\nbir nevi bittiğinde, konuşmamızı veri tabanındaki etkileşim kimliğiyle güncelleriz,\nböylece AI'dan gelen yanıtlar konuşma günlüğümüzde\num evet, buradaki dizine bakabildiğimiz kadar bu yüzden kullandığımız dizinde\nbunun istemci tarafında oluşturulduğunu biliyorsunuz, bu yüzden burada Supabase uh tarayıcı istemcisini kullanıyoruz Supabase\nkimlik doğrulama yardımcıları ve sonra hemen hemen bir araya getiriyoruz, burada nerede var, evet\nburada superface kimlik doğrulama bileşenini kullanarak kimlik doğrulamasını bir araya getiriyoruz ve sonra\nsadece Kanal dinleyicimiz var, yani bu Supabase ah gerçek zamanlı Kanal yayınımız, bu yüzden\nbir sohbet etkinliği aldığımızda temelde sadece kontrol ederiz tamam mı bu bir yanıt mı bu bir durum mesajı mı\nah yanıt ve ne buldun ve sonra chatbot mesajımızı güncelliyoruz ah ve bu çok\nnazik Supabase'i gerçek zamanlı kullanarak müşteri boyutumuza göre akış türünü nasıl elde ettiğimize dair evet ımm,\nhemen hemen bu kadar, bu, tüm bu farklı hizmet\nsağlayıcılarını temel olarak süper hızda bir araya getirmenin bir yolu, böylece işlevsellik kullanılabilir.\num Supabase ile daha fazlasını, next.js ile daha fazla türde AI uygulamasıyla geliştirmekle ilgileniyorsunuz, bir\nxjs openai belge aramamız var ve bu aslında um versal ve versal AI SDK'yı kullanıyor, yani\neğer ilgileniyorsanız tür bilirsiniz bu nasıl çalışıyor, buna buradan bakabilirsiniz ve bunun için de\nbir video açıklamamız var, bizi izlediğiniz için çok teşekkürler ve bir sonraki\nyabancı videoda görüşürüz"
      }
    ],
    "commentsTurnedOff": false,
    "isMonetized": null,
    "hashtags": [
      "#AppDevelopment",
      "#Supabase",
      "#DeveloperTools"
    ],
    "formats": [],
    "isMembersOnly": false,
    "input": "https://youtu.be/Tt45NrVIBn8?si=Rh62ANKcBMsr04bE"
  }
]